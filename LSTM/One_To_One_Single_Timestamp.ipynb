{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create simple datasets\n",
    "X = list()\n",
    "Y = list()\n",
    "X = [x+1 for x in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [y*15 for y in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] [15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300]\n"
     ]
    }
   ],
   "source": [
    "print (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(20, 1, 1) # input to LSTM is 3D (samples, timestamps, features).. as we have 20 sample, 1 timestamp per sample, 1 feature per timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/digishgabhawala/Library/Python/3.5/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(50,activation='relu',input_shape=(1,1))) # inputshape 1X1 because we have 1 timestamp and 1 feature\n",
    "model.add(keras.layers.Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/digishgabhawala/Library/Python/3.5/lib/python/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 21029.7590 - val_loss: 77221.5234\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 640us/step - loss: 21013.4615 - val_loss: 77168.4219\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 20996.4658 - val_loss: 77112.2734\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 20979.5771 - val_loss: 77055.5469\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 20962.7809 - val_loss: 76998.5938\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 519us/step - loss: 20945.3277 - val_loss: 76938.1484\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 526us/step - loss: 20925.6630 - val_loss: 76874.9531\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 529us/step - loss: 20907.3409 - val_loss: 76803.9688\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 20887.9018 - val_loss: 76729.6172\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 20862.8324 - val_loss: 76653.9688\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 20841.1300 - val_loss: 76566.5156\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 20815.5127 - val_loss: 76470.2109\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 20788.6351 - val_loss: 76365.9062\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 20758.4920 - val_loss: 76251.6250\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 20725.7950 - val_loss: 76124.4375\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 20694.5881 - val_loss: 75977.1172\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 20650.7177 - val_loss: 75814.7656\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 636us/step - loss: 20606.2111 - val_loss: 75629.3047\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 20564.4917 - val_loss: 75408.1094\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 20506.1914 - val_loss: 75175.8750\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 20446.1285 - val_loss: 74923.3281\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 649us/step - loss: 20379.0442 - val_loss: 74642.3125\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 20306.6528 - val_loss: 74339.6094\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 20236.8339 - val_loss: 73992.9297\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 20152.4552 - val_loss: 73635.8125\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 20074.0770 - val_loss: 73227.3516\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 19976.5351 - val_loss: 72794.9297\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 19870.7941 - val_loss: 72352.7344\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 19777.9459 - val_loss: 71859.5547\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 19644.2831 - val_loss: 71372.0156\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 19542.0893 - val_loss: 70815.3359\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 672us/step - loss: 19408.3681 - val_loss: 70275.5703\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 19289.6843 - val_loss: 69690.0156\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 19129.8922 - val_loss: 69089.5625\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 18992.2618 - val_loss: 68429.6797\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 18844.3704 - val_loss: 67761.9453\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 18689.6678 - val_loss: 67092.2031\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 18519.9427 - val_loss: 66435.8047\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 18377.3156 - val_loss: 65764.3984\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 18200.4706 - val_loss: 65082.6875\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 18032.2128 - val_loss: 64415.8906\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 17873.7248 - val_loss: 63767.7148\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 17708.1924 - val_loss: 63135.1836\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 17541.9648 - val_loss: 62483.1250\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 17361.0392 - val_loss: 61773.2578\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 17181.1356 - val_loss: 61048.9531\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 16987.4653 - val_loss: 60373.2812\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 16824.4241 - val_loss: 59686.3242\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 16645.0277 - val_loss: 58988.5312\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 16468.4781 - val_loss: 58251.2422\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 16266.9035 - val_loss: 57572.7969\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 16080.1903 - val_loss: 56910.4141\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 15907.6173 - val_loss: 56213.5273\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 15712.8686 - val_loss: 55564.2383\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 15525.0997 - val_loss: 54926.5156\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 15349.5084 - val_loss: 54237.7812\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 15165.3078 - val_loss: 53553.8711\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 14981.4244 - val_loss: 52849.3359\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 14781.9982 - val_loss: 52177.5508\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 643us/step - loss: 14599.1229 - val_loss: 51526.1367\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 14406.1010 - val_loss: 50878.0781\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 14225.0183 - val_loss: 50221.2344\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 14039.6264 - val_loss: 49576.4570\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 13858.6503 - val_loss: 48929.9727\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 13682.5513 - val_loss: 48301.9844\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 13489.7244 - val_loss: 47685.2344\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 13308.5388 - val_loss: 47003.9297\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 13137.4008 - val_loss: 46290.7656\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 12916.7710 - val_loss: 45620.4219\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 12721.7439 - val_loss: 44906.5117\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 12516.3715 - val_loss: 44243.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 12333.6135 - val_loss: 43576.1992\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 528us/step - loss: 12137.3262 - val_loss: 42900.9336\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 11942.5156 - val_loss: 42168.0898\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 11729.8217 - val_loss: 41423.8945\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 11539.0202 - val_loss: 40728.1250\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 11331.8884 - val_loss: 40102.0078\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 11163.5336 - val_loss: 39481.0273\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 10980.1607 - val_loss: 38854.3867\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 10801.3744 - val_loss: 38263.1016\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 634us/step - loss: 10632.0803 - val_loss: 37674.9609\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 10455.9069 - val_loss: 37091.0117\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 654us/step - loss: 10296.2314 - val_loss: 36499.6680\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 10130.3685 - val_loss: 35911.9531\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 9948.4672 - val_loss: 35295.1758\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 9771.3479 - val_loss: 34644.2227\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 9584.7634 - val_loss: 34040.6406\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 9413.7664 - val_loss: 33453.7578\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 9245.9038 - val_loss: 32865.1016\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 9078.5614 - val_loss: 32217.8438\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 8891.7670 - val_loss: 31592.4277\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 8725.6163 - val_loss: 30983.9414\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 8534.6123 - val_loss: 30414.8789\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 637us/step - loss: 8393.5858 - val_loss: 29813.6328\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 8218.2747 - val_loss: 29188.1016\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 8047.7177 - val_loss: 28521.4785\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 7860.0540 - val_loss: 27902.6621\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 7679.6852 - val_loss: 27307.6816\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 7507.7413 - val_loss: 26743.1113\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 7348.6668 - val_loss: 26188.8320\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 7190.3408 - val_loss: 25664.8984\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 7044.2988 - val_loss: 25152.8301\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 6907.7198 - val_loss: 24640.0215\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 6772.3708 - val_loss: 24127.3809\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 6626.2073 - val_loss: 23635.1602\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 6477.9801 - val_loss: 23164.2715\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 6346.5472 - val_loss: 22687.6211\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 6206.8531 - val_loss: 22223.7012\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 641us/step - loss: 6078.6147 - val_loss: 21745.8848\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 5937.0522 - val_loss: 21281.6992\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 5804.8042 - val_loss: 20828.5820\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 5674.1752 - val_loss: 20360.9180\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 5539.3435 - val_loss: 19849.1289\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 5412.1480 - val_loss: 19329.1406\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 5262.6137 - val_loss: 18831.8965\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 5114.6871 - val_loss: 18369.6523\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 4973.7362 - val_loss: 17903.6895\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 4837.4381 - val_loss: 17382.4980\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 4707.5620 - val_loss: 16839.4355\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 4549.3311 - val_loss: 16360.4727\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 4411.2113 - val_loss: 15899.8760\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 4280.3825 - val_loss: 15426.3271\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 4152.7242 - val_loss: 14973.3633\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 4014.1908 - val_loss: 14517.8760\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 3890.8943 - val_loss: 14088.8594\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 3780.7700 - val_loss: 13690.3457\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 3669.1232 - val_loss: 13323.4287\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 3566.6228 - val_loss: 12965.3115\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 3462.2152 - val_loss: 12587.1523\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 3358.6233 - val_loss: 12212.1016\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 3252.4993 - val_loss: 11865.9014\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 645us/step - loss: 3159.3891 - val_loss: 11526.5869\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 3063.6832 - val_loss: 11198.0000\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 2963.7472 - val_loss: 10871.8262\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 669us/step - loss: 2877.6992 - val_loss: 10530.3965\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 621us/step - loss: 2782.5847 - val_loss: 10208.5195\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 2697.1385 - val_loss: 9877.4541\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 2602.9737 - val_loss: 9563.1943\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 2515.1699 - val_loss: 9233.4590\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 2416.7439 - val_loss: 8935.9199\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 2341.3797 - val_loss: 8623.4609\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 2258.7800 - val_loss: 8336.5156\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 2175.0263 - val_loss: 8065.2256\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 2094.1933 - val_loss: 7781.7129\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 2015.7751 - val_loss: 7500.1475\n",
      "Epoch 146/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 564us/step - loss: 1942.5589 - val_loss: 7209.0127\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1862.6106 - val_loss: 6927.8374\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1781.5730 - val_loss: 6664.8701\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 644us/step - loss: 1724.7943 - val_loss: 6390.8804\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1639.0611 - val_loss: 6153.2715\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 678us/step - loss: 1571.5953 - val_loss: 5908.8105\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1511.6185 - val_loss: 5668.9326\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1449.8696 - val_loss: 5451.2935\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1384.0296 - val_loss: 5247.6089\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1326.4964 - val_loss: 5047.6055\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1275.3648 - val_loss: 4853.8369\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1225.1795 - val_loss: 4670.7334\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1175.2298 - val_loss: 4495.9053\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1127.9515 - val_loss: 4336.3237\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1087.4277 - val_loss: 4181.9692\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1045.0445 - val_loss: 4030.9045\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1000.4256 - val_loss: 3894.7969\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 966.9932 - val_loss: 3757.2939\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 928.6388 - val_loss: 3625.9282\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 894.6514 - val_loss: 3488.6069\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 858.2495 - val_loss: 3355.7412\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 821.3726 - val_loss: 3222.8838\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 787.8676 - val_loss: 3100.3105\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 754.6056 - val_loss: 2986.8809\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 723.4585 - val_loss: 2879.5898\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 693.4741 - val_loss: 2774.6375\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 668.2435 - val_loss: 2661.9575\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 634.5647 - val_loss: 2558.0752\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 606.5015 - val_loss: 2443.6716\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 577.4363 - val_loss: 2329.7173\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 547.9806 - val_loss: 2222.2368\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 520.8549 - val_loss: 2124.0146\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 494.6921 - val_loss: 2031.0031\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 626us/step - loss: 470.2718 - val_loss: 1942.2297\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 446.1846 - val_loss: 1848.8291\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 422.8437 - val_loss: 1757.9846\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 401.0543 - val_loss: 1672.2682\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 380.0727 - val_loss: 1594.1196\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 359.2913 - val_loss: 1524.0037\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 677us/step - loss: 340.9162 - val_loss: 1453.9039\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 323.7789 - val_loss: 1386.2166\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 306.1512 - val_loss: 1322.1111\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 288.9344 - val_loss: 1256.8679\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 614us/step - loss: 273.2299 - val_loss: 1191.0072\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 257.3681 - val_loss: 1131.5951\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 242.4521 - val_loss: 1072.4226\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 229.2621 - val_loss: 1014.3781\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 650us/step - loss: 214.0785 - val_loss: 965.1852\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 610us/step - loss: 202.5863 - val_loss: 920.1727\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 191.0512 - val_loss: 880.6589\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 181.3859 - val_loss: 842.1947\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 172.5663 - val_loss: 801.6868\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 162.8020 - val_loss: 765.8477\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 153.9611 - val_loss: 731.9241\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 693us/step - loss: 145.4317 - val_loss: 697.6274\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 137.3611 - val_loss: 666.1845\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 130.1084 - val_loss: 636.8917\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 123.6379 - val_loss: 607.2889\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 116.2916 - val_loss: 580.5022\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 109.9822 - val_loss: 554.8683\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 104.4611 - val_loss: 527.7532\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 97.8351 - val_loss: 504.3751\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 92.7332 - val_loss: 482.3120\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 87.6072 - val_loss: 460.6667\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 624us/step - loss: 82.4869 - val_loss: 440.2390\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 78.0655 - val_loss: 418.7718\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 73.4887 - val_loss: 399.4601\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 68.8949 - val_loss: 382.2449\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 65.1722 - val_loss: 364.9787\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 61.3914 - val_loss: 347.6403\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 57.6144 - val_loss: 332.1871\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 54.4651 - val_loss: 317.4600\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 51.1734 - val_loss: 303.5689\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 48.2795 - val_loss: 289.3363\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 45.2901 - val_loss: 276.5195\n",
      "Epoch 221/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 583us/step - loss: 42.5863 - val_loss: 264.1225\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 39.7513 - val_loss: 250.9695\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 647us/step - loss: 37.4048 - val_loss: 237.9082\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 34.9274 - val_loss: 226.3067\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 627us/step - loss: 32.3926 - val_loss: 215.8549\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 667us/step - loss: 30.3036 - val_loss: 204.9892\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 28.4246 - val_loss: 194.9718\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 26.5263 - val_loss: 185.9088\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 24.8695 - val_loss: 177.9096\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 619us/step - loss: 23.3291 - val_loss: 170.7203\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 21.8468 - val_loss: 163.8486\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 20.6857 - val_loss: 156.8405\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 19.4776 - val_loss: 150.4532\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 18.2320 - val_loss: 144.7442\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 17.2476 - val_loss: 139.3429\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 657us/step - loss: 16.2998 - val_loss: 134.1011\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 15.4148 - val_loss: 128.3499\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 14.3553 - val_loss: 123.1117\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 690us/step - loss: 13.5118 - val_loss: 118.2793\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 12.7654 - val_loss: 113.4118\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 614us/step - loss: 11.8467 - val_loss: 108.5333\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 662us/step - loss: 11.0545 - val_loss: 103.4921\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 10.3661 - val_loss: 98.8286\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 625us/step - loss: 9.6507 - val_loss: 94.4688\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 9.0318 - val_loss: 90.7038\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 527us/step - loss: 8.4525 - val_loss: 87.2118\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 7.9146 - val_loss: 83.5412\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 7.4514 - val_loss: 80.2614\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 7.0402 - val_loss: 77.3549\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 6.6391 - val_loss: 74.7723\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 6.3390 - val_loss: 72.2425\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 651us/step - loss: 5.9707 - val_loss: 70.0280\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 5.6947 - val_loss: 67.9533\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 5.4577 - val_loss: 65.9501\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 5.2199 - val_loss: 64.0541\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 4.9762 - val_loss: 62.3156\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 4.7425 - val_loss: 60.6801\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 4.5653 - val_loss: 58.8870\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 4.3620 - val_loss: 57.2930\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 4.2017 - val_loss: 55.8267\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 4.0205 - val_loss: 54.5586\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 3.8926 - val_loss: 53.1933\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 3.7422 - val_loss: 51.5308\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 3.5796 - val_loss: 49.9018\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 3.4263 - val_loss: 48.2595\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 3.2610 - val_loss: 46.9133\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 3.1683 - val_loss: 45.6683\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 3.0516 - val_loss: 44.6395\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 2.9637 - val_loss: 43.7254\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 2.8987 - val_loss: 42.8841\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 2.8239 - val_loss: 42.1591\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 2.7685 - val_loss: 41.4611\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 2.7152 - val_loss: 40.7906\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 2.6494 - val_loss: 40.1454\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 2.6073 - val_loss: 39.3278\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 2.5396 - val_loss: 38.5788\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 2.4989 - val_loss: 37.8927\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 2.4491 - val_loss: 37.3056\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 2.4128 - val_loss: 36.7504\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 2.3880 - val_loss: 36.1808\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 2.3406 - val_loss: 35.7624\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 2.3104 - val_loss: 35.3177\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 659us/step - loss: 2.2797 - val_loss: 34.5838\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 2.2368 - val_loss: 33.8153\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 670us/step - loss: 2.2005 - val_loss: 33.0317\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 2.1597 - val_loss: 32.4704\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 529us/step - loss: 2.1345 - val_loss: 32.0436\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 631us/step - loss: 2.1133 - val_loss: 31.7196\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 2.0979 - val_loss: 31.3746\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 2.0847 - val_loss: 30.9642\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.0641 - val_loss: 30.6465\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 2.0494 - val_loss: 30.3172\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 2.0393 - val_loss: 29.9966\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 2.0232 - val_loss: 29.7274\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 2.0089 - val_loss: 29.3384\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.9973 - val_loss: 28.9824\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.9902 - val_loss: 28.6841\n",
      "Epoch 298/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 554us/step - loss: 1.9767 - val_loss: 28.4022\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.9650 - val_loss: 28.1437\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.9572 - val_loss: 27.9092\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.9497 - val_loss: 27.7171\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.9433 - val_loss: 27.5884\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.9392 - val_loss: 27.4433\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.9389 - val_loss: 27.0720\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.9236 - val_loss: 26.8660\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.9196 - val_loss: 26.7313\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.9163 - val_loss: 26.6281\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.9120 - val_loss: 26.4569\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.9074 - val_loss: 26.0541\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 1.8933 - val_loss: 25.6622\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.8902 - val_loss: 25.3364\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.8842 - val_loss: 25.1036\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8815 - val_loss: 24.9456\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.8814 - val_loss: 24.8323\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.8778 - val_loss: 24.7990\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.8769 - val_loss: 24.5843\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.8697 - val_loss: 24.3379\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.8707 - val_loss: 24.1231\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8665 - val_loss: 24.0306\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.8645 - val_loss: 23.8475\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.8611 - val_loss: 23.5434\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.8606 - val_loss: 23.2768\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.8569 - val_loss: 23.0032\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.8615 - val_loss: 22.7573\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.8570 - val_loss: 22.6029\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.8570 - val_loss: 22.5167\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.8564 - val_loss: 22.5234\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.8552 - val_loss: 22.5741\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.8554 - val_loss: 22.5349\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8547 - val_loss: 22.5461\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.8543 - val_loss: 22.5444\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.8544 - val_loss: 22.5525\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 650us/step - loss: 1.8539 - val_loss: 22.5351\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.8546 - val_loss: 22.5264\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 626us/step - loss: 1.8530 - val_loss: 22.5883\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.8532 - val_loss: 22.6301\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.8533 - val_loss: 22.6443\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 651us/step - loss: 1.8530 - val_loss: 22.5961\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.8545 - val_loss: 22.5376\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.8522 - val_loss: 22.5572\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.8525 - val_loss: 22.5684\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.8516 - val_loss: 22.5864\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.8509 - val_loss: 22.6552\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.8509 - val_loss: 22.7187\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.8520 - val_loss: 22.8365\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.8513 - val_loss: 22.8810\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 1.8509 - val_loss: 22.8744\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.8507 - val_loss: 22.8385\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.8499 - val_loss: 22.7709\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.8506 - val_loss: 22.7048\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.8509 - val_loss: 22.7129\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.8474 - val_loss: 22.5192\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.8459 - val_loss: 22.3289\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.8490 - val_loss: 22.0657\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.8460 - val_loss: 21.8854\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.8496 - val_loss: 21.7702\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.8482 - val_loss: 21.8018\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.8485 - val_loss: 21.8979\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.8488 - val_loss: 21.9704\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.8470 - val_loss: 22.0152\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.8457 - val_loss: 22.0912\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.8455 - val_loss: 22.1390\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.8456 - val_loss: 22.2430\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.8481 - val_loss: 22.3731\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.8443 - val_loss: 22.4233\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.8434 - val_loss: 22.5254\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.8440 - val_loss: 22.5826\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.8439 - val_loss: 22.5004\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.8440 - val_loss: 22.4284\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.8429 - val_loss: 22.4476\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.8423 - val_loss: 22.4686\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.8418 - val_loss: 22.5183\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.8414 - val_loss: 22.6380\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.8417 - val_loss: 22.7563\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.8414 - val_loss: 22.8218\n",
      "Epoch 376/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 555us/step - loss: 1.8425 - val_loss: 22.8970\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.8430 - val_loss: 22.9784\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.8422 - val_loss: 23.0404\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.8415 - val_loss: 23.1362\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.8441 - val_loss: 23.1721\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.8439 - val_loss: 22.9536\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.8395 - val_loss: 22.8275\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.8412 - val_loss: 22.7285\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 658us/step - loss: 1.8406 - val_loss: 22.6343\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.8391 - val_loss: 22.6335\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.8392 - val_loss: 22.6711\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.8381 - val_loss: 22.6316\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 1.8376 - val_loss: 22.5921\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.8372 - val_loss: 22.5668\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.8378 - val_loss: 22.6280\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.8366 - val_loss: 22.6127\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.8355 - val_loss: 22.6913\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.8350 - val_loss: 22.8003\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8366 - val_loss: 22.8719\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.8364 - val_loss: 22.8650\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.8356 - val_loss: 22.8636\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.8356 - val_loss: 22.8909\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.8352 - val_loss: 22.8738\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.8350 - val_loss: 22.8137\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.8344 - val_loss: 22.8451\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 1.8339 - val_loss: 22.8577\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.8343 - val_loss: 22.8790\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.8336 - val_loss: 22.8789\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.8334 - val_loss: 22.8224\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.8321 - val_loss: 22.5768\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.8313 - val_loss: 22.4122\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.8306 - val_loss: 22.3674\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8306 - val_loss: 22.3873\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.8300 - val_loss: 22.4006\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.8297 - val_loss: 22.4685\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.8288 - val_loss: 22.5182\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.8299 - val_loss: 22.6035\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.8306 - val_loss: 22.6462\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.8276 - val_loss: 22.5331\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.8288 - val_loss: 22.4297\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.8272 - val_loss: 22.4618\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.8268 - val_loss: 22.5113\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.8272 - val_loss: 22.5384\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8266 - val_loss: 22.6587\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.8271 - val_loss: 22.7630\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.8265 - val_loss: 22.6919\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 528us/step - loss: 1.8255 - val_loss: 22.6193\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 630us/step - loss: 1.8249 - val_loss: 22.5185\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.8267 - val_loss: 22.4367\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.8248 - val_loss: 22.4293\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 1.8238 - val_loss: 22.4879\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.8255 - val_loss: 22.5772\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.8228 - val_loss: 22.6510\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.8233 - val_loss: 22.6995\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.8230 - val_loss: 22.7246\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.8224 - val_loss: 22.7987\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8227 - val_loss: 22.8247\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.8237 - val_loss: 22.8492\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.8226 - val_loss: 22.8008\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.8219 - val_loss: 22.7666\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.8212 - val_loss: 22.8339\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.8228 - val_loss: 22.8878\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.8209 - val_loss: 22.8085\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.8209 - val_loss: 22.8563\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.8202 - val_loss: 22.9635\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.8203 - val_loss: 23.0805\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.8209 - val_loss: 23.1924\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.8225 - val_loss: 23.2291\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.8201 - val_loss: 23.0918\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.8183 - val_loss: 22.9451\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.8214 - val_loss: 22.6048\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.8112 - val_loss: 22.2380\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 1.8171 - val_loss: 21.7826\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.8153 - val_loss: 21.5687\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.8173 - val_loss: 21.3960\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.8179 - val_loss: 21.2751\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8185 - val_loss: 21.2296\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.8160 - val_loss: 21.2868\n",
      "Epoch 454/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 561us/step - loss: 1.8159 - val_loss: 21.3211\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.8145 - val_loss: 21.4282\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.8136 - val_loss: 21.5980\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.8164 - val_loss: 21.7845\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.8121 - val_loss: 21.7805\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.8117 - val_loss: 21.7553\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.8117 - val_loss: 21.7249\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.8108 - val_loss: 21.7751\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.8103 - val_loss: 21.8288\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.8101 - val_loss: 21.9830\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.8119 - val_loss: 22.1260\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 621us/step - loss: 1.8090 - val_loss: 22.1918\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.8095 - val_loss: 22.3168\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.8088 - val_loss: 22.4473\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.8080 - val_loss: 22.5624\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.8089 - val_loss: 22.5858\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.8108 - val_loss: 22.6039\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.8039 - val_loss: 22.3159\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.8009 - val_loss: 21.8934\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.8025 - val_loss: 21.5873\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 1.8096 - val_loss: 21.3518\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.8069 - val_loss: 21.3641\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.8064 - val_loss: 21.4358\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.8064 - val_loss: 21.4413\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.8050 - val_loss: 21.5226\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.8042 - val_loss: 21.5262\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.8041 - val_loss: 21.4338\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.8048 - val_loss: 21.2901\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.8034 - val_loss: 21.3206\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.8056 - val_loss: 21.3923\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.8031 - val_loss: 21.1990\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.8024 - val_loss: 21.1103\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.8027 - val_loss: 21.1257\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.8032 - val_loss: 21.0946\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.8021 - val_loss: 20.8700\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.8027 - val_loss: 20.8195\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.8033 - val_loss: 20.8943\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.8018 - val_loss: 21.0416\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.7998 - val_loss: 21.1112\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.8012 - val_loss: 21.2586\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.7981 - val_loss: 21.3229\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.7967 - val_loss: 21.4470\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.7961 - val_loss: 21.5860\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.7933 - val_loss: 21.7703\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.7934 - val_loss: 21.9452\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.7938 - val_loss: 22.0103\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.7958 - val_loss: 22.0026\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.7893 - val_loss: 21.6947\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.7876 - val_loss: 21.2661\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.7978 - val_loss: 20.9332\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.7981 - val_loss: 20.7827\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 640us/step - loss: 1.7956 - val_loss: 20.8089\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.7968 - val_loss: 20.9558\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 627us/step - loss: 1.7954 - val_loss: 21.0959\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.7924 - val_loss: 21.2283\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.7914 - val_loss: 21.3106\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.7897 - val_loss: 21.3678\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.7895 - val_loss: 21.4381\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.7896 - val_loss: 21.5579\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.7895 - val_loss: 21.4790\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.7878 - val_loss: 21.4596\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.7884 - val_loss: 21.4106\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.7875 - val_loss: 21.4496\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.7880 - val_loss: 21.4988\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 1.7873 - val_loss: 21.3731\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.7865 - val_loss: 21.2534\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.7838 - val_loss: 20.9626\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.7873 - val_loss: 20.7322\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.7878 - val_loss: 20.6270\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 614us/step - loss: 1.7904 - val_loss: 20.5993\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.7867 - val_loss: 20.3682\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.7905 - val_loss: 20.2495\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.7914 - val_loss: 20.3012\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.7893 - val_loss: 20.3627\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.7886 - val_loss: 20.4541\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.7878 - val_loss: 20.5312\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.7863 - val_loss: 20.6206\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.7852 - val_loss: 20.7895\n",
      "Epoch 532/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 596us/step - loss: 1.7827 - val_loss: 20.8986\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.7834 - val_loss: 20.9715\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.7860 - val_loss: 20.8560\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.7814 - val_loss: 20.9118\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.7785 - val_loss: 21.1071\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.7770 - val_loss: 21.3701\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.7783 - val_loss: 21.5855\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.7800 - val_loss: 21.7623\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.7750 - val_loss: 21.9461\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.7743 - val_loss: 22.1522\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.7807 - val_loss: 22.4279\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.7774 - val_loss: 22.4763\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.7832 - val_loss: 22.2751\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.7749 - val_loss: 22.2006\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 1.7742 - val_loss: 22.0992\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.7738 - val_loss: 22.0529\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.7743 - val_loss: 21.9333\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.7725 - val_loss: 21.8489\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.7716 - val_loss: 21.7989\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.7717 - val_loss: 21.7565\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.7733 - val_loss: 21.6230\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.7710 - val_loss: 21.6341\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.7704 - val_loss: 21.5618\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.7698 - val_loss: 21.5082\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.7696 - val_loss: 21.4829\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.7689 - val_loss: 21.4881\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.7689 - val_loss: 21.4574\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.7691 - val_loss: 21.4303\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.7689 - val_loss: 21.4798\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.7673 - val_loss: 21.3356\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 1.7661 - val_loss: 21.2000\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.7642 - val_loss: 20.9880\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.7657 - val_loss: 20.8219\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.7670 - val_loss: 20.6964\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.7687 - val_loss: 20.6183\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 1.7687 - val_loss: 20.6301\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.7670 - val_loss: 20.7978\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.7636 - val_loss: 20.9953\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.7676 - val_loss: 21.3045\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 1.7672 - val_loss: 21.6099\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 619us/step - loss: 1.7625 - val_loss: 21.7686\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 634us/step - loss: 1.7607 - val_loss: 21.9532\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.7613 - val_loss: 22.0636\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.7619 - val_loss: 22.0621\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 1.7614 - val_loss: 22.1092\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 1.7603 - val_loss: 22.1367\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.7626 - val_loss: 22.1771\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.7580 - val_loss: 21.8902\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 1.7650 - val_loss: 21.6286\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.7580 - val_loss: 21.6312\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 528us/step - loss: 1.7592 - val_loss: 21.7796\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.7587 - val_loss: 21.7893\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.7566 - val_loss: 21.9549\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.7564 - val_loss: 21.9801\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.7583 - val_loss: 21.7702\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.7538 - val_loss: 21.6249\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.7543 - val_loss: 21.3605\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.7537 - val_loss: 21.3112\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.7551 - val_loss: 21.2380\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.7533 - val_loss: 21.1415\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 656us/step - loss: 1.7588 - val_loss: 20.7593\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.7571 - val_loss: 20.5616\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.7567 - val_loss: 20.5325\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.7544 - val_loss: 20.2847\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.7556 - val_loss: 20.2224\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.7565 - val_loss: 20.1923\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.7547 - val_loss: 20.3447\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.7563 - val_loss: 20.5939\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.7506 - val_loss: 20.7599\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.7500 - val_loss: 21.0410\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.7545 - val_loss: 21.2902\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.7475 - val_loss: 21.1927\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 512us/step - loss: 1.7499 - val_loss: 21.0794\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.7462 - val_loss: 21.1421\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.7453 - val_loss: 21.1875\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 1.7443 - val_loss: 21.3820\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.7405 - val_loss: 21.5725\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.7461 - val_loss: 21.7433\n",
      "Epoch 610/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 572us/step - loss: 1.7428 - val_loss: 21.6573\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.7419 - val_loss: 21.3409\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 1.7409 - val_loss: 21.3100\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.7422 - val_loss: 21.4043\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 1.7411 - val_loss: 21.4769\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.7389 - val_loss: 21.5804\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 507us/step - loss: 1.7390 - val_loss: 21.7021\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 515us/step - loss: 1.7384 - val_loss: 21.7884\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 514us/step - loss: 1.7413 - val_loss: 21.9238\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.7391 - val_loss: 22.0283\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 526us/step - loss: 1.7388 - val_loss: 22.0466\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 1.7380 - val_loss: 21.9279\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 521us/step - loss: 1.7445 - val_loss: 21.4961\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 1.7337 - val_loss: 21.3001\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 1.7381 - val_loss: 20.9319\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.7370 - val_loss: 20.7028\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.7352 - val_loss: 20.7199\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.7359 - val_loss: 20.7722\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.7337 - val_loss: 20.7452\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 1.7342 - val_loss: 20.6795\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 1.7349 - val_loss: 20.7210\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.7325 - val_loss: 20.7539\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.7335 - val_loss: 20.8392\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 528us/step - loss: 1.7366 - val_loss: 20.6996\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 521us/step - loss: 1.7319 - val_loss: 20.7072\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.7276 - val_loss: 20.4609\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 1.7293 - val_loss: 20.1198\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.7316 - val_loss: 19.8713\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.7318 - val_loss: 19.4669\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.7419 - val_loss: 19.2582\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.7431 - val_loss: 19.2841\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 1.7408 - val_loss: 19.4974\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 1.7378 - val_loss: 19.5518\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.7353 - val_loss: 19.5867\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.7343 - val_loss: 19.6593\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.7302 - val_loss: 19.9088\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.7300 - val_loss: 20.2480\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.7242 - val_loss: 20.4010\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.7230 - val_loss: 20.5811\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.7206 - val_loss: 20.8716\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 518us/step - loss: 1.7264 - val_loss: 21.1895\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.7199 - val_loss: 21.3627\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.7194 - val_loss: 21.6037\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.7243 - val_loss: 21.9399\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.7222 - val_loss: 22.1758\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.7206 - val_loss: 22.2381\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.7205 - val_loss: 22.2718\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.7207 - val_loss: 22.2967\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.7200 - val_loss: 22.4011\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.7250 - val_loss: 22.3872\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.7180 - val_loss: 21.9841\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.7201 - val_loss: 21.7479\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.7157 - val_loss: 21.7457\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.7191 - val_loss: 21.9314\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.7150 - val_loss: 22.0203\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.7151 - val_loss: 22.0629\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.7150 - val_loss: 22.2306\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.7223 - val_loss: 22.4136\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.7154 - val_loss: 22.2454\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.7139 - val_loss: 22.1042\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.7129 - val_loss: 22.0445\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.7100 - val_loss: 21.7767\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.7094 - val_loss: 21.6115\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.7088 - val_loss: 21.6125\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 621us/step - loss: 1.7091 - val_loss: 21.5354\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.7075 - val_loss: 21.5283\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.7075 - val_loss: 21.6007\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.7055 - val_loss: 21.6685\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.7059 - val_loss: 21.7107\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.7058 - val_loss: 21.7638\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 614us/step - loss: 1.7062 - val_loss: 21.8080\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.7046 - val_loss: 21.8058\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.7062 - val_loss: 21.8504\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.7040 - val_loss: 21.8436\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.7092 - val_loss: 21.8865\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.7056 - val_loss: 21.4699\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.7015 - val_loss: 21.2436\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.6996 - val_loss: 21.1902\n",
      "Epoch 688/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 575us/step - loss: 1.7018 - val_loss: 21.2791\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 691us/step - loss: 1.7001 - val_loss: 21.3237\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 1.6988 - val_loss: 21.2636\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 1.6975 - val_loss: 21.1227\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.6986 - val_loss: 20.6502\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.6981 - val_loss: 20.3765\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 1.7005 - val_loss: 20.3383\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.6951 - val_loss: 20.5549\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.6958 - val_loss: 20.7834\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.6915 - val_loss: 21.0162\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.6933 - val_loss: 21.3451\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.6920 - val_loss: 21.5141\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.6948 - val_loss: 21.6622\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.6941 - val_loss: 21.6786\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.6939 - val_loss: 21.6644\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.6924 - val_loss: 21.8225\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.6955 - val_loss: 21.9154\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.6971 - val_loss: 21.5437\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 1.6911 - val_loss: 21.3583\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.6892 - val_loss: 21.3606\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.6875 - val_loss: 21.2485\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.6868 - val_loss: 21.0139\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.6885 - val_loss: 20.7787\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.6857 - val_loss: 20.7470\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.6866 - val_loss: 20.7827\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 1.6841 - val_loss: 20.9091\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 528us/step - loss: 1.6813 - val_loss: 21.1055\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.6829 - val_loss: 21.3531\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.6876 - val_loss: 21.4877\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.6921 - val_loss: 21.2368\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.6839 - val_loss: 21.1735\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.6816 - val_loss: 21.1972\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.6816 - val_loss: 21.2939\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.6827 - val_loss: 21.5862\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 1.6837 - val_loss: 21.8675\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 627us/step - loss: 1.6858 - val_loss: 22.0931\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.6862 - val_loss: 22.1342\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.6856 - val_loss: 22.1681\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.6859 - val_loss: 22.1206\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.6958 - val_loss: 21.7304\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.6811 - val_loss: 21.4986\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.6794 - val_loss: 21.2870\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.6775 - val_loss: 21.0239\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.6793 - val_loss: 20.8102\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 1.6752 - val_loss: 20.7608\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 520us/step - loss: 1.6824 - val_loss: 20.3071\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.6721 - val_loss: 20.1709\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.6729 - val_loss: 20.2422\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.6712 - val_loss: 20.4241\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 519us/step - loss: 1.6730 - val_loss: 20.5570\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.6697 - val_loss: 20.5896\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.6691 - val_loss: 20.5831\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.6717 - val_loss: 20.4203\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 529us/step - loss: 1.6682 - val_loss: 20.3760\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.6671 - val_loss: 20.4603\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.6668 - val_loss: 20.5606\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.6685 - val_loss: 20.9059\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.6650 - val_loss: 21.1117\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 528us/step - loss: 1.6661 - val_loss: 20.9819\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.6656 - val_loss: 20.7054\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.6652 - val_loss: 20.6751\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.6647 - val_loss: 20.9293\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 1.6686 - val_loss: 21.2413\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.6636 - val_loss: 21.3020\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.6657 - val_loss: 21.4456\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 510us/step - loss: 1.6636 - val_loss: 21.4097\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 522us/step - loss: 1.6634 - val_loss: 21.3938\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.6646 - val_loss: 21.5591\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.6641 - val_loss: 21.5518\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 625us/step - loss: 1.6635 - val_loss: 21.2769\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.6595 - val_loss: 21.0928\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.6596 - val_loss: 20.5489\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.6549 - val_loss: 20.3757\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.6557 - val_loss: 20.3362\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.6544 - val_loss: 20.2993\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.6536 - val_loss: 20.2907\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.6537 - val_loss: 20.2926\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 1.6581 - val_loss: 20.3560\n",
      "Epoch 766/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 565us/step - loss: 1.6499 - val_loss: 19.9949\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.6562 - val_loss: 19.7663\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.6511 - val_loss: 19.8620\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.6477 - val_loss: 20.1273\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.6504 - val_loss: 20.4644\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.6496 - val_loss: 20.4338\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.6483 - val_loss: 20.5539\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.6474 - val_loss: 20.5937\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.6456 - val_loss: 20.8253\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 614us/step - loss: 1.6441 - val_loss: 21.1409\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.6511 - val_loss: 21.3757\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.6450 - val_loss: 21.0037\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.6462 - val_loss: 20.3368\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 1.6412 - val_loss: 19.9232\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.6408 - val_loss: 19.1774\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.6425 - val_loss: 18.4381\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 1.6586 - val_loss: 18.1036\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.6559 - val_loss: 18.1491\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.6532 - val_loss: 18.3236\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.6491 - val_loss: 18.5222\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.6508 - val_loss: 18.9125\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.6402 - val_loss: 19.0671\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.6377 - val_loss: 19.2513\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.6400 - val_loss: 19.5709\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.6341 - val_loss: 19.7265\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.6340 - val_loss: 19.8573\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 625us/step - loss: 1.6347 - val_loss: 19.8980\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.6311 - val_loss: 20.1930\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.6303 - val_loss: 20.5156\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.6408 - val_loss: 20.8324\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.6324 - val_loss: 20.9504\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.6355 - val_loss: 21.0486\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.6324 - val_loss: 20.9692\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.6312 - val_loss: 20.8601\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.6311 - val_loss: 20.6886\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.6299 - val_loss: 20.0571\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.6232 - val_loss: 19.5408\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.6210 - val_loss: 18.8332\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.6252 - val_loss: 18.3779\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.6427 - val_loss: 18.1061\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.6374 - val_loss: 18.2162\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.6357 - val_loss: 18.6127\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 1.6337 - val_loss: 19.0140\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 754us/step - loss: 1.6272 - val_loss: 19.1766\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 1.6292 - val_loss: 18.9951\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 650us/step - loss: 1.6250 - val_loss: 18.9571\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 637us/step - loss: 1.6245 - val_loss: 19.0267\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 652us/step - loss: 1.6178 - val_loss: 19.3282\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 644us/step - loss: 1.6175 - val_loss: 19.6942\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 654us/step - loss: 1.6178 - val_loss: 19.7199\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 710us/step - loss: 1.6174 - val_loss: 19.6743\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 646us/step - loss: 1.6173 - val_loss: 19.6448\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 686us/step - loss: 1.6209 - val_loss: 19.2438\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.6206 - val_loss: 18.8378\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 674us/step - loss: 1.6197 - val_loss: 18.7617\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 736us/step - loss: 1.6179 - val_loss: 18.9192\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 752us/step - loss: 1.6166 - val_loss: 19.0280\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 683us/step - loss: 1.6150 - val_loss: 19.0626\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.6149 - val_loss: 19.3414\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.6120 - val_loss: 19.5580\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 681us/step - loss: 1.6096 - val_loss: 19.6548\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 636us/step - loss: 1.6112 - val_loss: 19.6665\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.6153 - val_loss: 19.9123\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.6103 - val_loss: 20.0295\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.6082 - val_loss: 19.9718\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.6069 - val_loss: 19.9455\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.6066 - val_loss: 20.0162\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.6059 - val_loss: 20.1810\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 1.6053 - val_loss: 20.2226\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 1.6030 - val_loss: 20.3956\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 680us/step - loss: 1.6143 - val_loss: 20.7274\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 679us/step - loss: 1.6059 - val_loss: 20.8301\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 704us/step - loss: 1.6088 - val_loss: 21.0003\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 1.6075 - val_loss: 20.9092\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.6078 - val_loss: 20.9445\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 722us/step - loss: 1.6041 - val_loss: 20.8771\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 692us/step - loss: 1.6038 - val_loss: 20.8612\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 643us/step - loss: 1.6042 - val_loss: 20.9475\n",
      "Epoch 844/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 731us/step - loss: 1.6030 - val_loss: 21.1475\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 1.6029 - val_loss: 21.3918\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.6080 - val_loss: 21.2910\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 641us/step - loss: 1.5981 - val_loss: 20.6683\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.5953 - val_loss: 20.2048\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.5941 - val_loss: 19.9924\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.5946 - val_loss: 19.7170\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 664us/step - loss: 1.5919 - val_loss: 19.3949\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 749us/step - loss: 1.5860 - val_loss: 18.8824\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 1.5922 - val_loss: 18.1069\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 653us/step - loss: 1.6150 - val_loss: 17.5770\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.6081 - val_loss: 17.6306\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 624us/step - loss: 1.6053 - val_loss: 17.7935\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.5995 - val_loss: 18.2023\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.5961 - val_loss: 18.5662\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.5877 - val_loss: 19.0328\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.5831 - val_loss: 19.4263\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.5892 - val_loss: 19.6783\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.5835 - val_loss: 19.7794\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.5833 - val_loss: 20.0338\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.5821 - val_loss: 20.1072\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.5848 - val_loss: 20.2635\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.5831 - val_loss: 20.2644\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.5806 - val_loss: 20.1096\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.5803 - val_loss: 19.9723\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.5816 - val_loss: 19.5021\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 1.5819 - val_loss: 19.2070\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.5770 - val_loss: 19.1060\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.5781 - val_loss: 19.0116\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.5771 - val_loss: 18.9781\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.5749 - val_loss: 18.7776\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.5779 - val_loss: 18.5169\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.5820 - val_loss: 18.1125\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.5861 - val_loss: 17.7985\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.5835 - val_loss: 17.7503\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.5835 - val_loss: 17.8455\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.5816 - val_loss: 18.1531\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.5749 - val_loss: 18.4250\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 652us/step - loss: 1.5713 - val_loss: 18.8258\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.5670 - val_loss: 19.1388\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.5656 - val_loss: 19.3355\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 636us/step - loss: 1.5652 - val_loss: 19.5197\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 641us/step - loss: 1.5663 - val_loss: 19.4958\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.5699 - val_loss: 19.0574\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.5657 - val_loss: 18.5550\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 1.5645 - val_loss: 18.0747\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.5641 - val_loss: 17.4784\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 1.5772 - val_loss: 17.1015\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.5814 - val_loss: 16.4711\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.5994 - val_loss: 15.8751\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.6105 - val_loss: 15.8317\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.6091 - val_loss: 15.9881\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.6033 - val_loss: 16.2185\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.5930 - val_loss: 16.5994\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.5757 - val_loss: 17.0742\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.5719 - val_loss: 17.5769\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 1.5666 - val_loss: 18.0799\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.5584 - val_loss: 18.3765\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.5650 - val_loss: 18.6261\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.5552 - val_loss: 18.5088\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.5534 - val_loss: 18.6370\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 652us/step - loss: 1.5535 - val_loss: 18.6260\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.5552 - val_loss: 18.8514\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 627us/step - loss: 1.5495 - val_loss: 18.9351\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 632us/step - loss: 1.5475 - val_loss: 19.1780\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.5448 - val_loss: 19.5817\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.5516 - val_loss: 20.0031\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.5503 - val_loss: 19.9407\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.5485 - val_loss: 20.0040\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 655us/step - loss: 1.5498 - val_loss: 20.0722\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 627us/step - loss: 1.5485 - val_loss: 20.1024\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 621us/step - loss: 1.5491 - val_loss: 20.2276\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 1.5521 - val_loss: 20.3621\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.5495 - val_loss: 20.2684\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.5479 - val_loss: 20.2467\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.5459 - val_loss: 20.3086\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 621us/step - loss: 1.5493 - val_loss: 20.2588\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 625us/step - loss: 1.5467 - val_loss: 20.2457\n",
      "Epoch 922/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 614us/step - loss: 1.5403 - val_loss: 19.6994\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 630us/step - loss: 1.5462 - val_loss: 19.2941\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 1.5372 - val_loss: 19.2473\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.5363 - val_loss: 19.1822\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.5363 - val_loss: 18.9873\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.5353 - val_loss: 18.7568\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.5342 - val_loss: 18.5808\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.5338 - val_loss: 18.5312\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.5336 - val_loss: 18.4535\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.5316 - val_loss: 18.6307\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 1.5389 - val_loss: 19.1201\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.5315 - val_loss: 19.3460\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 626us/step - loss: 1.5291 - val_loss: 19.3799\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 614us/step - loss: 1.5292 - val_loss: 19.4815\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.5288 - val_loss: 19.7047\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 627us/step - loss: 1.5281 - val_loss: 19.8425\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.5330 - val_loss: 20.2083\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.5313 - val_loss: 20.3673\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 719us/step - loss: 1.5312 - val_loss: 20.5445\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.5382 - val_loss: 20.4698\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.5293 - val_loss: 19.7073\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 631us/step - loss: 1.5227 - val_loss: 19.1553\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.5212 - val_loss: 18.7600\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.5295 - val_loss: 18.3974\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 655us/step - loss: 1.5215 - val_loss: 18.4632\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.5191 - val_loss: 18.3498\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 1.5211 - val_loss: 17.8845\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 637us/step - loss: 1.5275 - val_loss: 17.2235\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.5274 - val_loss: 17.1473\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 1.5271 - val_loss: 17.0849\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.5275 - val_loss: 17.1446\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.5253 - val_loss: 17.4755\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 610us/step - loss: 1.5233 - val_loss: 17.8907\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.5173 - val_loss: 18.1751\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 640us/step - loss: 1.5155 - val_loss: 18.5823\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 643us/step - loss: 1.5114 - val_loss: 18.8738\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.5085 - val_loss: 19.1320\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 635us/step - loss: 1.5080 - val_loss: 19.3557\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 645us/step - loss: 1.5091 - val_loss: 19.3262\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.5115 - val_loss: 18.9821\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.5052 - val_loss: 18.9804\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.5047 - val_loss: 18.8192\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.5059 - val_loss: 18.7108\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.5024 - val_loss: 18.8695\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.5070 - val_loss: 18.9036\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.5103 - val_loss: 18.2886\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.5048 - val_loss: 18.0478\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.5017 - val_loss: 18.1692\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.5015 - val_loss: 18.3202\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 1.4979 - val_loss: 18.5149\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.5056 - val_loss: 19.0875\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 1.4967 - val_loss: 19.6416\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.4970 - val_loss: 20.1221\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 1.5018 - val_loss: 20.2583\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.5106 - val_loss: 20.3803\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 712us/step - loss: 1.5031 - val_loss: 20.2081\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 673us/step - loss: 1.4987 - val_loss: 19.8572\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.5024 - val_loss: 19.5414\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 707us/step - loss: 1.4941 - val_loss: 19.4926\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.4954 - val_loss: 19.6225\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 685us/step - loss: 1.4935 - val_loss: 19.6034\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 688us/step - loss: 1.4916 - val_loss: 19.7006\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.4930 - val_loss: 19.5952\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.4897 - val_loss: 19.2738\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 1.4874 - val_loss: 19.2022\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.4873 - val_loss: 19.1287\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 626us/step - loss: 1.4932 - val_loss: 19.2687\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.4877 - val_loss: 19.1830\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 1.4851 - val_loss: 19.2756\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.4889 - val_loss: 18.9595\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.4814 - val_loss: 18.9591\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.4803 - val_loss: 18.9555\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.4802 - val_loss: 19.0905\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.4824 - val_loss: 19.2574\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.4801 - val_loss: 19.3962\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.4809 - val_loss: 19.6949\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 1.4799 - val_loss: 19.9297\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 702us/step - loss: 1.4901 - val_loss: 20.1120\n",
      "Epoch 1000/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 629us/step - loss: 1.4839 - val_loss: 19.9141\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 1.4780 - val_loss: 19.5894\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 658us/step - loss: 1.4783 - val_loss: 18.9667\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.4726 - val_loss: 18.7310\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 630us/step - loss: 1.4712 - val_loss: 18.5216\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.4761 - val_loss: 18.3182\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.4698 - val_loss: 18.2932\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.4704 - val_loss: 18.1832\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.4670 - val_loss: 18.3341\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.4665 - val_loss: 18.4923\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 626us/step - loss: 1.4618 - val_loss: 18.8242\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.4636 - val_loss: 18.9988\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 667us/step - loss: 1.4638 - val_loss: 19.1253\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.4668 - val_loss: 19.3647\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.4652 - val_loss: 19.5989\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.4679 - val_loss: 19.5562\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.4580 - val_loss: 18.8784\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.4604 - val_loss: 18.3127\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.4563 - val_loss: 18.0192\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.4586 - val_loss: 17.9638\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 1.4556 - val_loss: 18.1172\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.4585 - val_loss: 18.4699\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.4521 - val_loss: 18.8524\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.4530 - val_loss: 19.0863\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.4539 - val_loss: 19.4506\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 1.4718 - val_loss: 19.8514\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.4585 - val_loss: 19.5678\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.4555 - val_loss: 19.4470\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.4537 - val_loss: 19.5884\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.4524 - val_loss: 19.8218\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.4620 - val_loss: 20.1083\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 1.4597 - val_loss: 19.9285\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 1.4553 - val_loss: 19.9145\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.4558 - val_loss: 20.0806\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.4559 - val_loss: 19.9388\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 1.4432 - val_loss: 19.2926\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 1.4618 - val_loss: 18.2876\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.4372 - val_loss: 17.7600\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 634us/step - loss: 1.4358 - val_loss: 17.3235\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.4432 - val_loss: 16.6784\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.4616 - val_loss: 16.2705\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 1.4540 - val_loss: 16.5418\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.4440 - val_loss: 16.8602\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.4443 - val_loss: 17.2740\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.4389 - val_loss: 17.5352\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.4338 - val_loss: 17.6985\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.4323 - val_loss: 18.0341\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.4329 - val_loss: 18.3077\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.4332 - val_loss: 18.2254\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.4210 - val_loss: 17.5853\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.4287 - val_loss: 17.0572\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.4294 - val_loss: 16.7080\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.4354 - val_loss: 16.4698\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.4378 - val_loss: 16.5216\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.4357 - val_loss: 16.7777\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 1.4324 - val_loss: 16.7747\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.4371 - val_loss: 17.1851\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.4247 - val_loss: 17.2523\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.4228 - val_loss: 17.3607\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.4201 - val_loss: 17.8061\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.4175 - val_loss: 18.4037\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 1.4277 - val_loss: 19.0190\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.4192 - val_loss: 19.2987\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.4210 - val_loss: 19.4323\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 1.4249 - val_loss: 19.5175\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 1.4222 - val_loss: 19.4385\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.4207 - val_loss: 19.4338\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.4196 - val_loss: 19.4782\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.4197 - val_loss: 19.5411\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.4204 - val_loss: 19.5172\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.4232 - val_loss: 19.6379\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.4227 - val_loss: 19.6039\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 1.4194 - val_loss: 19.3112\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 1.4168 - val_loss: 18.3456\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 679us/step - loss: 1.4028 - val_loss: 17.4309\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 659us/step - loss: 1.4037 - val_loss: 16.9156\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 630us/step - loss: 1.4061 - val_loss: 16.3846\n",
      "Epoch 1077/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 620us/step - loss: 1.4332 - val_loss: 15.5825\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.4323 - val_loss: 15.4394\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 648us/step - loss: 1.4308 - val_loss: 15.4933\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 769us/step - loss: 1.4245 - val_loss: 15.9721\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.4102 - val_loss: 16.4972\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.3985 - val_loss: 17.2307\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 1.3916 - val_loss: 17.8267\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.3990 - val_loss: 17.9971\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 1.3974 - val_loss: 17.4707\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.4006 - val_loss: 17.0220\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.3958 - val_loss: 16.7256\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.4020 - val_loss: 16.4673\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.4033 - val_loss: 16.3674\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.3998 - val_loss: 16.6520\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.3962 - val_loss: 16.7900\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 1.3952 - val_loss: 16.9433\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.3913 - val_loss: 17.0509\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 522us/step - loss: 1.3907 - val_loss: 17.4439\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.3843 - val_loss: 17.6691\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 526us/step - loss: 1.3834 - val_loss: 17.8109\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.3836 - val_loss: 17.9279\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 1.3906 - val_loss: 18.1541\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.3807 - val_loss: 17.4608\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 1.3787 - val_loss: 16.8092\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.3840 - val_loss: 16.6061\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.3841 - val_loss: 16.4803\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.3843 - val_loss: 16.4715\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.3844 - val_loss: 16.5560\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.3832 - val_loss: 17.0211\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.3845 - val_loss: 17.3647\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.3742 - val_loss: 17.3458\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.3740 - val_loss: 17.3799\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.3733 - val_loss: 17.4568\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 1.3746 - val_loss: 17.5049\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.3760 - val_loss: 17.6464\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 1.3700 - val_loss: 17.6238\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.3652 - val_loss: 17.2298\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.3678 - val_loss: 16.6980\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.3715 - val_loss: 16.6471\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 512us/step - loss: 1.3706 - val_loss: 16.6828\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 1.3688 - val_loss: 17.0883\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.3658 - val_loss: 17.4042\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 521us/step - loss: 1.3692 - val_loss: 17.7667\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.3612 - val_loss: 17.7611\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.3629 - val_loss: 17.7284\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.3622 - val_loss: 18.0095\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.3599 - val_loss: 17.7796\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 1.3511 - val_loss: 17.0599\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 619us/step - loss: 1.3677 - val_loss: 16.5478\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 660us/step - loss: 1.3610 - val_loss: 16.2208\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.3604 - val_loss: 16.0055\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.3638 - val_loss: 15.9159\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 659us/step - loss: 1.3651 - val_loss: 15.5864\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 1.3672 - val_loss: 15.6589\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.3657 - val_loss: 15.6115\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.3634 - val_loss: 15.4270\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.3731 - val_loss: 15.1101\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.3702 - val_loss: 15.2380\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.3667 - val_loss: 15.3436\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.3575 - val_loss: 15.7217\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 1.3621 - val_loss: 16.2444\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.3487 - val_loss: 16.2849\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.3456 - val_loss: 16.3252\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.3464 - val_loss: 16.5028\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.3586 - val_loss: 16.9552\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.3441 - val_loss: 16.5551\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.3410 - val_loss: 16.5648\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 1.3365 - val_loss: 16.8501\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 1.3391 - val_loss: 17.3482\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.3334 - val_loss: 17.4382\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 632us/step - loss: 1.3331 - val_loss: 17.5836\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 1.3409 - val_loss: 17.7764\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 633us/step - loss: 1.3409 - val_loss: 16.9717\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.3248 - val_loss: 16.4853\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 628us/step - loss: 1.3303 - val_loss: 15.9957\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 651us/step - loss: 1.3350 - val_loss: 15.1146\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.3437 - val_loss: 14.5772\n",
      "Epoch 1154/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 559us/step - loss: 1.3656 - val_loss: 14.2648\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.3588 - val_loss: 14.5130\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.3583 - val_loss: 14.9389\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.3450 - val_loss: 15.3385\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 610us/step - loss: 1.3364 - val_loss: 15.7462\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.3193 - val_loss: 16.3147\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.3310 - val_loss: 17.1353\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 1.3236 - val_loss: 17.6042\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 1.3218 - val_loss: 17.6790\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.3149 - val_loss: 17.1917\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.3154 - val_loss: 16.6303\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.3103 - val_loss: 16.2526\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.3141 - val_loss: 15.9460\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.3196 - val_loss: 15.8351\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.3213 - val_loss: 16.0667\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.3170 - val_loss: 16.0583\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.3150 - val_loss: 16.2624\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.3060 - val_loss: 15.6682\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.3142 - val_loss: 14.8551\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 635us/step - loss: 1.3261 - val_loss: 14.6843\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.3306 - val_loss: 14.4447\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 617us/step - loss: 1.3272 - val_loss: 14.0361\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 1.3416 - val_loss: 13.9307\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.3382 - val_loss: 14.3358\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.3370 - val_loss: 14.8902\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.3122 - val_loss: 15.2021\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.3031 - val_loss: 15.7546\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.2949 - val_loss: 16.4850\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.2909 - val_loss: 17.1565\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.3144 - val_loss: 17.9380\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 1.2989 - val_loss: 17.9908\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.2996 - val_loss: 17.8319\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.2996 - val_loss: 17.1013\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.2882 - val_loss: 16.6609\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.2875 - val_loss: 16.3063\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 1.2882 - val_loss: 16.2451\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.2937 - val_loss: 15.8770\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.2975 - val_loss: 15.3634\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.2920 - val_loss: 15.2459\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.2935 - val_loss: 14.6969\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.3208 - val_loss: 13.9269\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 1.3165 - val_loss: 14.1619\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.3017 - val_loss: 14.8145\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.2789 - val_loss: 15.7599\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.2726 - val_loss: 16.8314\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 510us/step - loss: 1.2775 - val_loss: 17.5435\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 1.2826 - val_loss: 17.8815\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 504us/step - loss: 1.2848 - val_loss: 18.2106\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.2910 - val_loss: 18.5527\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.2969 - val_loss: 18.4899\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 507us/step - loss: 1.2860 - val_loss: 17.7688\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.2793 - val_loss: 17.5083\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 503us/step - loss: 1.2809 - val_loss: 17.3152\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.2706 - val_loss: 17.5289\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 507us/step - loss: 1.2899 - val_loss: 17.7188\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 1.2675 - val_loss: 16.6807\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 1.2641 - val_loss: 15.6748\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 513us/step - loss: 1.2730 - val_loss: 15.3134\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.2639 - val_loss: 15.3951\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 513us/step - loss: 1.2659 - val_loss: 15.4301\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.2668 - val_loss: 15.8881\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 518us/step - loss: 1.2591 - val_loss: 15.8076\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 526us/step - loss: 1.2559 - val_loss: 16.0312\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.2554 - val_loss: 16.1692\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 513us/step - loss: 1.2542 - val_loss: 16.2111\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.2580 - val_loss: 16.0060\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 517us/step - loss: 1.2534 - val_loss: 15.8298\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.2515 - val_loss: 14.8077\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.2573 - val_loss: 13.7666\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.2851 - val_loss: 13.4898\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 1.2746 - val_loss: 13.8865\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.2553 - val_loss: 14.7616\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 1.2518 - val_loss: 15.7073\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.2461 - val_loss: 16.3477\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.2437 - val_loss: 16.9163\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 512us/step - loss: 1.2448 - val_loss: 17.2351\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 529us/step - loss: 1.2477 - val_loss: 17.3714\n",
      "Epoch 1231/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 521us/step - loss: 1.2494 - val_loss: 17.2976\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 1.2466 - val_loss: 17.4423\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.2476 - val_loss: 17.6012\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.2505 - val_loss: 17.6334\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.2515 - val_loss: 17.5086\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.2442 - val_loss: 17.2452\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 517us/step - loss: 1.2388 - val_loss: 16.8963\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 1.2366 - val_loss: 16.4891\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 1.2368 - val_loss: 16.2210\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 507us/step - loss: 1.2307 - val_loss: 16.3500\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.2297 - val_loss: 16.3921\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 486us/step - loss: 1.2288 - val_loss: 16.5290\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.2363 - val_loss: 16.7242\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 518us/step - loss: 1.2274 - val_loss: 16.0483\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 1.2241 - val_loss: 15.9457\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.2228 - val_loss: 16.1056\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 526us/step - loss: 1.2177 - val_loss: 16.4783\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.2222 - val_loss: 16.8369\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 526us/step - loss: 1.2246 - val_loss: 16.9949\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.2268 - val_loss: 16.8400\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 527us/step - loss: 1.2228 - val_loss: 16.5322\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.2135 - val_loss: 15.7284\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.2200 - val_loss: 15.0762\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 1.2188 - val_loss: 15.0180\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.2139 - val_loss: 15.4688\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.2095 - val_loss: 15.8963\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.2085 - val_loss: 16.4257\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 1.2208 - val_loss: 16.5590\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 514us/step - loss: 1.2195 - val_loss: 15.6314\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.2094 - val_loss: 14.9390\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 1.2117 - val_loss: 14.4870\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.2101 - val_loss: 14.5526\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 528us/step - loss: 1.2046 - val_loss: 14.8988\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 517us/step - loss: 1.2019 - val_loss: 15.1541\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.1997 - val_loss: 15.5920\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 520us/step - loss: 1.2012 - val_loss: 15.9293\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.1969 - val_loss: 16.2989\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 1.1976 - val_loss: 16.8384\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.2052 - val_loss: 17.1252\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 630us/step - loss: 1.2089 - val_loss: 17.5590\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.2196 - val_loss: 17.7036\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 1.2140 - val_loss: 16.9183\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 1.1964 - val_loss: 15.9141\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.1929 - val_loss: 15.5172\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.1905 - val_loss: 15.3244\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 519us/step - loss: 1.1917 - val_loss: 14.9364\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.1916 - val_loss: 14.8606\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.1870 - val_loss: 15.1408\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 1.1882 - val_loss: 15.7275\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.1881 - val_loss: 16.0758\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.1885 - val_loss: 16.0971\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.1879 - val_loss: 16.0888\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.1898 - val_loss: 16.0258\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 1.1854 - val_loss: 15.8535\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.1863 - val_loss: 15.7432\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.1727 - val_loss: 14.8570\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.1741 - val_loss: 14.3210\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.1769 - val_loss: 14.0590\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 1.1796 - val_loss: 13.6025\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 628us/step - loss: 1.1914 - val_loss: 12.7493\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.2017 - val_loss: 12.5790\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 642us/step - loss: 1.2000 - val_loss: 12.9784\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.1871 - val_loss: 13.5304\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.1693 - val_loss: 14.2794\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 619us/step - loss: 1.1706 - val_loss: 15.1944\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.1615 - val_loss: 15.7345\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.1798 - val_loss: 16.0951\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 1.1817 - val_loss: 15.6357\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 641us/step - loss: 1.1696 - val_loss: 15.7027\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 1.1663 - val_loss: 15.6185\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 628us/step - loss: 1.1712 - val_loss: 15.8846\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 651us/step - loss: 1.1713 - val_loss: 16.1486\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 621us/step - loss: 1.1790 - val_loss: 16.2186\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.1662 - val_loss: 14.9026\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.1623 - val_loss: 13.4002\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.1622 - val_loss: 12.8150\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.1781 - val_loss: 12.3859\n",
      "Epoch 1308/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 516us/step - loss: 1.1838 - val_loss: 12.0039\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.1874 - val_loss: 11.9572\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.1867 - val_loss: 12.1018\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.1800 - val_loss: 12.4489\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.1708 - val_loss: 13.0511\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 614us/step - loss: 1.1624 - val_loss: 13.5099\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.1549 - val_loss: 13.6474\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.1477 - val_loss: 13.6436\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.1465 - val_loss: 13.7368\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.1549 - val_loss: 14.2867\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 647us/step - loss: 1.1429 - val_loss: 14.3701\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 1.1471 - val_loss: 14.5951\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 1.1534 - val_loss: 13.9130\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 621us/step - loss: 1.1414 - val_loss: 13.8083\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 1.1372 - val_loss: 13.7683\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 1.1363 - val_loss: 13.8457\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.1354 - val_loss: 14.0009\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.1353 - val_loss: 14.3076\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.1291 - val_loss: 14.6731\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.1306 - val_loss: 14.9233\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 639us/step - loss: 1.1280 - val_loss: 15.4261\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 1.1319 - val_loss: 16.0354\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.1558 - val_loss: 16.8015\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 1.1669 - val_loss: 17.2477\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.1702 - val_loss: 17.1271\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 1.1677 - val_loss: 16.8489\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 613us/step - loss: 1.1659 - val_loss: 15.3404\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 1.1354 - val_loss: 14.2864\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 624us/step - loss: 1.1229 - val_loss: 13.5588\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 1.1398 - val_loss: 13.0921\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.1249 - val_loss: 13.2008\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 1.1219 - val_loss: 13.4378\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 1.1165 - val_loss: 13.8902\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.1194 - val_loss: 13.7397\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.1053 - val_loss: 12.9061\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.1312 - val_loss: 12.2941\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 1.1264 - val_loss: 12.3485\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.1232 - val_loss: 12.6071\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.1187 - val_loss: 12.8286\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.1195 - val_loss: 12.8778\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.1134 - val_loss: 12.2514\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.1220 - val_loss: 11.9984\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 1.1367 - val_loss: 11.9013\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.1210 - val_loss: 12.2730\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.1119 - val_loss: 12.7672\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.1027 - val_loss: 13.2355\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.1074 - val_loss: 13.7124\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.1091 - val_loss: 14.1221\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.1034 - val_loss: 14.1231\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.1122 - val_loss: 13.2200\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 1.0962 - val_loss: 13.0713\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 1.0988 - val_loss: 12.9659\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 635us/step - loss: 1.0934 - val_loss: 13.4227\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 1.1014 - val_loss: 13.9729\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 1.0890 - val_loss: 14.1161\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 1.0929 - val_loss: 14.3532\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.0883 - val_loss: 14.4617\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 627us/step - loss: 1.0846 - val_loss: 14.8980\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 1.1075 - val_loss: 15.2732\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 1.0870 - val_loss: 14.3263\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 1.0922 - val_loss: 13.3076\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.1022 - val_loss: 12.6110\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 1.0838 - val_loss: 12.6445\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 1.0824 - val_loss: 12.7025\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.0836 - val_loss: 12.5565\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.0819 - val_loss: 12.6438\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.0726 - val_loss: 13.1113\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 1.0707 - val_loss: 13.4396\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 1.0740 - val_loss: 13.7779\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 620us/step - loss: 1.0692 - val_loss: 13.5105\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 619us/step - loss: 1.0674 - val_loss: 13.4722\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 1.0675 - val_loss: 13.5841\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.0728 - val_loss: 13.7597\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 1.0748 - val_loss: 13.0265\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.0649 - val_loss: 12.9158\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 1.0637 - val_loss: 12.6630\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 1.0621 - val_loss: 12.3972\n",
      "Epoch 1385/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 559us/step - loss: 1.0708 - val_loss: 12.1063\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 517us/step - loss: 1.0715 - val_loss: 11.8975\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 1.0690 - val_loss: 12.1764\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 1.0572 - val_loss: 12.8543\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.0584 - val_loss: 13.4195\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 1.0512 - val_loss: 13.8836\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.0533 - val_loss: 14.0126\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 525us/step - loss: 1.0529 - val_loss: 14.4801\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.0547 - val_loss: 14.6493\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.0547 - val_loss: 14.9916\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 1.0593 - val_loss: 15.1730\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 515us/step - loss: 1.0741 - val_loss: 15.3824\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.0620 - val_loss: 14.6011\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 524us/step - loss: 1.0467 - val_loss: 14.1520\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 503us/step - loss: 1.0454 - val_loss: 13.7592\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1.0413 - val_loss: 13.3972\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 517us/step - loss: 1.0396 - val_loss: 13.4812\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 1.0411 - val_loss: 13.9401\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 1.0346 - val_loss: 14.4608\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 1.0408 - val_loss: 15.0140\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 517us/step - loss: 1.0613 - val_loss: 15.0797\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 1.0636 - val_loss: 13.8852\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0348 - val_loss: 13.4709\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 1.0310 - val_loss: 13.3131\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.0302 - val_loss: 13.4315\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 1.0383 - val_loss: 13.5672\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.0371 - val_loss: 12.7159\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 1.0267 - val_loss: 12.4140\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 1.0249 - val_loss: 12.0167\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 1.0275 - val_loss: 12.1598\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 1.0245 - val_loss: 12.1094\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 1.0241 - val_loss: 11.9339\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 1.0393 - val_loss: 11.1479\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 1.0328 - val_loss: 11.2325\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 1.0272 - val_loss: 11.4670\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 1.0277 - val_loss: 12.2119\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 1.0155 - val_loss: 12.4763\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.0221 - val_loss: 12.2491\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 496us/step - loss: 1.0093 - val_loss: 12.6085\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.0107 - val_loss: 12.9383\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 1.0111 - val_loss: 12.9182\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 1.0089 - val_loss: 12.8855\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 1.0080 - val_loss: 12.9496\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 513us/step - loss: 1.0111 - val_loss: 12.7462\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 1.0036 - val_loss: 12.8857\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 622us/step - loss: 1.0060 - val_loss: 12.9487\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 1.0013 - val_loss: 12.7379\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 1.0019 - val_loss: 12.4277\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 501us/step - loss: 0.9972 - val_loss: 12.5216\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.9978 - val_loss: 12.5051\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 497us/step - loss: 0.9941 - val_loss: 12.2788\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 1.0059 - val_loss: 11.9547\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 0.9995 - val_loss: 12.3330\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.9902 - val_loss: 12.4414\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 532us/step - loss: 0.9882 - val_loss: 12.6424\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 0.9855 - val_loss: 12.9187\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 0.9914 - val_loss: 13.2808\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 472us/step - loss: 0.9876 - val_loss: 13.2828\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.9888 - val_loss: 13.2850\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.9890 - val_loss: 12.9250\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 0.9821 - val_loss: 12.7963\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 522us/step - loss: 0.9891 - val_loss: 12.2624\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 0.9795 - val_loss: 12.2960\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.9778 - val_loss: 12.2967\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 485us/step - loss: 0.9768 - val_loss: 12.5379\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.9750 - val_loss: 12.6227\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 0.9726 - val_loss: 12.7474\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.9725 - val_loss: 12.8316\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 0.9702 - val_loss: 13.0297\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.9713 - val_loss: 13.0298\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 0.9712 - val_loss: 12.9889\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.9735 - val_loss: 13.0207\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.9682 - val_loss: 13.0192\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 501us/step - loss: 0.9688 - val_loss: 13.1382\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 0.9666 - val_loss: 13.3879\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.9658 - val_loss: 13.6319\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.9821 - val_loss: 14.1575\n",
      "Epoch 1462/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 610us/step - loss: 0.9864 - val_loss: 14.4061\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 0.9831 - val_loss: 14.0325\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.9709 - val_loss: 13.4030\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 509us/step - loss: 0.9660 - val_loss: 12.8176\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 0.9563 - val_loss: 12.5988\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 0.9557 - val_loss: 12.2390\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 0.9509 - val_loss: 12.1426\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.9500 - val_loss: 12.0249\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 0.9544 - val_loss: 11.6181\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.9517 - val_loss: 11.2981\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 541us/step - loss: 0.9566 - val_loss: 11.1917\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 0.9501 - val_loss: 11.6216\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 477us/step - loss: 0.9457 - val_loss: 11.9897\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.9394 - val_loss: 12.6787\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 521us/step - loss: 0.9455 - val_loss: 13.2823\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.9490 - val_loss: 12.8161\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 515us/step - loss: 0.9402 - val_loss: 11.5697\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 524us/step - loss: 0.9413 - val_loss: 11.0776\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.9421 - val_loss: 10.9562\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 492us/step - loss: 0.9423 - val_loss: 11.5218\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 0.9402 - val_loss: 12.0149\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 487us/step - loss: 0.9268 - val_loss: 11.5151\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 0.9389 - val_loss: 10.9777\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 525us/step - loss: 0.9307 - val_loss: 11.1307\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.9296 - val_loss: 11.1725\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.9270 - val_loss: 11.2413\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 0.9245 - val_loss: 10.9154\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 0.9360 - val_loss: 10.5465\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 0.9268 - val_loss: 10.7671\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.9205 - val_loss: 11.3771\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 632us/step - loss: 0.9136 - val_loss: 11.8292\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 0.9234 - val_loss: 12.3611\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 644us/step - loss: 0.9235 - val_loss: 12.3314\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 642us/step - loss: 0.9214 - val_loss: 12.2303\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 0.9201 - val_loss: 12.2416\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 655us/step - loss: 0.9207 - val_loss: 12.4909\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 0.9224 - val_loss: 12.8582\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 0.9405 - val_loss: 12.9632\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 0.9265 - val_loss: 12.0314\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 518us/step - loss: 0.9096 - val_loss: 11.4651\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 0.9070 - val_loss: 11.3146\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.9137 - val_loss: 11.5350\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 524us/step - loss: 0.9065 - val_loss: 11.2677\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 0.9070 - val_loss: 10.8572\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 510us/step - loss: 0.9012 - val_loss: 10.6347\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 0.9025 - val_loss: 10.5589\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 500us/step - loss: 0.9008 - val_loss: 10.8622\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 0.8971 - val_loss: 11.6061\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 0.9114 - val_loss: 11.9173\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.8937 - val_loss: 11.1614\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 0.8920 - val_loss: 10.6841\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 0.8913 - val_loss: 9.6623\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 0.9034 - val_loss: 9.4180\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 0.9059 - val_loss: 9.4933\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 0.9014 - val_loss: 9.9077\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.8917 - val_loss: 10.7157\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.8821 - val_loss: 11.5323\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.8900 - val_loss: 12.0070\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 521us/step - loss: 0.8965 - val_loss: 11.8825\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.8932 - val_loss: 11.5742\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 529us/step - loss: 0.8844 - val_loss: 11.1105\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.9030 - val_loss: 9.8417\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.8878 - val_loss: 9.5295\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.8869 - val_loss: 9.7837\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.8783 - val_loss: 10.3354\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 0.8715 - val_loss: 10.6106\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.8786 - val_loss: 11.0883\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.8707 - val_loss: 10.8540\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 0.8695 - val_loss: 10.5018\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 0.8572 - val_loss: 9.6045\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.8773 - val_loss: 9.0135\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 0.8798 - val_loss: 8.6378\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 0.8901 - val_loss: 8.5945\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 0.8889 - val_loss: 8.1325\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 640us/step - loss: 0.8969 - val_loss: 8.1934\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 0.8919 - val_loss: 8.4058\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 647us/step - loss: 0.8814 - val_loss: 8.6723\n",
      "Epoch 1539/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 611us/step - loss: 0.8792 - val_loss: 8.9301\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 0.8734 - val_loss: 8.6238\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 0.8695 - val_loss: 8.9754\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 0.8649 - val_loss: 9.1744\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.8570 - val_loss: 8.7787\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.8622 - val_loss: 8.8886\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 0.8570 - val_loss: 9.3745\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 507us/step - loss: 0.8484 - val_loss: 9.6908\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.8498 - val_loss: 9.8125\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.8512 - val_loss: 9.8579\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 0.8539 - val_loss: 9.0381\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 0.8529 - val_loss: 8.7756\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 0.8477 - val_loss: 9.1071\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.8459 - val_loss: 9.8554\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 522us/step - loss: 0.8548 - val_loss: 10.3933\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 0.8394 - val_loss: 9.6975\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 507us/step - loss: 0.8311 - val_loss: 8.8871\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 0.8398 - val_loss: 7.9176\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 0.8689 - val_loss: 7.7651\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 510us/step - loss: 0.8489 - val_loss: 8.3105\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.8334 - val_loss: 8.9468\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 506us/step - loss: 0.8508 - val_loss: 9.7135\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.8285 - val_loss: 9.0874\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 511us/step - loss: 0.8316 - val_loss: 8.1215\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.8438 - val_loss: 7.9946\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 493us/step - loss: 0.8277 - val_loss: 8.5413\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.8212 - val_loss: 9.3727\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 0.8333 - val_loss: 10.1833\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 0.8352 - val_loss: 10.4602\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 0.8354 - val_loss: 10.1683\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 499us/step - loss: 0.8315 - val_loss: 9.7964\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 0.8220 - val_loss: 9.6097\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 523us/step - loss: 0.8181 - val_loss: 9.4900\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 511us/step - loss: 0.8174 - val_loss: 9.4192\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.8179 - val_loss: 9.2974\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 0.8119 - val_loss: 9.0185\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 0.8159 - val_loss: 8.6132\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.8087 - val_loss: 8.6513\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 0.8129 - val_loss: 9.0742\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.8058 - val_loss: 9.1234\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 519us/step - loss: 0.8047 - val_loss: 9.2174\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 600us/step - loss: 0.8055 - val_loss: 9.5987\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 508us/step - loss: 0.8165 - val_loss: 9.8182\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 0.8087 - val_loss: 9.5836\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 0.8051 - val_loss: 9.1749\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 0.7970 - val_loss: 8.8416\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.7973 - val_loss: 8.5641\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 501us/step - loss: 0.7975 - val_loss: 8.5613\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 0.7951 - val_loss: 8.4490\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 509us/step - loss: 0.7955 - val_loss: 8.1896\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 0.7976 - val_loss: 7.6778\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 522us/step - loss: 0.8260 - val_loss: 6.9817\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 0.8229 - val_loss: 7.2225\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 0.8076 - val_loss: 7.6267\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 484us/step - loss: 0.7964 - val_loss: 8.1771\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.7841 - val_loss: 8.6754\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 519us/step - loss: 0.7752 - val_loss: 9.2593\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.8029 - val_loss: 10.0101\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 494us/step - loss: 0.7925 - val_loss: 10.0862\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.7944 - val_loss: 9.8339\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 500us/step - loss: 0.7747 - val_loss: 8.6464\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.7735 - val_loss: 7.8921\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.7701 - val_loss: 6.9972\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 521us/step - loss: 0.8123 - val_loss: 6.5703\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 0.8114 - val_loss: 7.0679\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 0.7879 - val_loss: 7.8975\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 0.7717 - val_loss: 8.8434\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 496us/step - loss: 0.7690 - val_loss: 9.2381\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 0.7662 - val_loss: 8.9386\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 0.7514 - val_loss: 7.9114\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 515us/step - loss: 0.7790 - val_loss: 7.3112\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.7741 - val_loss: 7.4606\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 494us/step - loss: 0.7701 - val_loss: 7.7386\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.7679 - val_loss: 7.9455\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 499us/step - loss: 0.7579 - val_loss: 7.8266\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 0.7620 - val_loss: 7.6148\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 505us/step - loss: 0.7636 - val_loss: 7.5196\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 0.7647 - val_loss: 7.6832\n",
      "Epoch 1617/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 533us/step - loss: 0.7628 - val_loss: 7.7273\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 519us/step - loss: 0.7526 - val_loss: 8.1806\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 0.7513 - val_loss: 8.5214\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 0.7466 - val_loss: 8.7655\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 516us/step - loss: 0.7447 - val_loss: 8.6857\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 539us/step - loss: 0.7478 - val_loss: 8.5879\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 516us/step - loss: 0.7310 - val_loss: 7.5745\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.7590 - val_loss: 6.4753\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 510us/step - loss: 0.7996 - val_loss: 6.2992\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.7874 - val_loss: 6.6735\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 518us/step - loss: 0.7623 - val_loss: 7.3141\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 0.7405 - val_loss: 8.3601\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 0.7355 - val_loss: 9.1096\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 508us/step - loss: 0.7400 - val_loss: 9.2927\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 0.7561 - val_loss: 9.7442\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 516us/step - loss: 0.7526 - val_loss: 9.4066\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.7428 - val_loss: 9.4957\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 486us/step - loss: 0.7462 - val_loss: 9.5759\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.7409 - val_loss: 9.0113\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 510us/step - loss: 0.7183 - val_loss: 7.8077\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.7411 - val_loss: 6.3289\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.7762 - val_loss: 5.7511\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 530us/step - loss: 0.7973 - val_loss: 5.8450\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 636us/step - loss: 0.7841 - val_loss: 6.1248\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.7649 - val_loss: 6.6141\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 0.7362 - val_loss: 7.3198\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 0.7248 - val_loss: 8.5170\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 538us/step - loss: 0.7242 - val_loss: 9.0435\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 0.7256 - val_loss: 8.7847\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 0.7202 - val_loss: 8.8514\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 0.7255 - val_loss: 8.7561\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 0.7252 - val_loss: 7.5649\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.7189 - val_loss: 6.8678\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 0.7239 - val_loss: 6.6243\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.7353 - val_loss: 6.4731\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.7369 - val_loss: 6.5318\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 0.7249 - val_loss: 6.9634\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 0.7345 - val_loss: 8.0430\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.7006 - val_loss: 8.5604\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.7240 - val_loss: 8.7609\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 0.7203 - val_loss: 7.7475\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 0.7044 - val_loss: 7.5331\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.7031 - val_loss: 7.4308\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 0.7088 - val_loss: 6.8845\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 0.7187 - val_loss: 6.3947\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.7170 - val_loss: 6.5128\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.7112 - val_loss: 7.1001\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 0.6997 - val_loss: 7.5034\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 0.6953 - val_loss: 7.9206\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 0.6977 - val_loss: 8.0839\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 0.7024 - val_loss: 8.3444\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 0.7041 - val_loss: 8.3041\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 0.7010 - val_loss: 8.2391\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 0.6999 - val_loss: 8.1631\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 0.6993 - val_loss: 8.0112\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.6951 - val_loss: 7.6792\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 0.6927 - val_loss: 7.5722\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 610us/step - loss: 0.6900 - val_loss: 7.2440\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.6904 - val_loss: 7.0128\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 587us/step - loss: 0.6870 - val_loss: 6.6246\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 0.7040 - val_loss: 6.2131\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 0.7004 - val_loss: 6.5462\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 0.6907 - val_loss: 6.6311\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 618us/step - loss: 0.6956 - val_loss: 7.0411\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.6905 - val_loss: 6.9982\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.6819 - val_loss: 7.1765\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 0.6833 - val_loss: 7.2525\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.6871 - val_loss: 7.8621\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 0.7005 - val_loss: 8.4588\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.7090 - val_loss: 8.5672\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 0.7044 - val_loss: 8.0179\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.6889 - val_loss: 7.8526\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.6837 - val_loss: 7.8816\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 0.6842 - val_loss: 7.8861\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 0.6855 - val_loss: 7.9862\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.6900 - val_loss: 8.2539\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.6894 - val_loss: 8.1234\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 0.6967 - val_loss: 7.5695\n",
      "Epoch 1695/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 565us/step - loss: 0.6759 - val_loss: 7.5862\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 0.6744 - val_loss: 7.8190\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.6785 - val_loss: 7.9641\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.6832 - val_loss: 8.0779\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 0.6811 - val_loss: 7.7650\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.6768 - val_loss: 7.6881\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.6797 - val_loss: 7.2498\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.6660 - val_loss: 7.3039\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.6674 - val_loss: 7.4840\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 612us/step - loss: 0.6662 - val_loss: 7.5470\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 0.6654 - val_loss: 7.7030\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.6689 - val_loss: 7.5386\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 0.6629 - val_loss: 7.0110\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.6933 - val_loss: 5.7405\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.6769 - val_loss: 5.6756\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 0.6749 - val_loss: 5.9568\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 0.6614 - val_loss: 6.4765\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 0.6593 - val_loss: 6.8797\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 0.6572 - val_loss: 6.9963\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 0.6601 - val_loss: 6.8052\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 0.6570 - val_loss: 5.8367\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 0.6638 - val_loss: 5.6970\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.6629 - val_loss: 6.1819\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 0.6547 - val_loss: 6.9757\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 0.6596 - val_loss: 7.5139\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 0.6608 - val_loss: 7.4144\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 0.6596 - val_loss: 7.2523\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 0.6551 - val_loss: 7.4509\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.6584 - val_loss: 7.5778\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 0.6666 - val_loss: 7.9062\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 0.6748 - val_loss: 7.9069\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 0.6725 - val_loss: 7.9259\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 0.6665 - val_loss: 7.5532\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.6538 - val_loss: 7.0318\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 0.6496 - val_loss: 6.5733\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.6425 - val_loss: 6.1847\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 0.6444 - val_loss: 5.8367\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 0.6469 - val_loss: 5.6934\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 527us/step - loss: 0.6485 - val_loss: 5.6111\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 0.6517 - val_loss: 5.4690\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.6512 - val_loss: 5.0156\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 0.6766 - val_loss: 4.7588\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 0.6826 - val_loss: 4.7337\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.6930 - val_loss: 4.6962\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 691us/step - loss: 0.6758 - val_loss: 5.5863\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 746us/step - loss: 0.6461 - val_loss: 6.4422\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 0.6288 - val_loss: 6.9350\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.6340 - val_loss: 7.4204\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 0.6445 - val_loss: 7.3230\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.6454 - val_loss: 7.3361\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 0.6372 - val_loss: 6.8601\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 678us/step - loss: 0.6327 - val_loss: 6.5945\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 0.6333 - val_loss: 6.2645\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 0.6330 - val_loss: 6.5098\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 629us/step - loss: 0.6277 - val_loss: 6.5075\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 0.6298 - val_loss: 6.3298\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 0.6266 - val_loss: 5.5094\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 0.6369 - val_loss: 5.6066\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 638us/step - loss: 0.6208 - val_loss: 6.3396\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 0.6159 - val_loss: 7.1698\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 674us/step - loss: 0.6327 - val_loss: 7.5264\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 674us/step - loss: 0.6394 - val_loss: 7.7765\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 0.6443 - val_loss: 7.3994\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 725us/step - loss: 0.6225 - val_loss: 6.3630\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 662us/step - loss: 0.6167 - val_loss: 5.6151\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 609us/step - loss: 0.6266 - val_loss: 5.2747\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.6269 - val_loss: 5.5588\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 0.6258 - val_loss: 6.2791\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 0.6129 - val_loss: 6.8958\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.6323 - val_loss: 7.5494\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.6403 - val_loss: 7.3745\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 519us/step - loss: 0.6357 - val_loss: 7.1590\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 0.6206 - val_loss: 6.3587\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.6051 - val_loss: 4.7515\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.6351 - val_loss: 3.5741\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.7278 - val_loss: 3.0011\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.7747 - val_loss: 3.1397\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 625us/step - loss: 0.7318 - val_loss: 4.0622\n",
      "Epoch 1773/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 619us/step - loss: 0.6298 - val_loss: 5.2369\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 0.6025 - val_loss: 6.5201\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.6184 - val_loss: 7.3675\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 0.6351 - val_loss: 7.4399\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 0.6403 - val_loss: 7.2787\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 0.6379 - val_loss: 5.9460\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 0.6061 - val_loss: 5.1880\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 0.6117 - val_loss: 5.0472\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 0.6127 - val_loss: 5.1401\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 607us/step - loss: 0.6044 - val_loss: 5.9045\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 0.6064 - val_loss: 6.8290\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.6182 - val_loss: 7.4518\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.6448 - val_loss: 7.3445\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 0.6115 - val_loss: 6.0087\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.6020 - val_loss: 4.8450\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.6122 - val_loss: 4.3022\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 0.6288 - val_loss: 4.2577\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.6355 - val_loss: 4.3046\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.6326 - val_loss: 4.5869\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.6027 - val_loss: 5.4774\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 524us/step - loss: 0.5932 - val_loss: 6.6983\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 584us/step - loss: 0.6089 - val_loss: 7.3601\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 616us/step - loss: 0.6271 - val_loss: 7.6529\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 0.6307 - val_loss: 7.3318\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 546us/step - loss: 0.6103 - val_loss: 6.4534\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 0.5957 - val_loss: 5.4048\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.6068 - val_loss: 4.6255\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 0.6137 - val_loss: 4.7791\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5982 - val_loss: 5.6365\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.5884 - val_loss: 6.5743\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 0.6055 - val_loss: 7.4168\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 0.6201 - val_loss: 7.5875\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 0.6261 - val_loss: 7.5034\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 0.6216 - val_loss: 6.7892\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.5918 - val_loss: 6.2231\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.5910 - val_loss: 5.6045\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 0.5852 - val_loss: 5.3690\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 0.5824 - val_loss: 5.6972\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.5889 - val_loss: 6.0621\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 0.5867 - val_loss: 5.9592\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 0.5802 - val_loss: 5.5922\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 0.5798 - val_loss: 5.4123\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 542us/step - loss: 0.5838 - val_loss: 5.2910\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 617us/step - loss: 0.5860 - val_loss: 5.1978\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 0.5772 - val_loss: 5.7057\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 599us/step - loss: 0.5804 - val_loss: 6.2709\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.5891 - val_loss: 6.3288\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.5828 - val_loss: 5.9075\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.5784 - val_loss: 5.7946\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.5767 - val_loss: 5.3669\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 0.5830 - val_loss: 5.0477\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 0.5796 - val_loss: 5.0212\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 0.5794 - val_loss: 4.8498\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 583us/step - loss: 0.5826 - val_loss: 5.0589\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 0.5746 - val_loss: 5.3460\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.5724 - val_loss: 5.7749\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 611us/step - loss: 0.5835 - val_loss: 6.2062\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 0.5770 - val_loss: 5.9766\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.5809 - val_loss: 5.5914\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 527us/step - loss: 0.5685 - val_loss: 5.6939\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 0.5698 - val_loss: 5.7145\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5684 - val_loss: 5.5245\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 624us/step - loss: 0.5665 - val_loss: 5.2638\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5653 - val_loss: 5.2311\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.5668 - val_loss: 5.0463\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 601us/step - loss: 0.5683 - val_loss: 4.9173\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 637us/step - loss: 0.5672 - val_loss: 4.9368\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 647us/step - loss: 0.5675 - val_loss: 5.0353\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 0.5659 - val_loss: 5.5350\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 640us/step - loss: 0.5656 - val_loss: 5.5461\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 0.5622 - val_loss: 5.6020\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 0.5729 - val_loss: 5.6056\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 617us/step - loss: 0.5550 - val_loss: 4.8258\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 568us/step - loss: 0.5781 - val_loss: 4.1917\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.5835 - val_loss: 4.5971\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 0.5636 - val_loss: 4.9424\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.5599 - val_loss: 5.5023\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 0.5634 - val_loss: 5.7546\n",
      "Epoch 1851/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 545us/step - loss: 0.5580 - val_loss: 5.4752\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 592us/step - loss: 0.5541 - val_loss: 4.8106\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 0.5660 - val_loss: 3.7903\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.5965 - val_loss: 3.6081\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 0.5843 - val_loss: 4.2224\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.5592 - val_loss: 4.7938\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.5500 - val_loss: 5.3572\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.5566 - val_loss: 5.6351\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 604us/step - loss: 0.5546 - val_loss: 5.4027\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 574us/step - loss: 0.5501 - val_loss: 5.1218\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 549us/step - loss: 0.5483 - val_loss: 5.2175\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.5514 - val_loss: 5.0823\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.5495 - val_loss: 5.1005\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 564us/step - loss: 0.5476 - val_loss: 5.0837\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.5463 - val_loss: 5.0763\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.5458 - val_loss: 5.0917\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 0.5489 - val_loss: 5.1605\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.5580 - val_loss: 4.3237\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 631us/step - loss: 0.5547 - val_loss: 4.2588\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 0.5562 - val_loss: 4.2099\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5684 - val_loss: 3.8451\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 571us/step - loss: 0.5575 - val_loss: 4.3650\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.5453 - val_loss: 4.9409\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.5366 - val_loss: 5.2756\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.5580 - val_loss: 5.6570\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.5422 - val_loss: 5.0801\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.5523 - val_loss: 4.3181\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 575us/step - loss: 0.5409 - val_loss: 4.3754\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.5375 - val_loss: 4.6995\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.5414 - val_loss: 5.0256\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.5355 - val_loss: 5.0264\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 0.5360 - val_loss: 5.0673\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 617us/step - loss: 0.5357 - val_loss: 4.9329\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 554us/step - loss: 0.5355 - val_loss: 5.2373\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 685us/step - loss: 0.5363 - val_loss: 5.4093\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 559us/step - loss: 0.5458 - val_loss: 5.5003\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 0.5405 - val_loss: 5.3426\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.5359 - val_loss: 4.7906\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.5457 - val_loss: 3.4711\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 581us/step - loss: 0.5592 - val_loss: 3.0012\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.5754 - val_loss: 3.1508\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 543us/step - loss: 0.5585 - val_loss: 3.6261\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5277 - val_loss: 4.6782\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 0.5390 - val_loss: 5.5033\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 0.5495 - val_loss: 5.2435\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 526us/step - loss: 0.5346 - val_loss: 5.0506\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.5285 - val_loss: 4.5219\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 590us/step - loss: 0.5213 - val_loss: 4.2530\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.5285 - val_loss: 4.1546\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 0.5240 - val_loss: 4.2754\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 557us/step - loss: 0.5227 - val_loss: 4.6317\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 534us/step - loss: 0.5232 - val_loss: 4.4975\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 605us/step - loss: 0.5262 - val_loss: 4.1498\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 577us/step - loss: 0.5192 - val_loss: 4.4438\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 615us/step - loss: 0.5177 - val_loss: 4.7271\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 596us/step - loss: 0.5268 - val_loss: 5.0283\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 598us/step - loss: 0.5355 - val_loss: 4.4065\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.5174 - val_loss: 4.4674\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 588us/step - loss: 0.5168 - val_loss: 4.2667\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.5148 - val_loss: 4.0343\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5210 - val_loss: 3.8813\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.5168 - val_loss: 3.1890\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5449 - val_loss: 2.6485\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.6008 - val_loss: 2.4013\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.5944 - val_loss: 2.9630\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 529us/step - loss: 0.5439 - val_loss: 3.7605\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.5106 - val_loss: 4.5201\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.5168 - val_loss: 5.2629\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 594us/step - loss: 0.5246 - val_loss: 5.1317\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 0.5218 - val_loss: 4.9187\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.5174 - val_loss: 4.6726\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.5124 - val_loss: 4.4961\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 602us/step - loss: 0.5057 - val_loss: 4.3268\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5038 - val_loss: 4.1420\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.5054 - val_loss: 3.9096\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.5057 - val_loss: 3.8756\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 558us/step - loss: 0.5058 - val_loss: 3.7633\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.5075 - val_loss: 3.5447\n",
      "Epoch 1929/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 581us/step - loss: 0.5115 - val_loss: 3.6422\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 0.5052 - val_loss: 3.9964\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 624us/step - loss: 0.5111 - val_loss: 4.5349\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 660us/step - loss: 0.5071 - val_loss: 4.5856\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 522us/step - loss: 0.5062 - val_loss: 4.1596\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 665us/step - loss: 0.4994 - val_loss: 4.2134\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 540us/step - loss: 0.4968 - val_loss: 4.5193\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.5168 - val_loss: 5.2105\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.5213 - val_loss: 5.3114\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.5123 - val_loss: 4.5589\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.5071 - val_loss: 3.6740\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 593us/step - loss: 0.5070 - val_loss: 3.0881\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.5266 - val_loss: 2.7878\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.5289 - val_loss: 3.4371\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 0.5102 - val_loss: 4.1253\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.4915 - val_loss: 3.7197\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.4994 - val_loss: 2.7984\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 560us/step - loss: 0.5247 - val_loss: 2.5370\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 0.5406 - val_loss: 2.6911\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 565us/step - loss: 0.5194 - val_loss: 3.3553\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.4894 - val_loss: 4.4352\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 0.4962 - val_loss: 5.2188\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 548us/step - loss: 0.5197 - val_loss: 4.9644\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 582us/step - loss: 0.4831 - val_loss: 3.6441\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 570us/step - loss: 0.4812 - val_loss: 2.3314\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 578us/step - loss: 0.5750 - val_loss: 1.8654\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 566us/step - loss: 0.5719 - val_loss: 2.7113\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 606us/step - loss: 0.5017 - val_loss: 4.2936\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.4765 - val_loss: 5.3282\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.5308 - val_loss: 5.5952\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 555us/step - loss: 0.5361 - val_loss: 4.8853\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 586us/step - loss: 0.5000 - val_loss: 4.3996\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.4842 - val_loss: 3.9380\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 0.4753 - val_loss: 3.2685\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 595us/step - loss: 0.4837 - val_loss: 3.0868\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 585us/step - loss: 0.4944 - val_loss: 3.0653\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 537us/step - loss: 0.4797 - val_loss: 3.7247\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.4765 - val_loss: 4.4266\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 639us/step - loss: 0.4864 - val_loss: 4.4408\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.4850 - val_loss: 4.1392\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 638us/step - loss: 0.4821 - val_loss: 4.0914\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 0.4765 - val_loss: 4.2775\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 535us/step - loss: 0.4841 - val_loss: 4.0634\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 550us/step - loss: 0.4801 - val_loss: 2.9785\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 603us/step - loss: 0.4923 - val_loss: 2.8054\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.4800 - val_loss: 3.3284\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 529us/step - loss: 0.4690 - val_loss: 3.7379\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 591us/step - loss: 0.4705 - val_loss: 3.9885\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 536us/step - loss: 0.4712 - val_loss: 3.8780\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 573us/step - loss: 0.4681 - val_loss: 3.6428\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 567us/step - loss: 0.4671 - val_loss: 3.3556\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 561us/step - loss: 0.4693 - val_loss: 2.5461\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 580us/step - loss: 0.5023 - val_loss: 2.0671\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 551us/step - loss: 0.5302 - val_loss: 2.2291\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 533us/step - loss: 0.5058 - val_loss: 2.8002\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 0.4724 - val_loss: 3.3884\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 0.4626 - val_loss: 4.0463\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 531us/step - loss: 0.4710 - val_loss: 4.0266\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 553us/step - loss: 0.4660 - val_loss: 3.6570\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 527us/step - loss: 0.4611 - val_loss: 3.2390\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 623us/step - loss: 0.4720 - val_loss: 2.5195\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.4977 - val_loss: 2.5140\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 0.4893 - val_loss: 3.4031\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 597us/step - loss: 0.4653 - val_loss: 4.0040\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 576us/step - loss: 0.4667 - val_loss: 3.9450\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 544us/step - loss: 0.4735 - val_loss: 3.4398\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 552us/step - loss: 0.4556 - val_loss: 3.1748\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 556us/step - loss: 0.4554 - val_loss: 2.7646\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 589us/step - loss: 0.4730 - val_loss: 2.5857\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 547us/step - loss: 0.4637 - val_loss: 3.0397\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 572us/step - loss: 0.4561 - val_loss: 3.3145\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 545us/step - loss: 0.4664 - val_loss: 3.8476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13f7f0d68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=2000, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[442.0501]\n",
      " [873.4851]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([30,60])\n",
    "test_input = test_input.reshape((2, 1, 1))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's try with stacked LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.LSTM(50,activation='relu',return_sequences=True,input_shape=(1,1))) # inputshape 1X1 because we have 1 timestamp and 1 feature\n",
    "model1.add(keras.layers.LSTM(50,activation='relu')) \n",
    "model1.add(keras.layers.Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1, 50)             10400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',loss='mse')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 21024.0827 - val_loss: 77205.5625\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 21013.6370 - val_loss: 77167.2969\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 21002.3416 - val_loss: 77126.3828\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 20990.6399 - val_loss: 77075.1797\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 20975.4011 - val_loss: 77010.3125\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 20958.2767 - val_loss: 76926.8906\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 20938.3113 - val_loss: 76818.2500\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 20907.8865 - val_loss: 76680.0312\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 20876.1433 - val_loss: 76493.8516\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 20827.1331 - val_loss: 76254.8125\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 20773.6718 - val_loss: 75913.2812\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 20690.6638 - val_loss: 75457.0859\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 20598.8754 - val_loss: 74849.8438\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 20469.3981 - val_loss: 74098.4219\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 20302.3538 - val_loss: 73146.3125\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 20074.3257 - val_loss: 71960.8047\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 19787.1721 - val_loss: 70498.2500\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 19475.6037 - val_loss: 68807.5859\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 19071.3609 - val_loss: 67010.8750\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 18613.5343 - val_loss: 65085.8203\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 18106.6989 - val_loss: 62923.8906\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 17610.9024 - val_loss: 60351.2188\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 16923.4046 - val_loss: 57607.4141\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 16148.3364 - val_loss: 54731.1758\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 15368.2291 - val_loss: 51451.4102\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 14486.4362 - val_loss: 47783.3945\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 13569.5743 - val_loss: 43715.2852\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 12561.8684 - val_loss: 39480.2188\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 11458.9310 - val_loss: 35256.8828\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 10322.3235 - val_loss: 30984.4512\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 9300.8515 - val_loss: 26877.8359\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 8236.0654 - val_loss: 22766.2793\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 7052.8947 - val_loss: 18689.1406\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 916us/step - loss: 6012.5743 - val_loss: 14756.9795\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 5028.2063 - val_loss: 11313.4570\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 913us/step - loss: 4049.0217 - val_loss: 8291.0166\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 3203.2827 - val_loss: 5854.7344\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 2469.1987 - val_loss: 3833.7209\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 1836.3472 - val_loss: 2249.9614\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 1334.4606 - val_loss: 1130.8345\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 899.6965 - val_loss: 442.2676\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 608.6123 - val_loss: 91.1102\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 408.3445 - val_loss: 8.2650\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 905us/step - loss: 277.8690 - val_loss: 90.7161\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 204.2367 - val_loss: 251.1403\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 167.5744 - val_loss: 434.8401\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 151.2532 - val_loss: 600.8099\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 149.0540 - val_loss: 735.5265\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 148.1096 - val_loss: 831.3387\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 149.2134 - val_loss: 891.4295\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 149.0047 - val_loss: 923.0852\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 149.5268 - val_loss: 935.7897\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 148.6603 - val_loss: 918.2728\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 147.2854 - val_loss: 896.2990\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 145.7592 - val_loss: 802.3996\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 139.9075 - val_loss: 710.9155\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 137.3290 - val_loss: 628.5897\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 136.6699 - val_loss: 576.9536\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 136.0421 - val_loss: 557.5760\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 135.3868 - val_loss: 548.9797\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 135.0329 - val_loss: 568.7411\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 924us/step - loss: 132.9335 - val_loss: 583.3352\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 131.6001 - val_loss: 592.2110\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 895us/step - loss: 130.4425 - val_loss: 599.9905\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 129.6062 - val_loss: 605.7627\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 128.3026 - val_loss: 622.7032\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 127.6344 - val_loss: 648.3873\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 944us/step - loss: 126.8480 - val_loss: 653.8143\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 125.7534 - val_loss: 628.5979\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 124.6227 - val_loss: 610.0008\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 762us/step - loss: 123.9927 - val_loss: 580.0735\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 122.6583 - val_loss: 574.0883\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 121.6866 - val_loss: 584.6643\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 120.8569 - val_loss: 596.6938\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 120.4616 - val_loss: 615.5977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 118.8411 - val_loss: 617.0454\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 117.9750 - val_loss: 617.0455\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 116.9888 - val_loss: 616.3875\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 116.2131 - val_loss: 615.7529\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 115.5244 - val_loss: 615.3969\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 114.0704 - val_loss: 574.0540\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 112.9944 - val_loss: 547.1754\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 111.8725 - val_loss: 534.6132\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 110.8313 - val_loss: 536.5247\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 110.0470 - val_loss: 545.0183\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 108.9506 - val_loss: 551.7951\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 108.2096 - val_loss: 571.2489\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 107.6897 - val_loss: 590.4598\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 107.6106 - val_loss: 613.7762\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 106.7641 - val_loss: 622.5913\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 106.2041 - val_loss: 618.7331\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 105.1546 - val_loss: 585.9841\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 103.8501 - val_loss: 568.6600\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 103.7389 - val_loss: 509.5168\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 100.6724 - val_loss: 469.4746\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 99.7218 - val_loss: 420.6545\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 101.1052 - val_loss: 367.3636\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 100.0870 - val_loss: 345.0306\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 99.4404 - val_loss: 339.1791\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 98.5622 - val_loss: 349.8277\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 96.6309 - val_loss: 377.3229\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 95.6631 - val_loss: 412.9065\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 94.0550 - val_loss: 432.8438\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 93.2456 - val_loss: 420.9129\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 92.0476 - val_loss: 424.6338\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 749us/step - loss: 91.1476 - val_loss: 436.0061\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 90.3229 - val_loss: 432.1514\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 89.5014 - val_loss: 434.6019\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 89.3551 - val_loss: 436.0266\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 87.8384 - val_loss: 394.6393\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 89.9799 - val_loss: 332.9982\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 88.1179 - val_loss: 316.9972\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 87.1988 - val_loss: 328.1270\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 85.8764 - val_loss: 327.7982\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 85.1203 - val_loss: 333.6624\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 84.2349 - val_loss: 351.0662\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 82.7736 - val_loss: 370.3828\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 81.8691 - val_loss: 395.2021\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 81.0259 - val_loss: 421.4677\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 81.6268 - val_loss: 451.8530\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 80.4398 - val_loss: 457.8068\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 80.1716 - val_loss: 453.1069\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 79.4937 - val_loss: 461.7278\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 78.9233 - val_loss: 448.7917\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 77.4581 - val_loss: 402.2935\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 76.1565 - val_loss: 375.9035\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 75.7546 - val_loss: 358.9024\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 74.8113 - val_loss: 350.9802\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 73.6133 - val_loss: 317.6389\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 73.5789 - val_loss: 296.1469\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 73.0411 - val_loss: 286.9585\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 72.3638 - val_loss: 288.2920\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 71.6626 - val_loss: 285.4712\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 70.7315 - val_loss: 293.1046\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 69.8119 - val_loss: 309.3909\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 69.0329 - val_loss: 332.9662\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 68.0298 - val_loss: 351.8516\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 67.3670 - val_loss: 371.1752\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 67.1719 - val_loss: 392.4724\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 67.0927 - val_loss: 403.2921\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 66.9519 - val_loss: 395.1131\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 66.4001 - val_loss: 355.0823\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 64.5558 - val_loss: 339.8356\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 64.0837 - val_loss: 322.2066\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 63.1781 - val_loss: 315.0251\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 62.4648 - val_loss: 293.4340\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 61.7925 - val_loss: 280.9102\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 61.0776 - val_loss: 261.9354\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 61.8374 - val_loss: 233.6650\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 61.1149 - val_loss: 222.4828\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 60.6324 - val_loss: 227.6891\n",
      "Epoch 152/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 823us/step - loss: 60.0529 - val_loss: 246.6493\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 58.8662 - val_loss: 259.6428\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 58.7268 - val_loss: 274.0515\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 57.4740 - val_loss: 275.2296\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 56.7903 - val_loss: 279.3270\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 56.5894 - val_loss: 294.7455\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 55.8678 - val_loss: 291.7879\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 55.8525 - val_loss: 262.5847\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 54.5023 - val_loss: 256.0493\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 918us/step - loss: 53.9644 - val_loss: 258.0857\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 53.3153 - val_loss: 260.2975\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 957us/step - loss: 52.8086 - val_loss: 252.9849\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 52.3231 - val_loss: 263.3791\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 51.4545 - val_loss: 271.1693\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 51.7040 - val_loss: 273.3466\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 49.7397 - val_loss: 238.1658\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 49.5714 - val_loss: 204.6266\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 49.5573 - val_loss: 195.6473\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 49.0986 - val_loss: 199.5239\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 48.6070 - val_loss: 205.8306\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 47.6338 - val_loss: 185.4830\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 47.7621 - val_loss: 155.0311\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 48.5799 - val_loss: 135.0372\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 48.8959 - val_loss: 134.6931\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 47.6960 - val_loss: 148.3577\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 46.2066 - val_loss: 157.1599\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 44.6871 - val_loss: 178.6387\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 919us/step - loss: 43.8976 - val_loss: 209.6273\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 42.6989 - val_loss: 229.0795\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 42.4034 - val_loss: 247.4220\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 42.9414 - val_loss: 263.0602\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 42.5292 - val_loss: 268.9749\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 42.5024 - val_loss: 273.2821\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 42.2196 - val_loss: 267.7972\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 41.5983 - val_loss: 247.8043\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 40.4155 - val_loss: 235.7592\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 39.7948 - val_loss: 226.2322\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 39.3664 - val_loss: 218.7559\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 38.6470 - val_loss: 214.5549\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 38.1406 - val_loss: 209.7278\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 37.6754 - val_loss: 204.2130\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 37.0338 - val_loss: 179.2277\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 36.5898 - val_loss: 162.5727\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 36.1577 - val_loss: 156.5062\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 35.7160 - val_loss: 161.2346\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 35.0696 - val_loss: 170.6447\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 34.6839 - val_loss: 180.6857\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 34.4432 - val_loss: 194.2247\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 34.1061 - val_loss: 202.7108\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 33.9903 - val_loss: 202.1994\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 33.6506 - val_loss: 199.1328\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 33.2499 - val_loss: 198.0173\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 32.9947 - val_loss: 193.5062\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 32.4220 - val_loss: 194.4221\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 32.1254 - val_loss: 191.7336\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 31.8785 - val_loss: 188.8399\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 31.3284 - val_loss: 177.2523\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 30.8949 - val_loss: 161.9086\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 30.1166 - val_loss: 147.8842\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 29.9990 - val_loss: 117.5851\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 29.7188 - val_loss: 110.6546\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 29.4033 - val_loss: 114.7330\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 28.7734 - val_loss: 122.5064\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 28.4082 - val_loss: 133.7199\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 27.8702 - val_loss: 144.1672\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 27.5383 - val_loss: 148.8224\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 942us/step - loss: 27.2412 - val_loss: 154.7353\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 764us/step - loss: 27.0767 - val_loss: 158.7833\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 26.9640 - val_loss: 162.7690\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 26.7156 - val_loss: 159.4284\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 26.3673 - val_loss: 149.3768\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 25.3637 - val_loss: 119.8456\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 25.0340 - val_loss: 102.9289\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 25.3700 - val_loss: 85.1193\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 25.0268 - val_loss: 82.9020\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 24.6269 - val_loss: 90.8101\n",
      "Epoch 228/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 859us/step - loss: 23.8222 - val_loss: 101.9696\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 23.2933 - val_loss: 117.2718\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 22.8860 - val_loss: 127.2942\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 22.7722 - val_loss: 130.7674\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 22.6793 - val_loss: 135.3481\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 22.4672 - val_loss: 131.4227\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 22.0177 - val_loss: 115.0335\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 21.5511 - val_loss: 101.2662\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 21.2552 - val_loss: 94.4258\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 21.0173 - val_loss: 96.7488\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 20.5529 - val_loss: 90.9390\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 20.3187 - val_loss: 94.5250\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 19.9259 - val_loss: 98.6974\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 19.6746 - val_loss: 106.3289\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 19.4446 - val_loss: 112.7328\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 19.7156 - val_loss: 113.3547\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 19.0132 - val_loss: 92.6344\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 18.6585 - val_loss: 80.6974\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 18.3097 - val_loss: 75.1263\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 17.9993 - val_loss: 78.1274\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 17.7271 - val_loss: 81.7543\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 17.4481 - val_loss: 78.8837\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 17.3952 - val_loss: 74.4195\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 17.0296 - val_loss: 74.1071\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 16.7923 - val_loss: 75.0335\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 16.6061 - val_loss: 80.4216\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 16.5236 - val_loss: 83.3712\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 16.4550 - val_loss: 68.9811\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 15.8438 - val_loss: 63.0795\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 15.6498 - val_loss: 62.4045\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 15.3097 - val_loss: 65.3837\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 15.1962 - val_loss: 70.1755\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 14.9496 - val_loss: 70.6909\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 14.5986 - val_loss: 59.7192\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 14.4642 - val_loss: 55.1247\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 14.2454 - val_loss: 54.4542\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 14.0331 - val_loss: 51.8100\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 13.8376 - val_loss: 44.2160\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 14.0211 - val_loss: 35.3526\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 14.0547 - val_loss: 36.2033\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 13.6023 - val_loss: 43.3631\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 12.9764 - val_loss: 54.3846\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 12.7572 - val_loss: 63.2643\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 765us/step - loss: 12.5914 - val_loss: 57.9318\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 12.2524 - val_loss: 52.9321\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 12.0063 - val_loss: 52.7873\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 11.8462 - val_loss: 53.8801\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 11.7211 - val_loss: 56.4248\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 11.4983 - val_loss: 56.5534\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 11.3258 - val_loss: 58.9290\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 11.2006 - val_loss: 58.7525\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 11.0753 - val_loss: 59.2739\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 10.8885 - val_loss: 57.3637\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 10.6727 - val_loss: 55.8133\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 10.5547 - val_loss: 51.9413\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 10.2629 - val_loss: 51.8526\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 10.0876 - val_loss: 48.8281\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 9.9686 - val_loss: 42.1645\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 9.6230 - val_loss: 38.4426\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 9.5106 - val_loss: 35.6800\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 9.3413 - val_loss: 35.2440\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 9.2023 - val_loss: 35.8013\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 9.1268 - val_loss: 39.1175\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 8.9070 - val_loss: 38.9370\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 8.7654 - val_loss: 39.9145\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 8.7037 - val_loss: 40.2300\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 971us/step - loss: 8.5565 - val_loss: 37.8245\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 8.3691 - val_loss: 34.5616\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 8.2050 - val_loss: 27.2286\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 8.2424 - val_loss: 22.9994\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 8.2735 - val_loss: 21.6494\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 771us/step - loss: 8.0591 - val_loss: 24.0307\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 7.8167 - val_loss: 26.7843\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 7.6057 - val_loss: 30.0076\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 7.6227 - val_loss: 33.2541\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 7.4702 - val_loss: 32.2437\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 7.3696 - val_loss: 32.4431\n",
      "Epoch 305/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 749us/step - loss: 7.2646 - val_loss: 29.7610\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 7.0042 - val_loss: 22.7054\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 6.9729 - val_loss: 19.1243\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 770us/step - loss: 7.1317 - val_loss: 14.1527\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 7.0719 - val_loss: 14.2767\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 6.8386 - val_loss: 17.6890\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 6.6654 - val_loss: 23.2932\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 6.3326 - val_loss: 26.4101\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 6.3212 - val_loss: 28.2709\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 6.2721 - val_loss: 26.2786\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 6.0897 - val_loss: 22.8950\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 778us/step - loss: 6.0367 - val_loss: 19.2910\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 5.9493 - val_loss: 17.4109\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 5.8088 - val_loss: 18.1584\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 5.7007 - val_loss: 18.9518\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 768us/step - loss: 5.6075 - val_loss: 18.5817\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 5.5251 - val_loss: 16.9916\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 5.4469 - val_loss: 17.0933\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 5.3434 - val_loss: 14.9752\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 5.3815 - val_loss: 12.5781\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 5.2483 - val_loss: 13.7359\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 5.0678 - val_loss: 15.7955\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 4.9357 - val_loss: 18.1201\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 4.9491 - val_loss: 20.1479\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 4.9461 - val_loss: 19.5858\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 4.8373 - val_loss: 14.1831\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 762us/step - loss: 4.7274 - val_loss: 12.1192\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 4.5762 - val_loss: 11.7939\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 4.4975 - val_loss: 9.6703\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 4.4298 - val_loss: 9.8409\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 4.3047 - val_loss: 10.8232\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 4.2351 - val_loss: 12.9399\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 4.1426 - val_loss: 14.5129\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 4.1030 - val_loss: 15.1733\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 4.0268 - val_loss: 12.9025\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 4.0127 - val_loss: 8.4930\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 3.8567 - val_loss: 7.1646\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 3.8211 - val_loss: 5.7512\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 3.9078 - val_loss: 4.8600\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 3.8368 - val_loss: 5.8498\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 3.6371 - val_loss: 7.2931\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 3.5010 - val_loss: 9.5871\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 3.5207 - val_loss: 12.2535\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 3.4513 - val_loss: 13.4882\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 3.4987 - val_loss: 13.6609\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 3.3778 - val_loss: 10.5737\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 3.2834 - val_loss: 7.6924\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 3.1164 - val_loss: 6.5452\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 3.0724 - val_loss: 6.6219\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 3.0061 - val_loss: 7.1389\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 2.9744 - val_loss: 8.0437\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 2.9640 - val_loss: 7.8634\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 2.8683 - val_loss: 6.1830\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 2.8508 - val_loss: 4.4582\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 2.7967 - val_loss: 3.8485\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 2.7828 - val_loss: 3.9130\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 2.7185 - val_loss: 4.4152\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 2.6587 - val_loss: 4.6515\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 2.6210 - val_loss: 4.6383\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 2.5746 - val_loss: 4.0552\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 2.5507 - val_loss: 3.7883\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 2.5046 - val_loss: 4.4286\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 2.4718 - val_loss: 5.5892\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 2.4527 - val_loss: 6.0775\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 2.3915 - val_loss: 4.4956\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 2.4039 - val_loss: 2.5865\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 2.3391 - val_loss: 1.7976\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 2.3478 - val_loss: 1.6334\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 2.2790 - val_loss: 2.2789\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 2.2059 - val_loss: 3.2385\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 2.1890 - val_loss: 4.0325\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 2.1435 - val_loss: 3.5022\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 754us/step - loss: 2.0959 - val_loss: 3.3142\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 755us/step - loss: 2.0809 - val_loss: 3.4344\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 2.0334 - val_loss: 3.4569\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 756us/step - loss: 2.0094 - val_loss: 3.1576\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 1.9587 - val_loss: 2.2891\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 1.9259 - val_loss: 1.7789\n",
      "Epoch 383/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 779us/step - loss: 1.9101 - val_loss: 1.1957\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 1.8992 - val_loss: 1.2601\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 1.8459 - val_loss: 1.5707\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 1.8428 - val_loss: 1.9424\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 736us/step - loss: 1.7868 - val_loss: 1.6698\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 762us/step - loss: 1.7778 - val_loss: 0.9782\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 770us/step - loss: 1.7431 - val_loss: 1.0161\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 1.6965 - val_loss: 1.4411\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 760us/step - loss: 1.6699 - val_loss: 2.0333\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 754us/step - loss: 1.6624 - val_loss: 2.4330\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 1.6762 - val_loss: 2.5189\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 761us/step - loss: 1.6281 - val_loss: 1.9677\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 1.5915 - val_loss: 1.0356\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 1.5426 - val_loss: 0.8234\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 770us/step - loss: 1.5320 - val_loss: 0.7257\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 1.5282 - val_loss: 0.4103\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 1.5038 - val_loss: 0.4521\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 737us/step - loss: 1.4725 - val_loss: 0.6631\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.4325 - val_loss: 0.6521\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 1.4101 - val_loss: 0.6677\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 1.3850 - val_loss: 0.8776\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 1.3952 - val_loss: 1.2371\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 755us/step - loss: 1.3746 - val_loss: 1.3212\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 1.3700 - val_loss: 1.2743\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 1.3537 - val_loss: 1.0173\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 1.3150 - val_loss: 0.7351\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 771us/step - loss: 1.2932 - val_loss: 0.4942\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 1.2747 - val_loss: 0.4166\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 1.2603 - val_loss: 0.3454\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 1.2516 - val_loss: 0.3218\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.2445 - val_loss: 0.2717\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 1.2226 - val_loss: 0.3692\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 1.2131 - val_loss: 0.5184\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 1.2130 - val_loss: 0.5767\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 1.1980 - val_loss: 0.6502\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 1.1942 - val_loss: 0.7626\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 1.1967 - val_loss: 0.8474\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 1.2028 - val_loss: 0.7539\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 1.1387 - val_loss: 0.2760\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 1.1291 - val_loss: 0.0675\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 1.1354 - val_loss: 0.1180\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 1.1649 - val_loss: 0.1167\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 1.1397 - val_loss: 0.0743\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 1.0816 - val_loss: 0.0788\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 1.0678 - val_loss: 0.1668\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.0495 - val_loss: 0.2402\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 1.0451 - val_loss: 0.1962\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 1.0256 - val_loss: 0.1206\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.0237 - val_loss: 0.0853\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 905us/step - loss: 1.0120 - val_loss: 0.0827\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 1.0000 - val_loss: 0.0961\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.9885 - val_loss: 0.1063\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.9810 - val_loss: 0.1061\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 927us/step - loss: 0.9742 - val_loss: 0.1087\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.9673 - val_loss: 0.1037\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.9603 - val_loss: 0.0959\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.9524 - val_loss: 0.0977\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.9478 - val_loss: 0.1195\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.9431 - val_loss: 0.1075\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.9303 - val_loss: 0.0983\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.9219 - val_loss: 0.1316\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.9202 - val_loss: 0.1419\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.9101 - val_loss: 0.1187\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.9006 - val_loss: 0.1074\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.8973 - val_loss: 0.1045\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.8921 - val_loss: 0.1059\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.8830 - val_loss: 0.1114\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.8769 - val_loss: 0.1102\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.8700 - val_loss: 0.1068\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.8706 - val_loss: 0.1085\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.8604 - val_loss: 0.1487\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.8402 - val_loss: 0.2912\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.8602 - val_loss: 0.4976\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.8632 - val_loss: 0.4800\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.8484 - val_loss: 0.2809\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.8077 - val_loss: 0.1597\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.8133 - val_loss: 0.1297\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.8185 - val_loss: 0.1605\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.8040 - val_loss: 0.1980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.7895 - val_loss: 0.2496\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.7838 - val_loss: 0.3229\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.7769 - val_loss: 0.4052\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.7753 - val_loss: 0.4653\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.7761 - val_loss: 0.4676\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.7675 - val_loss: 0.3697\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.7570 - val_loss: 0.2933\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7766 - val_loss: 0.2204\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.7577 - val_loss: 0.2830\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 919us/step - loss: 0.7478 - val_loss: 0.3161\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.7424 - val_loss: 0.3383\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.7317 - val_loss: 0.4807\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.7349 - val_loss: 0.6914\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.7351 - val_loss: 0.7865\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.7278 - val_loss: 0.6276\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.7172 - val_loss: 0.4408\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7121 - val_loss: 0.4029\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.7118 - val_loss: 0.3655\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.7088 - val_loss: 0.4652\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.6939 - val_loss: 0.6852\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.6992 - val_loss: 0.9816\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.7046 - val_loss: 1.0273\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.7019 - val_loss: 1.0644\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.7009 - val_loss: 1.0552\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.6928 - val_loss: 0.9353\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.6864 - val_loss: 0.8197\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.6768 - val_loss: 0.7953\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.6734 - val_loss: 0.7709\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.6708 - val_loss: 0.7540\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.6682 - val_loss: 0.8731\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.6669 - val_loss: 0.9467\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.6658 - val_loss: 1.0711\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.6648 - val_loss: 1.0413\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.6602 - val_loss: 1.0651\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.6583 - val_loss: 1.1070\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.6559 - val_loss: 1.0908\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.6546 - val_loss: 0.9635\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 949us/step - loss: 0.6461 - val_loss: 0.9158\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 779us/step - loss: 0.6432 - val_loss: 0.8415\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.6404 - val_loss: 0.9013\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.6375 - val_loss: 1.0321\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 916us/step - loss: 0.6369 - val_loss: 1.0319\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.6328 - val_loss: 1.1337\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.6318 - val_loss: 1.2872\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.6347 - val_loss: 1.3257\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.6308 - val_loss: 1.1539\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.6222 - val_loss: 1.0355\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.6265 - val_loss: 0.9077\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.6207 - val_loss: 0.9995\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.6166 - val_loss: 1.2611\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.6135 - val_loss: 1.4860\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.6222 - val_loss: 1.6253\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 0.6214 - val_loss: 1.4539\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.6072 - val_loss: 1.0471\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.6053 - val_loss: 0.8054\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.6135 - val_loss: 0.8763\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.6070 - val_loss: 0.9126\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.6058 - val_loss: 0.9637\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.6035 - val_loss: 1.1848\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.5918 - val_loss: 1.2502\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.5890 - val_loss: 1.3654\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.5886 - val_loss: 1.5552\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.5869 - val_loss: 1.4461\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.5872 - val_loss: 1.3155\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.5792 - val_loss: 1.4040\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.5775 - val_loss: 1.4566\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.5774 - val_loss: 1.5392\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.5742 - val_loss: 1.4202\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.5722 - val_loss: 1.3615\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.5693 - val_loss: 1.4872\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.5681 - val_loss: 1.4135\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.5651 - val_loss: 1.4277\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.5639 - val_loss: 1.5111\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.5587 - val_loss: 1.6998\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.5589 - val_loss: 1.9122\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.5649 - val_loss: 2.0020\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.5594 - val_loss: 1.7397\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 0.5483 - val_loss: 1.3363\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.5599 - val_loss: 1.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.5618 - val_loss: 1.2408\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.5437 - val_loss: 1.7336\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.5521 - val_loss: 2.2126\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.5569 - val_loss: 2.3382\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.5560 - val_loss: 2.2298\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.5482 - val_loss: 2.0792\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.5390 - val_loss: 1.7732\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.5321 - val_loss: 1.4354\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.5346 - val_loss: 1.2711\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.5425 - val_loss: 1.3011\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.5367 - val_loss: 1.7113\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.5320 - val_loss: 1.9124\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.5275 - val_loss: 1.8307\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.5252 - val_loss: 1.6179\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.5210 - val_loss: 1.4413\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.5244 - val_loss: 1.3492\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5289 - val_loss: 1.3502\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.5305 - val_loss: 1.4446\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5232 - val_loss: 1.6353\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.5153 - val_loss: 1.7540\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.5139 - val_loss: 1.9448\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.5106 - val_loss: 2.0333\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.5075 - val_loss: 2.0006\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.5091 - val_loss: 1.8528\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.5046 - val_loss: 2.0406\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.5040 - val_loss: 2.3885\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.5055 - val_loss: 2.5439\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.5044 - val_loss: 2.5315\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.5020 - val_loss: 2.4773\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.4998 - val_loss: 2.3568\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.4943 - val_loss: 2.0748\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.4895 - val_loss: 1.7908\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.5042 - val_loss: 1.5231\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.5117 - val_loss: 1.5542\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.5019 - val_loss: 1.9276\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.4876 - val_loss: 2.5031\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.4879 - val_loss: 2.6724\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.4914 - val_loss: 2.4609\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.4844 - val_loss: 2.4691\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.4812 - val_loss: 2.5352\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.4809 - val_loss: 2.5790\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.4800 - val_loss: 2.5452\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.4775 - val_loss: 2.4857\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.4767 - val_loss: 2.2797\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.4737 - val_loss: 2.3584\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.4723 - val_loss: 2.4241\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.4731 - val_loss: 2.5143\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.4732 - val_loss: 2.3479\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.4681 - val_loss: 2.4838\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.4685 - val_loss: 2.7339\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.4706 - val_loss: 2.8707\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.4675 - val_loss: 2.7151\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.4630 - val_loss: 2.4993\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.4604 - val_loss: 2.1223\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.4613 - val_loss: 2.2223\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.4587 - val_loss: 2.5654\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.4578 - val_loss: 2.6304\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 928us/step - loss: 0.4550 - val_loss: 2.4830\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 774us/step - loss: 0.4557 - val_loss: 2.2253\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.4548 - val_loss: 2.0932\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.4558 - val_loss: 2.0301\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.4587 - val_loss: 1.9645\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.4591 - val_loss: 2.1056\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.4541 - val_loss: 2.7320\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.4496 - val_loss: 3.2020\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.4543 - val_loss: 3.1658\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.4515 - val_loss: 3.0788\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 0.4476 - val_loss: 3.0281\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.4453 - val_loss: 2.9583\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 943us/step - loss: 0.4440 - val_loss: 2.8141\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.4413 - val_loss: 2.8415\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.4391 - val_loss: 2.7255\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.4382 - val_loss: 2.6688\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.4381 - val_loss: 2.7403\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.4388 - val_loss: 3.1442\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.4396 - val_loss: 3.1707\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.4361 - val_loss: 2.8259\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.4385 - val_loss: 2.2703\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.4389 - val_loss: 2.5178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.4355 - val_loss: 3.0642\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.4336 - val_loss: 3.1423\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.4323 - val_loss: 2.9944\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.4295 - val_loss: 3.0086\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.4301 - val_loss: 3.1609\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.4294 - val_loss: 3.1594\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.4280 - val_loss: 3.0456\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.4296 - val_loss: 2.7647\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.4249 - val_loss: 2.8934\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.4237 - val_loss: 2.9194\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.4208 - val_loss: 3.2161\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.4227 - val_loss: 3.3844\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.4239 - val_loss: 3.1998\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 767us/step - loss: 0.4194 - val_loss: 2.9573\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 727us/step - loss: 0.4200 - val_loss: 2.7303\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 770us/step - loss: 0.4206 - val_loss: 2.6870\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.4281 - val_loss: 2.3888\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.4243 - val_loss: 2.6731\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.4153 - val_loss: 3.2722\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.4231 - val_loss: 3.5682\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.4171 - val_loss: 2.9002\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.4150 - val_loss: 2.5806\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 0.4164 - val_loss: 2.8637\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.4119 - val_loss: 3.1695\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.4110 - val_loss: 3.0869\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 741us/step - loss: 0.4114 - val_loss: 2.7532\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.4098 - val_loss: 2.6452\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.4122 - val_loss: 2.7091\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.4140 - val_loss: 3.1363\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.4053 - val_loss: 3.1518\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.4056 - val_loss: 3.1900\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.4030 - val_loss: 3.0651\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.4038 - val_loss: 3.0221\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.4009 - val_loss: 3.2594\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.4069 - val_loss: 3.7337\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.4077 - val_loss: 3.6497\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.4051 - val_loss: 3.4002\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.3974 - val_loss: 3.4320\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.3973 - val_loss: 3.4360\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.3958 - val_loss: 3.2848\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.3921 - val_loss: 3.0125\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.3910 - val_loss: 2.9845\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.3898 - val_loss: 3.0227\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.3890 - val_loss: 3.0623\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3867 - val_loss: 3.3289\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.3877 - val_loss: 3.2293\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.3853 - val_loss: 3.0640\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.3854 - val_loss: 2.9661\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.3843 - val_loss: 3.3476\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.3854 - val_loss: 3.7322\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.3882 - val_loss: 3.4967\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.3844 - val_loss: 3.3317\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.3801 - val_loss: 2.9201\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.3843 - val_loss: 2.6507\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.3910 - val_loss: 2.7112\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.3885 - val_loss: 3.5345\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.3872 - val_loss: 4.0309\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.3878 - val_loss: 3.6918\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.3776 - val_loss: 3.5522\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.3818 - val_loss: 3.2473\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.3744 - val_loss: 3.5104\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 764us/step - loss: 0.3735 - val_loss: 3.3755\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.3751 - val_loss: 3.1721\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.3712 - val_loss: 3.3545\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.3694 - val_loss: 3.2467\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.3696 - val_loss: 2.9955\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.3761 - val_loss: 2.8679\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.3723 - val_loss: 3.2283\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.3632 - val_loss: 3.7087\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.3672 - val_loss: 4.2690\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.3789 - val_loss: 4.2036\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.3659 - val_loss: 3.5724\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.3589 - val_loss: 3.2541\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.3589 - val_loss: 3.2056\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.3568 - val_loss: 3.4900\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.3618 - val_loss: 3.8683\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 0.3576 - val_loss: 3.7162\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 755us/step - loss: 0.3610 - val_loss: 3.2402\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.3517 - val_loss: 3.3324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.3518 - val_loss: 3.3169\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.3483 - val_loss: 3.6388\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.3494 - val_loss: 3.9166\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.3518 - val_loss: 3.9988\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.3532 - val_loss: 3.8588\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.3514 - val_loss: 3.8674\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.3533 - val_loss: 3.3895\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 0.3465 - val_loss: 3.2456\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 965us/step - loss: 0.3446 - val_loss: 3.4122\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.3433 - val_loss: 3.4862\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.3427 - val_loss: 3.5976\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.3415 - val_loss: 3.4447\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.3396 - val_loss: 3.2464\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 0.3436 - val_loss: 3.1973\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3382 - val_loss: 3.6639\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.3407 - val_loss: 3.7200\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.3414 - val_loss: 3.1188\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.3426 - val_loss: 3.1904\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.3410 - val_loss: 3.3366\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.3390 - val_loss: 3.3854\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.3389 - val_loss: 3.5730\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.3354 - val_loss: 3.6699\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.3366 - val_loss: 3.6045\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.3328 - val_loss: 3.9503\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.3351 - val_loss: 3.9299\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.3350 - val_loss: 4.1461\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.3380 - val_loss: 4.2825\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.3387 - val_loss: 4.0673\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.3358 - val_loss: 3.5513\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.3300 - val_loss: 3.5967\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.3284 - val_loss: 3.7223\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.3290 - val_loss: 3.9357\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.3303 - val_loss: 3.9496\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.3281 - val_loss: 3.6680\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.3276 - val_loss: 3.1923\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.3330 - val_loss: 3.1043\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.3315 - val_loss: 3.4417\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3292 - val_loss: 4.1100\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.3294 - val_loss: 3.9727\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.3272 - val_loss: 3.7420\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.3254 - val_loss: 2.7990\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.3435 - val_loss: 2.6423\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.3481 - val_loss: 2.8698\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.3384 - val_loss: 3.6894\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.3193 - val_loss: 4.0343\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.3222 - val_loss: 4.1963\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.3237 - val_loss: 4.1697\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.3258 - val_loss: 3.6471\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.3234 - val_loss: 3.3934\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.3210 - val_loss: 3.9483\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.3178 - val_loss: 4.2081\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.3199 - val_loss: 4.1668\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.3195 - val_loss: 4.0371\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.3147 - val_loss: 3.6070\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.3168 - val_loss: 3.2366\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.3274 - val_loss: 3.2124\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.3197 - val_loss: 3.7044\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.3176 - val_loss: 4.5768\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.3217 - val_loss: 4.5244\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.3185 - val_loss: 4.1152\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.3143 - val_loss: 3.2954\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.3270 - val_loss: 2.9465\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.3324 - val_loss: 3.2015\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.3266 - val_loss: 3.3107\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.3144 - val_loss: 4.3187\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.3134 - val_loss: 4.5501\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.3143 - val_loss: 3.9669\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3210 - val_loss: 2.9287\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.3288 - val_loss: 3.2090\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3126 - val_loss: 3.9045\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.3123 - val_loss: 4.5814\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.3070 - val_loss: 3.7305\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.3066 - val_loss: 3.0856\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.3215 - val_loss: 3.0454\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.3158 - val_loss: 3.5911\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 930us/step - loss: 0.2972 - val_loss: 4.8955\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.3437 - val_loss: 5.6416\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.3366 - val_loss: 4.7004\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.3117 - val_loss: 3.5363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.3058 - val_loss: 3.5681\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.3061 - val_loss: 4.2858\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.3042 - val_loss: 4.9698\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.3232 - val_loss: 5.1116\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.3123 - val_loss: 4.3148\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.3035 - val_loss: 3.8247\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 0.2994 - val_loss: 4.0620\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.3108 - val_loss: 4.6924\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.3033 - val_loss: 4.2396\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.2995 - val_loss: 3.6461\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.3020 - val_loss: 3.5625\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.3034 - val_loss: 4.2079\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.2962 - val_loss: 4.5006\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.2997 - val_loss: 4.3795\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.2985 - val_loss: 3.7773\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.3015 - val_loss: 3.5105\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.3063 - val_loss: 3.7007\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.2991 - val_loss: 3.8194\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.2971 - val_loss: 4.0330\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.2988 - val_loss: 4.3404\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.2938 - val_loss: 4.2860\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.2948 - val_loss: 4.1035\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.2939 - val_loss: 4.1704\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.2933 - val_loss: 4.2301\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.2927 - val_loss: 4.4183\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.2977 - val_loss: 5.1176\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.3004 - val_loss: 5.1309\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.2998 - val_loss: 4.8126\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.2920 - val_loss: 4.4769\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.2895 - val_loss: 4.5122\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.2901 - val_loss: 4.9213\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.2950 - val_loss: 4.8317\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.2960 - val_loss: 4.9125\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2904 - val_loss: 4.3364\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.2914 - val_loss: 3.7897\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.2883 - val_loss: 4.1287\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.2840 - val_loss: 4.8627\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.2928 - val_loss: 4.4490\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 942us/step - loss: 0.2931 - val_loss: 3.0764\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3149 - val_loss: 3.4027\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.2778 - val_loss: 4.9844\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.2968 - val_loss: 6.2947\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.3358 - val_loss: 6.0146\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.3186 - val_loss: 4.9013\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.2801 - val_loss: 3.9942\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.2856 - val_loss: 3.2834\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.2972 - val_loss: 3.4546\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2900 - val_loss: 3.8514\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.2827 - val_loss: 4.1562\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.2820 - val_loss: 4.2888\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.2808 - val_loss: 4.1464\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.2826 - val_loss: 3.7788\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.2957 - val_loss: 3.2642\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.2915 - val_loss: 4.2095\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2774 - val_loss: 4.9739\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.2870 - val_loss: 5.4656\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.2980 - val_loss: 5.0786\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.2699 - val_loss: 3.7764\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.2857 - val_loss: 3.0508\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.3071 - val_loss: 3.2220\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.2848 - val_loss: 4.4372\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.2697 - val_loss: 5.6320\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.3199 - val_loss: 5.3680\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 902us/step - loss: 0.2743 - val_loss: 3.0389\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.3335 - val_loss: 2.4290\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.3274 - val_loss: 3.3408\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.2733 - val_loss: 4.3273\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.2817 - val_loss: 4.9147\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.2829 - val_loss: 4.6256\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.2772 - val_loss: 3.6676\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.2766 - val_loss: 3.6223\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.2750 - val_loss: 4.2537\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.2692 - val_loss: 4.6888\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.2745 - val_loss: 5.1646\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.2832 - val_loss: 4.8498\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.2728 - val_loss: 4.2837\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.2711 - val_loss: 4.0835\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2699 - val_loss: 4.0028\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.2656 - val_loss: 4.5995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.2750 - val_loss: 4.9539\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2828 - val_loss: 4.9685\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.2710 - val_loss: 4.1644\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2603 - val_loss: 3.3434\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2786 - val_loss: 3.2008\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.2809 - val_loss: 3.4494\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.2776 - val_loss: 3.3288\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.2721 - val_loss: 3.9728\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.2623 - val_loss: 4.5372\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.2746 - val_loss: 5.1812\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2767 - val_loss: 4.3638\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.2577 - val_loss: 3.2782\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.2989 - val_loss: 2.5633\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.2883 - val_loss: 4.0315\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 952us/step - loss: 0.2871 - val_loss: 5.7601\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 0.3026 - val_loss: 5.4304\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.2798 - val_loss: 4.3090\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.2690 - val_loss: 3.6144\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.2628 - val_loss: 3.8875\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.2623 - val_loss: 3.9950\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.2601 - val_loss: 4.2589\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.2582 - val_loss: 4.8949\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.2674 - val_loss: 4.8382\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.2683 - val_loss: 4.1980\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.2569 - val_loss: 4.1976\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.2568 - val_loss: 3.9328\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.2671 - val_loss: 3.7278\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2559 - val_loss: 4.6320\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.2589 - val_loss: 4.8586\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.2613 - val_loss: 4.6724\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.2589 - val_loss: 4.5344\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2549 - val_loss: 3.9033\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2635 - val_loss: 3.6256\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.2656 - val_loss: 4.4135\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.2577 - val_loss: 4.4752\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.2526 - val_loss: 3.9260\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.2610 - val_loss: 3.7995\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.2576 - val_loss: 4.1501\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.2556 - val_loss: 5.2973\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.2731 - val_loss: 5.1471\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.2579 - val_loss: 4.0010\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.2603 - val_loss: 3.1586\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 778us/step - loss: 0.2755 - val_loss: 3.2864\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 0.2602 - val_loss: 4.1391\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.2449 - val_loss: 5.0963\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 778us/step - loss: 0.2586 - val_loss: 5.1104\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 763us/step - loss: 0.2613 - val_loss: 4.6459\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2564 - val_loss: 4.2865\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 723us/step - loss: 0.2510 - val_loss: 4.6027\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.2491 - val_loss: 4.3141\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 723us/step - loss: 0.2500 - val_loss: 3.8824\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.2633 - val_loss: 3.8243\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.2559 - val_loss: 5.1662\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2618 - val_loss: 5.5458\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 757us/step - loss: 0.2653 - val_loss: 4.9961\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.2532 - val_loss: 4.1987\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.2434 - val_loss: 3.4233\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 769us/step - loss: 0.2653 - val_loss: 2.5434\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.3021 - val_loss: 3.1441\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.2472 - val_loss: 5.6012\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.3339 - val_loss: 6.9465\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.3237 - val_loss: 4.9792\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.2483 - val_loss: 3.5777\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2465 - val_loss: 2.9306\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 0.2748 - val_loss: 2.5214\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.3025 - val_loss: 3.0578\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.2515 - val_loss: 5.1661\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.2682 - val_loss: 5.6410\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.2708 - val_loss: 5.1798\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2543 - val_loss: 4.5735\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.2406 - val_loss: 3.8560\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.2449 - val_loss: 4.0086\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.2426 - val_loss: 4.0544\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.2401 - val_loss: 4.1168\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.2402 - val_loss: 4.2544\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.2393 - val_loss: 4.7330\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 777us/step - loss: 0.2443 - val_loss: 4.6946\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.2429 - val_loss: 4.7855\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.2499 - val_loss: 4.3964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.2351 - val_loss: 2.6208\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.3046 - val_loss: 2.7782\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.2471 - val_loss: 5.0776\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2532 - val_loss: 6.5224\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.3007 - val_loss: 4.9407\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.2578 - val_loss: 2.1699\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.3118 - val_loss: 2.9334\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.2465 - val_loss: 5.7986\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.3112 - val_loss: 6.3242\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.3005 - val_loss: 4.1412\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.2565 - val_loss: 3.0799\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.2508 - val_loss: 3.2517\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.2465 - val_loss: 3.6011\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.2360 - val_loss: 3.8704\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.2342 - val_loss: 3.8789\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.2418 - val_loss: 3.6551\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.2382 - val_loss: 3.9874\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 926us/step - loss: 0.2335 - val_loss: 5.0080\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.2571 - val_loss: 5.0789\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2404 - val_loss: 4.1600\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.2384 - val_loss: 4.1098\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.2360 - val_loss: 5.1335\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.2609 - val_loss: 5.5208\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2480 - val_loss: 4.2491\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2299 - val_loss: 3.7077\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.2379 - val_loss: 3.5577\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.2504 - val_loss: 2.9669\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.2517 - val_loss: 3.5524\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.2440 - val_loss: 4.4604\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.2375 - val_loss: 4.3088\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.2310 - val_loss: 4.6921\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.2349 - val_loss: 4.2387\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.2355 - val_loss: 3.7345\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.2360 - val_loss: 3.8625\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.2356 - val_loss: 4.9883\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.2381 - val_loss: 4.8381\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.2339 - val_loss: 4.1422\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.2525 - val_loss: 3.0277\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.2497 - val_loss: 3.3556\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.2332 - val_loss: 4.1077\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.2482 - val_loss: 5.6027\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.2624 - val_loss: 5.3201\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.2472 - val_loss: 4.6852\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2290 - val_loss: 3.8027\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 0.2313 - val_loss: 3.2323\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2439 - val_loss: 3.6485\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.2261 - val_loss: 5.1072\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2526 - val_loss: 5.1654\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.2464 - val_loss: 4.0813\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.2248 - val_loss: 4.2029\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.2239 - val_loss: 4.6620\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 913us/step - loss: 0.2308 - val_loss: 4.7438\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 738us/step - loss: 0.2268 - val_loss: 4.0887\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2217 - val_loss: 3.6167\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2264 - val_loss: 3.5284\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.2283 - val_loss: 3.8919\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.2200 - val_loss: 4.8049\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.2416 - val_loss: 5.4689\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2483 - val_loss: 4.7382\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.2263 - val_loss: 3.9395\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.2271 - val_loss: 3.2288\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.2261 - val_loss: 4.2599\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2373 - val_loss: 5.3529\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.2472 - val_loss: 4.7105\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 902us/step - loss: 0.2356 - val_loss: 3.4328\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2242 - val_loss: 3.1212\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.2363 - val_loss: 3.5266\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.2358 - val_loss: 5.4385\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.2487 - val_loss: 5.1752\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.2445 - val_loss: 3.9285\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.2197 - val_loss: 4.0943\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2266 - val_loss: 4.8680\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.2418 - val_loss: 4.9301\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.2279 - val_loss: 4.1089\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2179 - val_loss: 3.9743\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.2175 - val_loss: 4.1837\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.2207 - val_loss: 4.0403\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.2188 - val_loss: 3.7983\n",
      "Epoch 1014/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 870us/step - loss: 0.2322 - val_loss: 3.5097\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2185 - val_loss: 4.1663\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.2275 - val_loss: 4.9282\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.2289 - val_loss: 4.5780\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 934us/step - loss: 0.2229 - val_loss: 4.1835\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.2155 - val_loss: 4.0288\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.2154 - val_loss: 3.9633\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.2334 - val_loss: 4.5866\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.2240 - val_loss: 3.6887\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 895us/step - loss: 0.2151 - val_loss: 3.6808\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.2152 - val_loss: 4.1837\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.2156 - val_loss: 4.8789\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.2295 - val_loss: 4.7558\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 926us/step - loss: 0.2192 - val_loss: 3.6379\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.2214 - val_loss: 2.7874\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2389 - val_loss: 3.0907\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.2164 - val_loss: 4.3731\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.2112 - val_loss: 5.4577\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.2460 - val_loss: 4.6884\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.2029 - val_loss: 2.8398\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.2463 - val_loss: 2.9076\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.2065 - val_loss: 4.6893\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.2352 - val_loss: 5.1198\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.2272 - val_loss: 3.7461\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.2130 - val_loss: 2.8256\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2315 - val_loss: 3.1323\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 927us/step - loss: 0.2085 - val_loss: 4.5156\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.2479 - val_loss: 5.2448\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.2245 - val_loss: 3.6233\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.2212 - val_loss: 2.2333\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.2654 - val_loss: 2.6671\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.2220 - val_loss: 4.2338\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.2191 - val_loss: 4.7556\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 767us/step - loss: 0.2202 - val_loss: 3.8656\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2027 - val_loss: 3.2415\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.2197 - val_loss: 2.9181\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.2223 - val_loss: 3.5001\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.2274 - val_loss: 4.7346\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.2091 - val_loss: 3.5524\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.2090 - val_loss: 3.1133\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.2225 - val_loss: 3.7641\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.2056 - val_loss: 3.1353\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.2526 - val_loss: 2.1591\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2485 - val_loss: 3.0460\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2180 - val_loss: 3.5823\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2051 - val_loss: 3.9279\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2217 - val_loss: 4.5059\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.2139 - val_loss: 3.8815\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2052 - val_loss: 3.6037\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2088 - val_loss: 3.3936\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.2019 - val_loss: 3.9308\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.2030 - val_loss: 3.3242\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2024 - val_loss: 3.0293\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.2085 - val_loss: 3.1582\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2043 - val_loss: 3.2508\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.2061 - val_loss: 3.5906\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.2019 - val_loss: 3.8990\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.2025 - val_loss: 4.0458\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.2039 - val_loss: 3.5417\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1963 - val_loss: 2.6914\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.2141 - val_loss: 3.1510\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1975 - val_loss: 4.3436\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.2180 - val_loss: 4.0556\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.2080 - val_loss: 3.1528\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.2013 - val_loss: 2.9157\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 0.2071 - val_loss: 3.2360\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.1939 - val_loss: 4.2985\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.2223 - val_loss: 5.1564\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.2304 - val_loss: 4.2674\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.2071 - val_loss: 3.5810\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.1993 - val_loss: 3.8160\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.1990 - val_loss: 3.5912\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 914us/step - loss: 0.1973 - val_loss: 3.3703\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.1970 - val_loss: 3.9291\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2020 - val_loss: 3.8881\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 0.1978 - val_loss: 3.4917\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.2043 - val_loss: 3.0243\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.2004 - val_loss: 3.4720\n",
      "Epoch 1092/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 857us/step - loss: 0.1950 - val_loss: 3.7046\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.1962 - val_loss: 3.7302\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.1959 - val_loss: 3.8563\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1951 - val_loss: 3.3948\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.1946 - val_loss: 3.2711\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.1906 - val_loss: 4.1492\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.2154 - val_loss: 4.6501\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.2158 - val_loss: 3.6906\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1973 - val_loss: 3.4301\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1890 - val_loss: 4.0930\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.2170 - val_loss: 4.4920\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.2115 - val_loss: 3.1428\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.1964 - val_loss: 3.1320\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.1908 - val_loss: 4.2417\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2100 - val_loss: 4.3202\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.2051 - val_loss: 3.4786\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.1905 - val_loss: 3.3314\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.1957 - val_loss: 3.7626\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1911 - val_loss: 3.1974\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.1990 - val_loss: 2.6044\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1979 - val_loss: 3.0554\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1906 - val_loss: 3.5838\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.1900 - val_loss: 3.2620\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.1914 - val_loss: 3.0119\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.1995 - val_loss: 3.2250\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.1998 - val_loss: 4.5913\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.2097 - val_loss: 3.9788\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.1842 - val_loss: 2.9242\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.1944 - val_loss: 2.4806\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.1964 - val_loss: 3.5042\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.1988 - val_loss: 5.1694\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2335 - val_loss: 4.3748\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.1923 - val_loss: 3.1231\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.1836 - val_loss: 2.5121\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.1957 - val_loss: 3.0552\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.1894 - val_loss: 3.5083\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 969us/step - loss: 0.1901 - val_loss: 3.2317\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.1872 - val_loss: 3.4908\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.1911 - val_loss: 3.8918\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.1880 - val_loss: 3.3336\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.1821 - val_loss: 2.7376\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 770us/step - loss: 0.2020 - val_loss: 2.6747\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.1937 - val_loss: 2.9464\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.1982 - val_loss: 2.3170\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.2062 - val_loss: 3.1292\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.1830 - val_loss: 4.4763\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2237 - val_loss: 4.5977\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.2048 - val_loss: 3.2202\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.1810 - val_loss: 2.3014\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.2154 - val_loss: 1.7181\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.2246 - val_loss: 2.8903\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.1777 - val_loss: 4.6161\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.2175 - val_loss: 3.6748\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.1871 - val_loss: 3.2787\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1819 - val_loss: 3.0869\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.1797 - val_loss: 3.0951\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.1848 - val_loss: 3.2520\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.1794 - val_loss: 2.8810\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.1837 - val_loss: 2.5959\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.1883 - val_loss: 1.6816\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.2520 - val_loss: 2.2902\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.1716 - val_loss: 5.2677\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.2828 - val_loss: 4.3862\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.1950 - val_loss: 2.5988\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.1978 - val_loss: 2.7431\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.1817 - val_loss: 4.1939\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.2044 - val_loss: 4.1625\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.1968 - val_loss: 2.4901\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.1954 - val_loss: 2.4188\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1787 - val_loss: 3.7620\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.1829 - val_loss: 4.1476\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.2062 - val_loss: 3.9325\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.1862 - val_loss: 2.5622\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.1892 - val_loss: 2.3203\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.1981 - val_loss: 3.1929\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.1746 - val_loss: 3.3345\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1769 - val_loss: 2.6936\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1966 - val_loss: 1.5383\n",
      "Epoch 1170/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 855us/step - loss: 0.2395 - val_loss: 2.5504\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1720 - val_loss: 4.0234\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2053 - val_loss: 4.3478\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1992 - val_loss: 3.1520\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.1762 - val_loss: 2.5321\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.1788 - val_loss: 2.6417\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1750 - val_loss: 3.0466\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.1788 - val_loss: 3.7437\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.1829 - val_loss: 3.2797\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.1931 - val_loss: 2.4840\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.1792 - val_loss: 3.4265\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.1788 - val_loss: 3.2608\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.1748 - val_loss: 2.7721\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.1698 - val_loss: 2.5334\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.1777 - val_loss: 2.7420\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.1737 - val_loss: 3.8880\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.1887 - val_loss: 3.4158\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1689 - val_loss: 2.4437\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.1789 - val_loss: 2.0713\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 934us/step - loss: 0.1830 - val_loss: 2.5567\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.1692 - val_loss: 3.3732\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 924us/step - loss: 0.1717 - val_loss: 3.7874\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.1769 - val_loss: 2.4870\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.2047 - val_loss: 1.2577\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.2082 - val_loss: 3.6324\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2260 - val_loss: 5.3336\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2474 - val_loss: 3.2180\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1968 - val_loss: 1.4006\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.2345 - val_loss: 2.4467\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 0.1863 - val_loss: 4.4456\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.1775 - val_loss: 1.9580\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.2537 - val_loss: 0.9055\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.2396 - val_loss: 2.9959\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1897 - val_loss: 5.7207\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.3213 - val_loss: 3.6800\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 952us/step - loss: 0.1691 - val_loss: 1.3085\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.2171 - val_loss: 1.9086\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.1657 - val_loss: 3.1673\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.1798 - val_loss: 3.4016\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.1770 - val_loss: 2.8393\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.1623 - val_loss: 2.1170\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.1718 - val_loss: 2.2724\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.1751 - val_loss: 3.3972\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.1745 - val_loss: 2.5565\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.1687 - val_loss: 2.0152\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.1693 - val_loss: 2.4058\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1758 - val_loss: 3.4565\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.1751 - val_loss: 3.0890\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.1673 - val_loss: 3.0091\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1643 - val_loss: 2.7372\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1579 - val_loss: 2.2456\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1665 - val_loss: 2.1396\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.1622 - val_loss: 2.6765\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.1594 - val_loss: 3.1596\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1674 - val_loss: 2.9046\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.1643 - val_loss: 2.1974\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1637 - val_loss: 2.4786\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.1541 - val_loss: 3.0821\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1564 - val_loss: 2.3641\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1716 - val_loss: 2.1397\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.1484 - val_loss: 3.4161\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.1744 - val_loss: 4.0218\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.1870 - val_loss: 2.7022\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1551 - val_loss: 2.0153\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1777 - val_loss: 2.1402\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.1568 - val_loss: 2.9129\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1869 - val_loss: 3.7082\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1597 - val_loss: 2.0425\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.2342 - val_loss: 0.8319\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.2615 - val_loss: 2.3649\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.1633 - val_loss: 4.2277\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.2188 - val_loss: 3.6986\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1552 - val_loss: 2.0332\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.1705 - val_loss: 1.5523\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.1884 - val_loss: 2.6364\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1496 - val_loss: 3.2282\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.1595 - val_loss: 3.4947\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.1689 - val_loss: 2.9994\n",
      "Epoch 1248/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 821us/step - loss: 0.1532 - val_loss: 2.0621\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.2161 - val_loss: 1.4080\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.1647 - val_loss: 4.2411\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 929us/step - loss: 0.2251 - val_loss: 3.0635\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2161 - val_loss: 0.7992\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.2130 - val_loss: 3.0928\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.1866 - val_loss: 5.1794\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2621 - val_loss: 2.7072\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.1427 - val_loss: 1.4341\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.1895 - val_loss: 1.6032\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1754 - val_loss: 1.9723\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.1621 - val_loss: 1.9014\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1537 - val_loss: 2.5070\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.1495 - val_loss: 2.7069\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.1517 - val_loss: 2.1816\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1506 - val_loss: 2.2611\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.1483 - val_loss: 2.5314\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 0.1501 - val_loss: 2.4009\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.1489 - val_loss: 2.5659\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1536 - val_loss: 2.9761\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 960us/step - loss: 0.1541 - val_loss: 2.2109\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.1511 - val_loss: 1.8290\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.2009 - val_loss: 1.3547\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.1661 - val_loss: 3.0045\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 757us/step - loss: 0.1771 - val_loss: 3.5619\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.1576 - val_loss: 2.0514\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.1811 - val_loss: 1.6583\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 0.1701 - val_loss: 3.1522\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 777us/step - loss: 0.1619 - val_loss: 2.2070\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.2152 - val_loss: 0.5846\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.2811 - val_loss: 1.6595\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1352 - val_loss: 3.2353\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1687 - val_loss: 2.4916\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.1644 - val_loss: 0.9564\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.2168 - val_loss: 1.6193\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1485 - val_loss: 3.4775\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.1857 - val_loss: 2.8726\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 758us/step - loss: 0.1423 - val_loss: 1.5677\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.1532 - val_loss: 1.4159\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.1573 - val_loss: 2.0698\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1434 - val_loss: 2.9709\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1572 - val_loss: 2.3389\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1407 - val_loss: 1.5685\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.1495 - val_loss: 1.5915\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.1670 - val_loss: 1.5946\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.1514 - val_loss: 2.9322\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 771us/step - loss: 0.1706 - val_loss: 2.2402\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1439 - val_loss: 1.1854\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.1616 - val_loss: 1.6842\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.1389 - val_loss: 2.5127\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1495 - val_loss: 2.1013\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.1405 - val_loss: 2.0851\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.1401 - val_loss: 2.3364\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1444 - val_loss: 1.8767\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.1463 - val_loss: 1.5889\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1428 - val_loss: 2.0683\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1399 - val_loss: 2.1033\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.1427 - val_loss: 1.8205\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1327 - val_loss: 2.7371\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.1484 - val_loss: 2.5238\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1386 - val_loss: 2.3060\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1377 - val_loss: 2.2680\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.1349 - val_loss: 2.5080\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.1423 - val_loss: 2.0407\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.1341 - val_loss: 2.1238\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.1378 - val_loss: 2.5029\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.1397 - val_loss: 1.9903\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.1324 - val_loss: 1.4891\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.1483 - val_loss: 2.0245\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1528 - val_loss: 3.2118\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 930us/step - loss: 0.1578 - val_loss: 2.1016\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.1396 - val_loss: 1.1407\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 957us/step - loss: 0.1482 - val_loss: 2.8757\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.1821 - val_loss: 3.4844\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.1540 - val_loss: 1.9454\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.1376 - val_loss: 1.4186\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.1411 - val_loss: 2.3867\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1382 - val_loss: 3.1701\n",
      "Epoch 1326/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 804us/step - loss: 0.1543 - val_loss: 2.0070\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1332 - val_loss: 1.1202\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.1708 - val_loss: 1.6562\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1456 - val_loss: 2.5905\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.1257 - val_loss: 1.4689\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1449 - val_loss: 1.5074\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.1311 - val_loss: 2.4308\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.1409 - val_loss: 3.2429\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1629 - val_loss: 1.9789\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1298 - val_loss: 2.0238\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.1284 - val_loss: 2.4889\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.1339 - val_loss: 1.8673\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1329 - val_loss: 1.6281\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1328 - val_loss: 2.1271\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.1253 - val_loss: 1.7073\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1303 - val_loss: 1.8891\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.1282 - val_loss: 2.4185\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.1469 - val_loss: 2.4422\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 962us/step - loss: 0.1261 - val_loss: 1.7113\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1352 - val_loss: 1.3455\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1410 - val_loss: 1.5626\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.1295 - val_loss: 2.4216\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.1513 - val_loss: 2.1475\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.1199 - val_loss: 1.2319\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.1421 - val_loss: 1.6606\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.1351 - val_loss: 2.8228\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.1503 - val_loss: 1.7168\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 936us/step - loss: 0.1307 - val_loss: 0.9438\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1590 - val_loss: 1.5340\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1295 - val_loss: 2.4714\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.1424 - val_loss: 1.9029\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.1247 - val_loss: 1.1589\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1479 - val_loss: 1.9353\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 0.1334 - val_loss: 2.8925\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.1350 - val_loss: 1.8163\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.1274 - val_loss: 1.8926\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.1534 - val_loss: 3.0306\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.1366 - val_loss: 1.4969\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.1404 - val_loss: 1.4177\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.1190 - val_loss: 3.0127\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1745 - val_loss: 3.0136\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.1417 - val_loss: 1.4017\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1362 - val_loss: 1.6484\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.1393 - val_loss: 3.2046\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.1626 - val_loss: 1.8832\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1300 - val_loss: 0.6231\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.2020 - val_loss: 1.7930\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1244 - val_loss: 2.6554\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.1318 - val_loss: 1.7207\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.1300 - val_loss: 1.4549\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1227 - val_loss: 2.2234\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1208 - val_loss: 2.1558\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.1172 - val_loss: 1.7450\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1287 - val_loss: 1.3885\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.1348 - val_loss: 1.6618\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.1185 - val_loss: 2.7375\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.1406 - val_loss: 2.1795\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.1218 - val_loss: 1.4725\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1194 - val_loss: 2.5023\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.1326 - val_loss: 2.8440\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.1206 - val_loss: 1.5603\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1280 - val_loss: 1.4535\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 928us/step - loss: 0.1386 - val_loss: 1.7889\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1464 - val_loss: 1.2867\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.1096 - val_loss: 3.3566\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.2016 - val_loss: 2.7919\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.1529 - val_loss: 0.7817\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.1747 - val_loss: 1.7427\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.1299 - val_loss: 4.0288\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1943 - val_loss: 2.0538\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.1221 - val_loss: 1.3359\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.1277 - val_loss: 2.1052\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.1099 - val_loss: 1.2679\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 918us/step - loss: 0.1275 - val_loss: 1.4587\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.1162 - val_loss: 2.0221\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.1183 - val_loss: 1.9254\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1152 - val_loss: 1.6467\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1201 - val_loss: 1.6000\n",
      "Epoch 1404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 790us/step - loss: 0.1092 - val_loss: 2.2294\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.1196 - val_loss: 1.7941\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.1135 - val_loss: 1.6558\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.1101 - val_loss: 2.0268\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 0.1218 - val_loss: 2.1259\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.1163 - val_loss: 1.3275\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.1115 - val_loss: 2.0179\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1303 - val_loss: 2.3499\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.1176 - val_loss: 1.3726\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1178 - val_loss: 1.3001\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1105 - val_loss: 1.8310\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.1163 - val_loss: 1.6361\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.1077 - val_loss: 1.1230\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1202 - val_loss: 1.4440\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 0.1112 - val_loss: 1.6559\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 779us/step - loss: 0.1099 - val_loss: 2.4133\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.1350 - val_loss: 1.5711\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1080 - val_loss: 1.1558\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.1141 - val_loss: 1.7630\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.1211 - val_loss: 1.6869\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 944us/step - loss: 0.1155 - val_loss: 1.1263\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1116 - val_loss: 1.7984\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.1136 - val_loss: 1.7100\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1096 - val_loss: 1.5444\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.1071 - val_loss: 1.1879\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1125 - val_loss: 1.5106\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1049 - val_loss: 1.6927\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.1055 - val_loss: 1.5881\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1105 - val_loss: 1.5807\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1016 - val_loss: 2.2332\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1151 - val_loss: 1.8142\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.1053 - val_loss: 1.8090\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1037 - val_loss: 1.6826\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.1062 - val_loss: 1.6927\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.1065 - val_loss: 1.4337\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1078 - val_loss: 1.6433\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.1024 - val_loss: 2.0996\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.1220 - val_loss: 2.3678\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1123 - val_loss: 1.4024\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.1097 - val_loss: 1.3410\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1041 - val_loss: 1.9190\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1169 - val_loss: 1.1854\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.1564 - val_loss: 0.2958\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.1908 - val_loss: 1.9160\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.1556 - val_loss: 1.8863\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.1226 - val_loss: 0.2594\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.2069 - val_loss: 1.6490\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1242 - val_loss: 2.9006\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1450 - val_loss: 0.9901\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.1227 - val_loss: 0.6054\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.1154 - val_loss: 2.1584\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1349 - val_loss: 1.4847\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.1209 - val_loss: 1.0450\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.0959 - val_loss: 2.2083\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.1228 - val_loss: 1.3594\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1101 - val_loss: 0.9931\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1044 - val_loss: 1.5416\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1027 - val_loss: 1.7134\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.1053 - val_loss: 1.5348\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.1016 - val_loss: 1.0748\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.1464 - val_loss: 0.5870\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.1198 - val_loss: 1.7844\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1213 - val_loss: 1.1730\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.1628 - val_loss: 0.1970\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 962us/step - loss: 0.1755 - val_loss: 1.8163\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.1284 - val_loss: 2.1692\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.1155 - val_loss: 0.7054\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.1125 - val_loss: 0.9886\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.1026 - val_loss: 1.4661\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1004 - val_loss: 1.1997\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.0961 - val_loss: 1.4817\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.0995 - val_loss: 1.4903\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.1034 - val_loss: 1.2865\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.0999 - val_loss: 1.2276\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.0968 - val_loss: 1.8547\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.053 - 0s 873us/step - loss: 0.1062 - val_loss: 0.8391\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.1185 - val_loss: 0.1975\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1755 - val_loss: 1.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.1048 - val_loss: 2.1783\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.1286 - val_loss: 1.0084\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.0982 - val_loss: 1.0260\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.0961 - val_loss: 0.9145\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 0.0986 - val_loss: 0.7501\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.0926 - val_loss: 1.7290\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.1228 - val_loss: 1.1426\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.1142 - val_loss: 0.3924\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.1311 - val_loss: 1.0947\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0942 - val_loss: 0.9534\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 939us/step - loss: 0.0969 - val_loss: 1.2890\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.0931 - val_loss: 0.8991\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.0957 - val_loss: 0.8897\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.0936 - val_loss: 1.1475\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.0950 - val_loss: 1.2145\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.0902 - val_loss: 0.9386\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.0941 - val_loss: 0.9959\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.0923 - val_loss: 1.4610\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.1025 - val_loss: 1.4344\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.0943 - val_loss: 0.8425\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.1018 - val_loss: 1.3597\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.1134 - val_loss: 2.0258\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.1003 - val_loss: 0.6855\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.1279 - val_loss: 0.9516\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0896 - val_loss: 2.0252\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.1094 - val_loss: 1.4594\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.0948 - val_loss: 1.1236\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 0.0928 - val_loss: 1.4265\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.0893 - val_loss: 1.1086\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 0.0959 - val_loss: 1.1668\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 938us/step - loss: 0.0879 - val_loss: 1.5746\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.0986 - val_loss: 1.2635\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.0929 - val_loss: 1.1274\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.0856 - val_loss: 1.8644\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.1056 - val_loss: 0.7555\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.1721 - val_loss: 0.3766\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.1328 - val_loss: 3.4561\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.2206 - val_loss: 0.9152\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.0998 - val_loss: 0.4103\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.1158 - val_loss: 1.6786\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.1040 - val_loss: 1.3709\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 777us/step - loss: 0.0874 - val_loss: 0.6487\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.1028 - val_loss: 1.3256\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.1056 - val_loss: 1.9182\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.1019 - val_loss: 0.7900\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.0942 - val_loss: 0.9584\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.0886 - val_loss: 1.2147\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.0859 - val_loss: 0.9262\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.0881 - val_loss: 1.1221\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.0879 - val_loss: 1.4723\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.0941 - val_loss: 0.6436\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1439 - val_loss: 0.4361\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.0975 - val_loss: 2.9610\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.2044 - val_loss: 0.7196\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.1464 - val_loss: 0.2699\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.1109 - val_loss: 2.2022\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.1824 - val_loss: 1.5025\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.1200 - val_loss: 0.4448\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1139 - val_loss: 2.3077\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.1350 - val_loss: 0.7098\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.1908 - val_loss: 0.5312\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.1312 - val_loss: 2.6527\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.1278 - val_loss: 0.3909\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.1911 - val_loss: 0.1160\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 918us/step - loss: 0.1488 - val_loss: 3.0660\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.2144 - val_loss: 1.2916\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.0869 - val_loss: 0.6519\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 0.0963 - val_loss: 1.7396\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.1108 - val_loss: 0.8121\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.0840 - val_loss: 0.8485\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.0814 - val_loss: 1.0239\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.0821 - val_loss: 1.0549\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.0816 - val_loss: 1.0253\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.0818 - val_loss: 1.1609\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.0824 - val_loss: 1.0534\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 0.0815 - val_loss: 1.0451\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.0832 - val_loss: 0.7535\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1047 - val_loss: 0.6471\n",
      "Epoch 1560/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 823us/step - loss: 0.0798 - val_loss: 2.3752\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.1300 - val_loss: 0.7061\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.0947 - val_loss: 0.6474\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.0927 - val_loss: 0.8438\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.0965 - val_loss: 0.5859\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.0837 - val_loss: 1.6126\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.0967 - val_loss: 0.9271\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.0928 - val_loss: 0.6062\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.0876 - val_loss: 1.2286\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.0813 - val_loss: 0.8721\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.0808 - val_loss: 0.8626\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.0881 - val_loss: 1.3403\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.0870 - val_loss: 0.8505\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.0824 - val_loss: 1.4343\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.0905 - val_loss: 0.7089\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.0856 - val_loss: 1.1014\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.0792 - val_loss: 1.4906\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.0887 - val_loss: 0.5996\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 0.1000 - val_loss: 0.6043\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.0771 - val_loss: 1.4154\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.1088 - val_loss: 0.7858\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.1022 - val_loss: 0.5070\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.1119 - val_loss: 1.6478\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1006 - val_loss: 0.6763\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 769us/step - loss: 0.0781 - val_loss: 1.0366\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.0796 - val_loss: 0.7487\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.0773 - val_loss: 0.6293\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.0772 - val_loss: 0.9384\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.0809 - val_loss: 0.9999\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.0772 - val_loss: 0.8696\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.0792 - val_loss: 0.8580\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.0759 - val_loss: 0.7430\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.0764 - val_loss: 0.9505\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.0735 - val_loss: 0.6422\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.0761 - val_loss: 1.2331\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.0870 - val_loss: 0.9298\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.0779 - val_loss: 0.8599\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 0.0827 - val_loss: 0.5648\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.1146 - val_loss: 0.2431\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.0996 - val_loss: 1.4772\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 752us/step - loss: 0.1097 - val_loss: 0.7413\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.0924 - val_loss: 0.4842\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.0773 - val_loss: 1.2248\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.0882 - val_loss: 0.8727\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.0714 - val_loss: 0.5157\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.0799 - val_loss: 0.5746\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.0807 - val_loss: 0.6918\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.0705 - val_loss: 1.5191\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.0956 - val_loss: 0.4980\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.0876 - val_loss: 0.5004\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.0744 - val_loss: 1.2417\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.0890 - val_loss: 0.8302\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0713 - val_loss: 0.6752\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 767us/step - loss: 0.0761 - val_loss: 0.5230\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1058 - val_loss: 0.6829\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.0869 - val_loss: 2.3198\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 0.1397 - val_loss: 0.1344\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.1703 - val_loss: 0.9014\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.1318 - val_loss: 1.3034\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.0951 - val_loss: 0.2186\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.1058 - val_loss: 1.1717\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.0793 - val_loss: 0.6969\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.0795 - val_loss: 0.7801\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.0723 - val_loss: 1.6136\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.1047 - val_loss: 0.5723\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.0911 - val_loss: 0.4521\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 961us/step - loss: 0.0677 - val_loss: 1.1880\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.0816 - val_loss: 0.7019\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.0699 - val_loss: 0.5623\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.0685 - val_loss: 0.8517\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.0699 - val_loss: 0.7517\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.0673 - val_loss: 0.5891\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0721 - val_loss: 0.7351\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.0767 - val_loss: 0.4896\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.1263 - val_loss: 0.3621\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 0.0913 - val_loss: 2.2879\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.1526 - val_loss: 0.3251\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.0801 - val_loss: 0.8697\n",
      "Epoch 1638/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 839us/step - loss: 0.0810 - val_loss: 0.6921\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.0805 - val_loss: 0.6204\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.0726 - val_loss: 1.3745\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.0779 - val_loss: 0.2747\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.1036 - val_loss: 0.6635\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.0822 - val_loss: 2.1616\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.1294 - val_loss: 0.1036\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1606 - val_loss: 0.8573\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1268 - val_loss: 1.5670\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.0930 - val_loss: 0.2101\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.0796 - val_loss: 1.2645\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.1106 - val_loss: 0.8059\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.0640 - val_loss: 0.2773\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.0782 - val_loss: 0.8577\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.0969 - val_loss: 0.7655\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.0768 - val_loss: 0.2685\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.0687 - val_loss: 1.0010\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.0928 - val_loss: 0.3070\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.1420 - val_loss: 0.2405\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.1123 - val_loss: 2.8647\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.2085 - val_loss: 0.0707\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.2436 - val_loss: 0.6847\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1130 - val_loss: 2.6735\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.1439 - val_loss: 0.1170\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.1600 - val_loss: 0.8279\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.0813 - val_loss: 1.3960\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.0732 - val_loss: 0.4333\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0828 - val_loss: 0.8802\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0782 - val_loss: 0.7731\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.0779 - val_loss: 0.3896\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.0755 - val_loss: 1.5262\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.0915 - val_loss: 0.3509\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.0896 - val_loss: 0.6228\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.0596 - val_loss: 1.2342\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.4261\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.6634\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.0629 - val_loss: 0.5942\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 919us/step - loss: 0.0623 - val_loss: 0.6452\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.0669 - val_loss: 0.7188\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.0613 - val_loss: 0.4075\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 956us/step - loss: 0.0639 - val_loss: 0.5341\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 988us/step - loss: 0.0609 - val_loss: 0.5938\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 937us/step - loss: 0.0602 - val_loss: 0.5522\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.5904\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 0.0611 - val_loss: 0.7765\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.6452\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 905us/step - loss: 0.0617 - val_loss: 0.6542\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 928us/step - loss: 0.0596 - val_loss: 0.5979\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.0600 - val_loss: 0.4938\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.0601 - val_loss: 0.5054\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.0593 - val_loss: 0.6919\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.0614 - val_loss: 0.8494\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.0651 - val_loss: 0.3847\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 0.0642 - val_loss: 0.7639\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.0683 - val_loss: 0.7245\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.0597 - val_loss: 0.4346\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.0580 - val_loss: 0.8492\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.0744 - val_loss: 0.6351\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.0567 - val_loss: 0.3481\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.0622 - val_loss: 0.5584\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.0593 - val_loss: 0.5132\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.0579 - val_loss: 0.5916\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.0681 - val_loss: 0.5136\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.0644 - val_loss: 0.4861\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.0585 - val_loss: 0.8939\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.0657 - val_loss: 0.3061\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.0637 - val_loss: 0.6611\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 953us/step - loss: 0.0657 - val_loss: 0.8320\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 946us/step - loss: 0.0578 - val_loss: 0.2338\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.0745 - val_loss: 0.7002\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 994us/step - loss: 0.0608 - val_loss: 0.7545\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.3776\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.6782\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 941us/step - loss: 0.0623 - val_loss: 0.6080\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 905us/step - loss: 0.0579 - val_loss: 0.4520\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.0597 - val_loss: 0.5289\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.0550 - val_loss: 0.3879\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 958us/step - loss: 0.0581 - val_loss: 0.6525\n",
      "Epoch 1716/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 907us/step - loss: 0.0650 - val_loss: 0.3925\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.0586 - val_loss: 0.4079\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 962us/step - loss: 0.0577 - val_loss: 0.3909\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.0577 - val_loss: 0.3321\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 962us/step - loss: 0.0554 - val_loss: 0.5837\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.0572 - val_loss: 0.3431\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.0578 - val_loss: 0.4780\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.0549 - val_loss: 0.4667\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 937us/step - loss: 0.0586 - val_loss: 0.5486\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.0591 - val_loss: 0.6005\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.0562 - val_loss: 0.3923\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.0544 - val_loss: 0.5839\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.0590 - val_loss: 0.3639\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0603 - val_loss: 0.3841\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.0571 - val_loss: 0.7186\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.0592 - val_loss: 0.3475\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.0603 - val_loss: 0.6298\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0697 - val_loss: 0.5883\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.0545 - val_loss: 0.3000\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.0568 - val_loss: 0.4210\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.0542 - val_loss: 0.3576\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.0535 - val_loss: 0.3810\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.0539 - val_loss: 0.4922\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0572 - val_loss: 0.4846\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.0522 - val_loss: 0.3115\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.0566 - val_loss: 0.2863\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.0704 - val_loss: 0.5087\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.0582 - val_loss: 0.5720\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 0.0520 - val_loss: 0.1335\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.0632 - val_loss: 0.6239\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.0743 - val_loss: 0.1378\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.1637 - val_loss: 0.0784\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.1148 - val_loss: 1.5038\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.1289 - val_loss: 0.8642\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.3626 - val_loss: 1.8298\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.1828 - val_loss: 0.1966\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.0961 - val_loss: 0.4049\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.1213 - val_loss: 1.3737\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.0840 - val_loss: 0.1029\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.0642 - val_loss: 0.7426\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.0738 - val_loss: 0.4078\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0584 - val_loss: 0.3046\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.0511 - val_loss: 0.6626\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.0537 - val_loss: 0.1970\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.0596 - val_loss: 0.6221\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.0656 - val_loss: 0.3746\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.0615 - val_loss: 0.2867\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.0557 - val_loss: 0.6327\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.0548 - val_loss: 0.3033\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0534 - val_loss: 0.4976\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.0530 - val_loss: 0.4057\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.0523 - val_loss: 0.2543\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.0505 - val_loss: 0.5270\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.0543 - val_loss: 0.3113\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.0514 - val_loss: 0.3150\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.0499 - val_loss: 0.5372\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.0554 - val_loss: 0.4306\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.0516 - val_loss: 0.4499\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.0577 - val_loss: 0.4735\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 973us/step - loss: 0.0495 - val_loss: 0.2407\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 977us/step - loss: 0.0540 - val_loss: 0.6199\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.0573 - val_loss: 0.3675\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.0524 - val_loss: 0.4054\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 942us/step - loss: 0.0521 - val_loss: 0.5891\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0514 - val_loss: 0.3560\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.0498 - val_loss: 0.3576\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.0507 - val_loss: 0.4458\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.2777\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.0583 - val_loss: 0.3059\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.0520 - val_loss: 0.4859\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 976us/step - loss: 0.0489 - val_loss: 0.2026\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 947us/step - loss: 0.0591 - val_loss: 0.4694\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.0525 - val_loss: 0.4234\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.0484 - val_loss: 0.2175\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.0507 - val_loss: 0.5303\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.0503 - val_loss: 0.2864\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 0.0541 - val_loss: 0.5190\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0646 - val_loss: 0.4070\n",
      "Epoch 1794/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 940us/step - loss: 0.0543 - val_loss: 0.2664\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.0543 - val_loss: 0.6075\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.0519 - val_loss: 0.2263\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.0527 - val_loss: 0.3102\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 894us/step - loss: 0.0506 - val_loss: 0.3388\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 984us/step - loss: 0.0472 - val_loss: 0.5221\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 0.0495 - val_loss: 0.1388\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.0783 - val_loss: 0.3312\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.0579 - val_loss: 0.5179\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.0511 - val_loss: 0.1748\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 762us/step - loss: 0.0502 - val_loss: 0.5280\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.0523 - val_loss: 0.3678\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.0483 - val_loss: 0.2827\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.0474 - val_loss: 0.4045\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.0502 - val_loss: 0.2524\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0549 - val_loss: 0.4072\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.0645 - val_loss: 0.4192\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.0533 - val_loss: 0.3241\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.0579 - val_loss: 0.4690\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.0478 - val_loss: 0.2680\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.0444 - val_loss: 0.5073\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.0490 - val_loss: 0.1718\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.0572 - val_loss: 0.4220\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.0467 - val_loss: 0.3132\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.0450 - val_loss: 0.2549\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.0462 - val_loss: 0.4544\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.0499 - val_loss: 0.3021\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.0491 - val_loss: 0.2494\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.0499 - val_loss: 0.1571\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.0707 - val_loss: 0.2243\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.0598 - val_loss: 0.6397\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.0633 - val_loss: 0.0265\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.0767 - val_loss: 0.2717\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.0491 - val_loss: 0.2222\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 758us/step - loss: 0.0524 - val_loss: 0.3105\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0533 - val_loss: 0.1888\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.0609 - val_loss: 0.4449\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.0622 - val_loss: 0.1517\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.0495 - val_loss: 0.3813\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 0.0461 - val_loss: 0.0908\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.0529 - val_loss: 0.5275\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.0499 - val_loss: 0.0836\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.0563 - val_loss: 0.4048\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0511 - val_loss: 0.0810\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.0932 - val_loss: 0.1102\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.0572 - val_loss: 0.9764\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.0750 - val_loss: 0.0585\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 777us/step - loss: 0.0580 - val_loss: 0.4051\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.0535 - val_loss: 0.0552\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 965us/step - loss: 0.0779 - val_loss: 0.1661\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.3292\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0466 - val_loss: 0.1741\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.0500 - val_loss: 0.3214\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 949us/step - loss: 0.0444 - val_loss: 0.1241\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.0474 - val_loss: 0.1128\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 956us/step - loss: 0.0787 - val_loss: 0.3075\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 926us/step - loss: 0.0958 - val_loss: 0.6240\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.0493 - val_loss: 0.0667\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.0497 - val_loss: 0.3426\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.0431 - val_loss: 0.0682\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.0536 - val_loss: 0.4760\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.0513 - val_loss: 0.2342\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.0454 - val_loss: 0.3236\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.0497 - val_loss: 0.1944\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.0482 - val_loss: 0.2196\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 763us/step - loss: 0.0426 - val_loss: 0.2890\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.0425 - val_loss: 0.1508\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 740us/step - loss: 0.0451 - val_loss: 0.2988\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.0433 - val_loss: 0.1771\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.0433 - val_loss: 0.2516\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 761us/step - loss: 0.0431 - val_loss: 0.2523\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 768us/step - loss: 0.0420 - val_loss: 0.1341\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.0448 - val_loss: 0.3543\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.0524 - val_loss: 0.1265\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.0551 - val_loss: 0.1246\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.0524 - val_loss: 0.0796\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0989 - val_loss: 0.2452\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.0968 - val_loss: 0.0194\n",
      "Epoch 1872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 816us/step - loss: 0.2196 - val_loss: 0.0182\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.0672 - val_loss: 0.9258\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 778us/step - loss: 0.0880 - val_loss: 0.1571\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1317 - val_loss: 0.6707\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.1393 - val_loss: 0.1141\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0639 - val_loss: 0.1977\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.0791 - val_loss: 0.1474\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.0446 - val_loss: 0.0193\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.0579 - val_loss: 0.3653\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 762us/step - loss: 0.0513 - val_loss: 0.0891\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.0412 - val_loss: 0.3196\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.0461 - val_loss: 0.0554\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.0542 - val_loss: 0.4199\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0463 - val_loss: 0.1948\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.0407 - val_loss: 0.2543\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.0419 - val_loss: 0.2474\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.0403 - val_loss: 0.1836\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0425 - val_loss: 0.2678\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.0420 - val_loss: 0.2202\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.0424 - val_loss: 0.3044\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.0415 - val_loss: 0.2761\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.0425 - val_loss: 0.2887\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.0441 - val_loss: 0.0592\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.0714 - val_loss: 0.2502\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.0509 - val_loss: 0.1524\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.0433 - val_loss: 0.0517\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.0439 - val_loss: 0.2159\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.0399 - val_loss: 0.0812\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.0437 - val_loss: 0.3076\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.0431 - val_loss: 0.1581\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.0431 - val_loss: 0.3507\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.0473 - val_loss: 0.0377\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.0951 - val_loss: 0.5153\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.1176 - val_loss: 0.0283\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.0983 - val_loss: 0.3697\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.0737 - val_loss: 0.1735\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.0528 - val_loss: 0.2012\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.0485 - val_loss: 0.4684\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.0456 - val_loss: 0.0217\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.0701 - val_loss: 0.9641\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.0828 - val_loss: 0.0460\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 0.0622 - val_loss: 0.6481\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.0780 - val_loss: 0.0228\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 956us/step - loss: 0.0770 - val_loss: 0.4448\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.0600 - val_loss: 0.0960\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.0424 - val_loss: 0.1970\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.0413 - val_loss: 0.1614\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.0403 - val_loss: 0.1901\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.0384 - val_loss: 0.2329\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 937us/step - loss: 0.0396 - val_loss: 0.2028\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.0385 - val_loss: 0.2598\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 963us/step - loss: 0.0391 - val_loss: 0.1473\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 948us/step - loss: 0.0411 - val_loss: 0.1363\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 955us/step - loss: 0.0398 - val_loss: 0.2618\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 949us/step - loss: 0.0385 - val_loss: 0.1518\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 976us/step - loss: 0.0390 - val_loss: 0.1733\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 975us/step - loss: 0.0368 - val_loss: 0.2104\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 0.0364 - val_loss: 0.0779\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 940us/step - loss: 0.0446 - val_loss: 0.3079\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 938us/step - loss: 0.0409 - val_loss: 0.1283\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.0380 - val_loss: 0.2111\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 932us/step - loss: 0.0402 - val_loss: 0.1511\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.0370 - val_loss: 0.1983\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.0370 - val_loss: 0.1356\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.0419 - val_loss: 0.1855\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.0376 - val_loss: 0.2108\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.0358 - val_loss: 0.1017\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.0368 - val_loss: 0.1698\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.0391 - val_loss: 0.0539\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.0429 - val_loss: 0.2541\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.1243\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.0388 - val_loss: 0.2390\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.0379 - val_loss: 0.0466\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.0650 - val_loss: 0.3343\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.0588 - val_loss: 0.0311\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.0588 - val_loss: 0.3513\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.0443 - val_loss: 0.1605\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.0352 - val_loss: 0.0734\n",
      "Epoch 1950/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 826us/step - loss: 0.0372 - val_loss: 0.2944\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 743us/step - loss: 0.0379 - val_loss: 0.1066\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.0363 - val_loss: 0.2765\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.0393 - val_loss: 0.0279\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.0524 - val_loss: 0.1958\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.0356 - val_loss: 0.1330\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.0354 - val_loss: 0.1862\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 756us/step - loss: 0.0351 - val_loss: 0.1133\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.0351 - val_loss: 0.1947\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.0358 - val_loss: 0.1570\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.0343 - val_loss: 0.1082\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.0362 - val_loss: 0.0719\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.0404 - val_loss: 0.1734\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.0367 - val_loss: 0.0825\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 774us/step - loss: 0.0407 - val_loss: 0.1564\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.0391 - val_loss: 0.0674\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.0483 - val_loss: 0.2586\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 746us/step - loss: 0.0498 - val_loss: 0.0337\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.0409 - val_loss: 0.2365\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.0476 - val_loss: 0.0699\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.0386 - val_loss: 0.0473\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.0373 - val_loss: 0.2007\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.0373 - val_loss: 0.0681\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 769us/step - loss: 0.0367 - val_loss: 0.0800\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.0371 - val_loss: 0.0688\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.0394 - val_loss: 0.2441\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.0370 - val_loss: 0.0713\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.0345 - val_loss: 0.2471\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 771us/step - loss: 0.0382 - val_loss: 0.0620\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.0438 - val_loss: 0.3710\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.0530 - val_loss: 0.0758\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.0358 - val_loss: 0.2387\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.0361 - val_loss: 0.1136\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.0338 - val_loss: 0.2679\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.0353 - val_loss: 0.0958\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.0351 - val_loss: 0.1804\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.0340 - val_loss: 0.0705\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.0401 - val_loss: 0.0708\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.0452 - val_loss: 0.3044\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.0419 - val_loss: 0.0505\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.0395 - val_loss: 0.2871\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 894us/step - loss: 0.0430 - val_loss: 0.0727\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.0392 - val_loss: 0.2670\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.0389 - val_loss: 0.0729\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.0355 - val_loss: 0.1775\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.0363 - val_loss: 0.0946\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.0333 - val_loss: 0.1022\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.0339 - val_loss: 0.0506\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.0350 - val_loss: 0.1696\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.0380 - val_loss: 0.0276\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.0389 - val_loss: 0.1786\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X, Y, epochs=2000, validation_split=0.2, verbose=1, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 446.62033]\n",
      " [ 878.9653 ]\n",
      " [1305.45   ]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([30,60,90])\n",
    "test_input = test_input.reshape((3, 1, 1))\n",
    "test_output = model1.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 50)             10400     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 33,201\n",
      "Trainable params: 33,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Let's see how it behaves after adding one more dense layer\n",
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.LSTM(50,activation='relu',return_sequences=True,input_shape=(1,1))) # inputshape 1X1 because we have 1 timestamp and 1 feature\n",
    "model2.add(keras.layers.LSTM(50,activation='relu')) \n",
    "model2.add(keras.layers.Dense(50)) \n",
    "model2.add(keras.layers.Dense(1))\n",
    "model2.compile(optimizer='adam',loss='mse')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 21026.6633 - val_loss: 77227.8125\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 933us/step - loss: 21001.2650 - val_loss: 77157.7812\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 997us/step - loss: 20976.2461 - val_loss: 77076.9922\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 949us/step - loss: 20943.4160 - val_loss: 76975.0078\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 20905.4329 - val_loss: 76838.4062\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 20855.5229 - val_loss: 76655.0625\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 20792.9836 - val_loss: 76391.7734\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 943us/step - loss: 20714.5634 - val_loss: 76024.2109\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 20598.5615 - val_loss: 75487.1094\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 964us/step - loss: 20416.2815 - val_loss: 74691.7188\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 991us/step - loss: 20180.9067 - val_loss: 73467.8594\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 19839.3340 - val_loss: 71602.5000\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 19383.2548 - val_loss: 68730.5625\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 18642.1379 - val_loss: 64590.9688\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 17623.7881 - val_loss: 59164.5000\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 16519.0987 - val_loss: 51725.1523\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 14672.7038 - val_loss: 42648.3008\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 12448.4250 - val_loss: 32302.1602\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 751us/step - loss: 9994.9217 - val_loss: 21566.5195\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 937us/step - loss: 7419.2404 - val_loss: 11957.8008\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 4727.3904 - val_loss: 4565.9956\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 975us/step - loss: 2341.6132 - val_loss: 431.7919\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 915.9455 - val_loss: 783.5469\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 434.6034 - val_loss: 4264.7261\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 972us/step - loss: 653.4492 - val_loss: 6647.0293\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 888.9412 - val_loss: 6231.3198\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 988us/step - loss: 718.5650 - val_loss: 3536.5134\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 944us/step - loss: 456.8846 - val_loss: 1731.1864\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 983us/step - loss: 343.4859 - val_loss: 712.3075\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 374.3479 - val_loss: 243.4302\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 419.7300 - val_loss: 151.9134\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 932us/step - loss: 417.2907 - val_loss: 242.3147\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 368.3901 - val_loss: 430.6617\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 929us/step - loss: 328.6229 - val_loss: 724.7133\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 919us/step - loss: 309.8547 - val_loss: 1031.8052\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 935us/step - loss: 307.9340 - val_loss: 1299.5616\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 961us/step - loss: 306.2856 - val_loss: 1335.3533\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 285.3256 - val_loss: 934.5096\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 279.5876 - val_loss: 565.5268\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 941us/step - loss: 268.1158 - val_loss: 481.1534\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 940us/step - loss: 262.1615 - val_loss: 514.9494\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 924us/step - loss: 252.6776 - val_loss: 544.1273\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 244.1037 - val_loss: 513.4919\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 967us/step - loss: 236.6184 - val_loss: 545.1927\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 236.2568 - val_loss: 600.4189\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 222.0291 - val_loss: 470.4275\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 216.4689 - val_loss: 420.9733\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 210.2270 - val_loss: 389.8854\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 205.0575 - val_loss: 343.2988\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 198.4487 - val_loss: 363.7713\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 961us/step - loss: 192.0186 - val_loss: 411.1073\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 186.3726 - val_loss: 432.9088\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 181.0323 - val_loss: 390.9125\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 175.4778 - val_loss: 373.5523\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 167.2555 - val_loss: 253.1969\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 946us/step - loss: 166.7372 - val_loss: 135.0743\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 946us/step - loss: 169.0234 - val_loss: 103.3252\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 164.9966 - val_loss: 130.9611\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 150.6949 - val_loss: 223.9367\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 147.9834 - val_loss: 355.9102\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 140.4956 - val_loss: 337.7557\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 136.1262 - val_loss: 222.3657\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 128.3344 - val_loss: 145.8531\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 127.5691 - val_loss: 115.7309\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 122.1248 - val_loss: 146.7870\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 115.6266 - val_loss: 173.1898\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 110.8613 - val_loss: 193.6380\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 108.4644 - val_loss: 220.3237\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 104.7979 - val_loss: 226.6870\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 101.4963 - val_loss: 213.6199\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 779us/step - loss: 97.5942 - val_loss: 201.2892\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 93.2428 - val_loss: 162.1123\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 87.2105 - val_loss: 116.3606\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 82.0142 - val_loss: 58.0150\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 79.0857 - val_loss: 24.7565\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 79.2899 - val_loss: 11.9646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 77.2872 - val_loss: 20.0726\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 962us/step - loss: 70.4777 - val_loss: 30.7776\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 65.8706 - val_loss: 33.6008\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 63.3414 - val_loss: 44.3427\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 61.0228 - val_loss: 53.9960\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 58.5397 - val_loss: 44.8191\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 55.1527 - val_loss: 34.1584\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 52.1713 - val_loss: 25.3339\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 49.5705 - val_loss: 19.2511\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 47.0385 - val_loss: 4.7251\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 44.5493 - val_loss: 2.3311\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 41.7999 - val_loss: 4.0011\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 39.4363 - val_loss: 4.7445\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 37.1966 - val_loss: 2.7273\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 35.2586 - val_loss: 1.7333\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 33.4816 - val_loss: 1.5013\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 31.7761 - val_loss: 2.1957\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 31.2384 - val_loss: 6.3927\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 29.4646 - val_loss: 4.3268\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 26.9104 - val_loss: 4.3096\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 25.5913 - val_loss: 5.0752\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 24.1239 - val_loss: 4.5990\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 23.0475 - val_loss: 4.9305\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 22.0984 - val_loss: 6.3013\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 20.8670 - val_loss: 9.8610\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 19.8327 - val_loss: 16.2732\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 18.9705 - val_loss: 20.1197\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 18.3256 - val_loss: 19.9506\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 17.3901 - val_loss: 24.1685\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 16.7394 - val_loss: 26.8461\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 16.1249 - val_loss: 29.5966\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 15.4537 - val_loss: 29.3468\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 14.6017 - val_loss: 23.8451\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 14.4279 - val_loss: 21.2552\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 917us/step - loss: 13.8663 - val_loss: 24.9343\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 12.9768 - val_loss: 33.8689\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 12.3360 - val_loss: 39.0312\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 11.8557 - val_loss: 48.9744\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 11.5251 - val_loss: 53.0582\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 11.1825 - val_loss: 51.3908\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 10.6765 - val_loss: 42.0279\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 10.2041 - val_loss: 34.9765\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 10.5873 - val_loss: 34.5410\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 9.9963 - val_loss: 52.0084\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 9.2253 - val_loss: 65.0943\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 9.2418 - val_loss: 64.3774\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 8.6332 - val_loss: 54.2609\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 8.2201 - val_loss: 44.6563\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 8.9484 - val_loss: 41.6812\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 8.5028 - val_loss: 60.3681\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 7.7116 - val_loss: 68.8858\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 7.7428 - val_loss: 60.7203\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 7.2991 - val_loss: 62.6096\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 7.1935 - val_loss: 60.5900\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 7.1208 - val_loss: 58.5092\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 768us/step - loss: 6.8192 - val_loss: 50.9364\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 6.9179 - val_loss: 45.7147\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 771us/step - loss: 6.8758 - val_loss: 51.7174\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 6.5058 - val_loss: 46.9659\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 6.4531 - val_loss: 49.6416\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 6.3029 - val_loss: 41.5210\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 772us/step - loss: 6.0959 - val_loss: 44.1552\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 5.9993 - val_loss: 46.2538\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 754us/step - loss: 5.9552 - val_loss: 46.1993\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 5.8295 - val_loss: 48.2695\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 5.8358 - val_loss: 48.2059\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 5.8267 - val_loss: 34.3800\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 5.7029 - val_loss: 31.3680\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 5.6696 - val_loss: 34.0830\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 5.5502 - val_loss: 38.8387\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 778us/step - loss: 5.5021 - val_loss: 34.5813\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 774us/step - loss: 5.2548 - val_loss: 40.3908\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 5.2232 - val_loss: 44.6332\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 743us/step - loss: 5.2524 - val_loss: 45.7118\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 740us/step - loss: 5.2584 - val_loss: 42.2245\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 5.0491 - val_loss: 42.0879\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 774us/step - loss: 5.0779 - val_loss: 38.7994\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 777us/step - loss: 4.8996 - val_loss: 40.6204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 4.8543 - val_loss: 45.9453\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 4.8378 - val_loss: 45.4627\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 4.7948 - val_loss: 41.1947\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 4.6575 - val_loss: 41.0802\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 4.7085 - val_loss: 38.9553\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 4.5639 - val_loss: 43.8842\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 4.4748 - val_loss: 45.2342\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 929us/step - loss: 4.4608 - val_loss: 40.1569\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 765us/step - loss: 4.3708 - val_loss: 41.7730\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 4.3284 - val_loss: 44.5948\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 4.2970 - val_loss: 46.9710\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 4.2584 - val_loss: 41.5152\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 4.1790 - val_loss: 42.0658\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 4.1569 - val_loss: 42.0852\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 4.0907 - val_loss: 41.4656\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 4.0355 - val_loss: 40.6993\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 932us/step - loss: 4.0505 - val_loss: 43.1917\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 3.9651 - val_loss: 41.8457\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 3.9128 - val_loss: 42.3267\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 3.8663 - val_loss: 41.3154\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 3.8221 - val_loss: 44.8111\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 3.7882 - val_loss: 48.8702\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 3.8830 - val_loss: 50.8043\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 3.8377 - val_loss: 47.8927\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 3.7480 - val_loss: 43.2341\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 3.6886 - val_loss: 39.4032\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 3.6380 - val_loss: 38.7161\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 3.5914 - val_loss: 42.1889\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 3.6578 - val_loss: 47.9175\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 3.7211 - val_loss: 47.8747\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 3.7521 - val_loss: 45.1103\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 3.5807 - val_loss: 37.2099\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 3.5728 - val_loss: 34.4753\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 3.4266 - val_loss: 39.0153\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 3.4029 - val_loss: 40.3844\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 3.4858 - val_loss: 37.0227\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 3.4012 - val_loss: 38.2684\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 3.3459 - val_loss: 37.2852\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 3.3533 - val_loss: 34.8352\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 3.4172 - val_loss: 33.5552\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 3.3294 - val_loss: 39.5513\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 3.2653 - val_loss: 37.4347\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 3.2502 - val_loss: 37.1833\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 3.2253 - val_loss: 35.7731\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 3.2318 - val_loss: 31.6679\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 3.2113 - val_loss: 32.8727\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 3.2109 - val_loss: 33.0298\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 3.0768 - val_loss: 40.2136\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 3.1088 - val_loss: 47.2526\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 3.4204 - val_loss: 48.5052\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 3.2608 - val_loss: 37.8757\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 3.0322 - val_loss: 32.2689\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 3.0085 - val_loss: 32.3254\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 2.9814 - val_loss: 28.7752\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 3.0264 - val_loss: 23.6411\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 3.1508 - val_loss: 26.4141\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 2.9489 - val_loss: 31.7459\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 3.1419 - val_loss: 41.8718\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 3.0937 - val_loss: 41.0544\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 2.9924 - val_loss: 36.7327\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 2.9450 - val_loss: 28.4828\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 2.8587 - val_loss: 28.3531\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 2.8411 - val_loss: 31.5619\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 2.8472 - val_loss: 38.3019\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 2.9475 - val_loss: 40.2424\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 2.9556 - val_loss: 34.9592\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 2.7769 - val_loss: 33.1296\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 2.7241 - val_loss: 29.1487\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 2.7134 - val_loss: 25.8545\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 924us/step - loss: 2.7518 - val_loss: 22.8091\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 2.8130 - val_loss: 20.4616\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 916us/step - loss: 2.8858 - val_loss: 23.1236\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 934us/step - loss: 2.7479 - val_loss: 27.0561\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 918us/step - loss: 2.6554 - val_loss: 23.7331\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 2.6890 - val_loss: 24.1601\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 2.6413 - val_loss: 27.2050\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 2.6762 - val_loss: 29.2570\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 2.6544 - val_loss: 28.7904\n",
      "Epoch 233/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 923us/step - loss: 2.6439 - val_loss: 27.1983\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 921us/step - loss: 2.5743 - val_loss: 23.2981\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 2.7051 - val_loss: 20.8545\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 2.6109 - val_loss: 25.6942\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 2.5397 - val_loss: 33.7288\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 916us/step - loss: 2.7201 - val_loss: 35.7048\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 2.7501 - val_loss: 29.1030\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 2.5359 - val_loss: 27.5845\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 2.5245 - val_loss: 28.5765\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 2.4817 - val_loss: 26.0409\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 2.5416 - val_loss: 23.9145\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 2.4703 - val_loss: 28.5808\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 2.4206 - val_loss: 36.1505\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 2.7852 - val_loss: 40.0890\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 2.7394 - val_loss: 34.2599\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 2.5358 - val_loss: 26.8924\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 2.4315 - val_loss: 23.7458\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 2.3976 - val_loss: 26.3904\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 2.4751 - val_loss: 31.3335\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 2.5067 - val_loss: 32.1058\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 2.5417 - val_loss: 30.3046\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 2.4350 - val_loss: 25.2371\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 2.4671 - val_loss: 21.0813\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 2.3909 - val_loss: 21.9460\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 2.3718 - val_loss: 21.7545\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 2.3077 - val_loss: 25.6425\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 2.3411 - val_loss: 28.3510\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 2.4093 - val_loss: 26.5269\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 2.3090 - val_loss: 20.8798\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 2.3646 - val_loss: 18.2081\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 2.3723 - val_loss: 18.5002\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 2.3652 - val_loss: 19.8351\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 2.3090 - val_loss: 26.0617\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 2.3225 - val_loss: 27.5577\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 2.4322 - val_loss: 28.3164\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 2.3889 - val_loss: 24.6756\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 2.2759 - val_loss: 21.5996\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 2.2743 - val_loss: 18.7053\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 2.3299 - val_loss: 12.9859\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 2.4595 - val_loss: 13.8051\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 2.3709 - val_loss: 17.4877\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 2.2251 - val_loss: 21.3746\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 2.2036 - val_loss: 22.7898\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 2.2248 - val_loss: 23.0437\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 2.2118 - val_loss: 20.1586\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 2.2954 - val_loss: 13.4295\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 2.3281 - val_loss: 18.1158\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 2.2159 - val_loss: 22.6009\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 2.1977 - val_loss: 18.8328\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 2.1568 - val_loss: 16.9623\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 2.1495 - val_loss: 15.4508\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 2.1993 - val_loss: 15.0542\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 2.1537 - val_loss: 17.9296\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 2.2286 - val_loss: 20.6967\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 2.1957 - val_loss: 12.9784\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 2.2329 - val_loss: 12.2023\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 2.2187 - val_loss: 14.4675\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 2.1656 - val_loss: 18.2168\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 2.1309 - val_loss: 13.1686\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 2.2116 - val_loss: 11.8900\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 2.1946 - val_loss: 13.8588\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 2.1100 - val_loss: 13.8909\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 2.0935 - val_loss: 15.6868\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 2.1115 - val_loss: 12.0789\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 2.1203 - val_loss: 12.5737\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 2.0576 - val_loss: 16.5667\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 2.1186 - val_loss: 19.4011\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 2.1115 - val_loss: 16.1795\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 2.0365 - val_loss: 14.4070\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 2.0302 - val_loss: 15.4081\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 2.0412 - val_loss: 17.4566\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 2.0213 - val_loss: 17.8445\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 2.0636 - val_loss: 18.0978\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 2.0536 - val_loss: 15.9725\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 1.9966 - val_loss: 12.7626\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 2.0260 - val_loss: 12.4058\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 2.0111 - val_loss: 14.5088\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 1.9640 - val_loss: 20.0185\n",
      "Epoch 311/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 804us/step - loss: 2.1167 - val_loss: 22.1690\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 2.0923 - val_loss: 19.4909\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 1.9767 - val_loss: 15.9234\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 1.9318 - val_loss: 12.6465\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 2.0032 - val_loss: 11.5645\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 1.9958 - val_loss: 15.2650\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.9604 - val_loss: 17.4174\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 1.9655 - val_loss: 14.8417\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 1.9154 - val_loss: 12.9471\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 1.9095 - val_loss: 10.8780\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 770us/step - loss: 1.9744 - val_loss: 10.9513\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 1.8893 - val_loss: 15.6974\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 2.0435 - val_loss: 18.9714\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 2.0071 - val_loss: 14.4531\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 1.8856 - val_loss: 13.2453\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 1.8962 - val_loss: 11.1419\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 1.9485 - val_loss: 11.1251\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 1.9473 - val_loss: 13.1963\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 1.9349 - val_loss: 17.2268\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.9043 - val_loss: 16.6741\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 1.8904 - val_loss: 14.8524\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 1.8458 - val_loss: 10.1259\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 1.9415 - val_loss: 9.3242\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 1.9276 - val_loss: 11.9093\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 1.8313 - val_loss: 13.4820\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 1.8285 - val_loss: 13.2635\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 1.8163 - val_loss: 11.9286\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 743us/step - loss: 1.8495 - val_loss: 12.5782\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 1.8014 - val_loss: 16.1032\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 1.8917 - val_loss: 16.8575\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 1.8718 - val_loss: 14.9200\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 1.8173 - val_loss: 12.0701\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.7960 - val_loss: 9.6285\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 765us/step - loss: 1.8457 - val_loss: 9.2632\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 1.8241 - val_loss: 11.5427\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 1.7712 - val_loss: 14.9162\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.8329 - val_loss: 14.5830\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 1.8023 - val_loss: 10.8448\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.7747 - val_loss: 8.8901\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 1.8548 - val_loss: 9.3851\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 1.7587 - val_loss: 13.2678\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 1.7913 - val_loss: 15.8657\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 927us/step - loss: 1.8284 - val_loss: 12.7684\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 1.7395 - val_loss: 10.9679\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 932us/step - loss: 1.7570 - val_loss: 9.6274\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 1.7602 - val_loss: 11.3146\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 1.7227 - val_loss: 14.7943\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 1.8586 - val_loss: 15.5156\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 1.7979 - val_loss: 12.3202\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 1.7115 - val_loss: 10.1161\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 1.7086 - val_loss: 8.4785\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 1.7727 - val_loss: 6.5760\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 926us/step - loss: 1.7612 - val_loss: 9.9868\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 990us/step - loss: 1.7124 - val_loss: 11.1031\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 1.6879 - val_loss: 9.3955\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 917us/step - loss: 1.7056 - val_loss: 7.7038\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 905us/step - loss: 1.7087 - val_loss: 9.7023\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 1.6643 - val_loss: 12.8318\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 1.7894 - val_loss: 12.5495\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 936us/step - loss: 1.7182 - val_loss: 7.2486\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 1.7234 - val_loss: 8.4109\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 1.6539 - val_loss: 11.8672\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 938us/step - loss: 1.7009 - val_loss: 12.5040\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.7217 - val_loss: 10.9482\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 926us/step - loss: 1.6631 - val_loss: 8.3711\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 916us/step - loss: 1.6262 - val_loss: 5.7211\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 946us/step - loss: 1.7605 - val_loss: 5.4889\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 1.7390 - val_loss: 7.6868\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 973us/step - loss: 1.6730 - val_loss: 10.3308\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 1.6494 - val_loss: 9.3191\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 1.6406 - val_loss: 9.6993\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 1.6146 - val_loss: 7.9112\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 1.6161 - val_loss: 8.3602\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 1.6180 - val_loss: 8.3868\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 1.6115 - val_loss: 7.1657\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 1.6018 - val_loss: 8.1288\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 1.5904 - val_loss: 7.6763\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.5886 - val_loss: 6.9662\n",
      "Epoch 389/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 885us/step - loss: 1.5898 - val_loss: 7.8511\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.5940 - val_loss: 10.0251\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 1.6217 - val_loss: 9.3186\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.5897 - val_loss: 7.3214\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 1.5625 - val_loss: 7.2764\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 1.5553 - val_loss: 8.1586\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 1.5636 - val_loss: 8.4142\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.5452 - val_loss: 6.9634\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 1.5928 - val_loss: 5.9464\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 1.5852 - val_loss: 7.5360\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 1.5540 - val_loss: 8.8038\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 1.5783 - val_loss: 9.1692\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.5567 - val_loss: 6.3349\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 1.5495 - val_loss: 7.3334\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 1.5440 - val_loss: 8.5321\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 1.5366 - val_loss: 7.4954\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 1.5185 - val_loss: 7.1043\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 1.5362 - val_loss: 6.3634\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.5317 - val_loss: 7.5581\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 1.5166 - val_loss: 6.5170\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 1.4998 - val_loss: 7.2847\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 1.5426 - val_loss: 7.7113\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 1.4968 - val_loss: 5.5818\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.5411 - val_loss: 4.2168\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 1.5511 - val_loss: 4.8580\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 1.5150 - val_loss: 6.5244\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 1.4896 - val_loss: 7.2010\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 1.4996 - val_loss: 7.4900\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 1.5038 - val_loss: 7.7747\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.5053 - val_loss: 7.9781\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 1.4910 - val_loss: 6.3853\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 1.4726 - val_loss: 5.9417\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 1.4524 - val_loss: 6.6190\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 1.4655 - val_loss: 6.8289\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 1.4802 - val_loss: 5.8151\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 739us/step - loss: 1.4509 - val_loss: 4.6204\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 1.4513 - val_loss: 4.6935\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 1.4394 - val_loss: 5.7531\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 1.4447 - val_loss: 5.9098\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 1.4348 - val_loss: 5.4394\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 1.4305 - val_loss: 5.8198\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 1.4326 - val_loss: 6.5412\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 1.4497 - val_loss: 6.5506\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 1.4370 - val_loss: 5.6192\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 1.4228 - val_loss: 4.8138\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 1.4165 - val_loss: 3.8965\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 1.4235 - val_loss: 4.1101\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 1.4121 - val_loss: 5.8849\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 1.4060 - val_loss: 5.5942\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 1.3880 - val_loss: 5.0899\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 1.4025 - val_loss: 4.8452\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 1.4054 - val_loss: 6.4559\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 1.4097 - val_loss: 7.9947\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 1.4420 - val_loss: 6.7540\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 1.3972 - val_loss: 4.5869\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 1.4027 - val_loss: 4.1498\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 1.3777 - val_loss: 5.3530\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 1.3788 - val_loss: 5.1175\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 1.3773 - val_loss: 3.8099\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 1.3855 - val_loss: 4.7165\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 1.3599 - val_loss: 4.8274\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 1.3532 - val_loss: 5.3791\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 1.3649 - val_loss: 4.4426\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 1.3473 - val_loss: 2.1568\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 1.4584 - val_loss: 2.5719\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 1.3789 - val_loss: 3.7372\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 1.3435 - val_loss: 4.6766\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 1.3446 - val_loss: 3.9973\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 1.3395 - val_loss: 2.2655\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 1.4032 - val_loss: 2.6961\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 1.3425 - val_loss: 3.9848\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 1.3210 - val_loss: 5.4002\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 1.3655 - val_loss: 4.5646\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 1.3264 - val_loss: 3.8994\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.3179 - val_loss: 3.7453\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 1.3163 - val_loss: 3.9210\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.3113 - val_loss: 4.0914\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 1.3116 - val_loss: 4.2001\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 1.3069 - val_loss: 4.3596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 1.3225 - val_loss: 3.9608\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 1.2965 - val_loss: 2.9483\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 1.3249 - val_loss: 3.3563\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 1.3027 - val_loss: 4.9944\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 1.3366 - val_loss: 4.8185\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 1.3039 - val_loss: 3.1837\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 1.3035 - val_loss: 3.2110\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 1.2897 - val_loss: 3.0560\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 1.3025 - val_loss: 2.7266\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.2836 - val_loss: 3.7038\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 1.2846 - val_loss: 4.7056\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 1.2974 - val_loss: 3.7832\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 1.2706 - val_loss: 2.4096\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 1.2872 - val_loss: 3.5686\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 1.2665 - val_loss: 5.7106\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 1.3372 - val_loss: 5.2767\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 1.2739 - val_loss: 3.3634\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.2613 - val_loss: 2.9752\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 1.2620 - val_loss: 3.9191\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 1.2440 - val_loss: 3.5249\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.2582 - val_loss: 3.1578\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.2633 - val_loss: 3.8536\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 1.2570 - val_loss: 3.3683\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.2418 - val_loss: 3.8594\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 1.2497 - val_loss: 3.9147\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 1.2345 - val_loss: 2.9207\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 1.2301 - val_loss: 2.3974\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 1.2245 - val_loss: 2.8900\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 1.2303 - val_loss: 2.8406\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 1.2318 - val_loss: 1.7550\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 1.2473 - val_loss: 2.3801\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 1.2161 - val_loss: 2.5247\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 1.2035 - val_loss: 3.1992\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 948us/step - loss: 1.2024 - val_loss: 3.3377\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 1.2043 - val_loss: 3.1049\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.1925 - val_loss: 2.4426\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.2338 - val_loss: 2.3712\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 1.1906 - val_loss: 4.0422\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 1.2118 - val_loss: 4.1869\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 1.2130 - val_loss: 2.5775\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 1.1888 - val_loss: 2.4543\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 1.1781 - val_loss: 3.0548\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 1.1757 - val_loss: 3.2102\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 1.1892 - val_loss: 2.9256\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 1.1707 - val_loss: 2.3766\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.1729 - val_loss: 2.2851\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 1.1757 - val_loss: 2.6084\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 1.1638 - val_loss: 2.2510\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.1641 - val_loss: 2.6226\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.1647 - val_loss: 2.5606\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 1.1727 - val_loss: 1.7049\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 1.1743 - val_loss: 2.5542\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 1.1486 - val_loss: 3.2168\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 1.1810 - val_loss: 2.9885\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 1.1496 - val_loss: 2.0013\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 1.1473 - val_loss: 1.7308\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 1.1529 - val_loss: 2.0697\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 1.1621 - val_loss: 2.4415\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 1.1417 - val_loss: 1.2966\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 1.1565 - val_loss: 1.4927\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 1.1369 - val_loss: 2.3039\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 1.1471 - val_loss: 2.5838\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 1.1447 - val_loss: 2.1300\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 1.1356 - val_loss: 1.7215\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 1.1250 - val_loss: 1.7120\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 1.1193 - val_loss: 1.9454\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 1.1242 - val_loss: 1.8125\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 1.1202 - val_loss: 1.7295\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 1.1193 - val_loss: 1.8841\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 1.1097 - val_loss: 1.8038\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 1.1067 - val_loss: 1.8017\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 1.1019 - val_loss: 2.2760\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 1.0991 - val_loss: 2.1206\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 1.0987 - val_loss: 1.7647\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 1.1061 - val_loss: 2.8345\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 1.1239 - val_loss: 3.2565\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 1.1165 - val_loss: 1.7891\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.0906 - val_loss: 1.9739\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 1.0626 - val_loss: 2.6487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 1.1103 - val_loss: 2.6210\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 1.0993 - val_loss: 1.3227\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.0925 - val_loss: 1.2212\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 1.0879 - val_loss: 2.0143\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 1.0841 - val_loss: 1.8197\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 1.0647 - val_loss: 1.1880\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.1196 - val_loss: 1.6587\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 1.0880 - val_loss: 3.0235\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 1.0888 - val_loss: 2.1790\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 1.0614 - val_loss: 1.0343\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.0745 - val_loss: 1.6308\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 1.0448 - val_loss: 2.6674\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 1.0934 - val_loss: 1.8627\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 1.0456 - val_loss: 0.7556\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 1.0965 - val_loss: 0.7752\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 1.0783 - val_loss: 1.9916\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 1.0424 - val_loss: 2.4763\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.0452 - val_loss: 2.3879\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 1.0721 - val_loss: 2.0536\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 1.0404 - val_loss: 1.1130\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 1.0457 - val_loss: 1.5599\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 1.0150 - val_loss: 2.0704\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 1.0352 - val_loss: 1.8224\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 1.0362 - val_loss: 1.1529\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 1.0234 - val_loss: 1.0812\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 1.0208 - val_loss: 1.2133\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 1.0120 - val_loss: 1.5007\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 1.0086 - val_loss: 1.8802\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 1.0180 - val_loss: 1.9506\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 1.0007 - val_loss: 0.9820\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 1.0217 - val_loss: 0.9413\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 1.0061 - val_loss: 1.5547\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.9928 - val_loss: 1.9099\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 1.0028 - val_loss: 1.3374\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.9885 - val_loss: 0.5683\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 1.0537 - val_loss: 0.9153\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 902us/step - loss: 1.0143 - val_loss: 2.5039\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 1.0011 - val_loss: 1.3627\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.9861 - val_loss: 1.0638\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.9793 - val_loss: 1.7520\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.9801 - val_loss: 1.5674\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.9745 - val_loss: 1.2695\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.9737 - val_loss: 0.8498\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.9821 - val_loss: 0.7606\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.9726 - val_loss: 2.0549\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 1.0206 - val_loss: 2.0888\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.9635 - val_loss: 0.5372\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 1.0288 - val_loss: 0.6157\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.9882 - val_loss: 2.6142\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 1.0584 - val_loss: 2.2279\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.9685 - val_loss: 0.3377\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 1.1420 - val_loss: 0.5116\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.9769 - val_loss: 2.5869\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 1.0278 - val_loss: 1.7849\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.9371 - val_loss: 0.5913\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.9990 - val_loss: 0.8402\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.9450 - val_loss: 1.8091\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.9704 - val_loss: 1.2221\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.9400 - val_loss: 0.6357\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.9418 - val_loss: 0.8848\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 0.9448 - val_loss: 1.3688\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.9643 - val_loss: 0.7981\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.9601 - val_loss: 0.4759\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.9431 - val_loss: 0.8845\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.9520 - val_loss: 1.2885\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.9522 - val_loss: 0.7943\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.9592 - val_loss: 0.3889\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.9570 - val_loss: 1.0787\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.9347 - val_loss: 2.1102\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.9483 - val_loss: 1.2791\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.9195 - val_loss: 1.0556\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.9149 - val_loss: 1.0035\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.9112 - val_loss: 1.2353\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.9217 - val_loss: 0.9093\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.9167 - val_loss: 0.5980\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.9106 - val_loss: 1.0053\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.9258 - val_loss: 1.0123\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.9013 - val_loss: 0.5463\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.9118 - val_loss: 1.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.9233 - val_loss: 1.2895\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.9031 - val_loss: 0.7291\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.9084 - val_loss: 0.7201\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.8962 - val_loss: 0.9815\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.8999 - val_loss: 0.9538\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.8890 - val_loss: 1.0833\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.8951 - val_loss: 0.9006\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.8926 - val_loss: 0.5973\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.8826 - val_loss: 1.1274\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.9437 - val_loss: 1.1369\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.8939 - val_loss: 0.3591\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 0.9079 - val_loss: 0.6963\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.8750 - val_loss: 1.0972\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.8794 - val_loss: 0.9512\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.8735 - val_loss: 0.7317\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 0.8753 - val_loss: 0.7738\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.8681 - val_loss: 1.1901\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.8937 - val_loss: 1.2339\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.8788 - val_loss: 0.6617\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.8711 - val_loss: 0.4924\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.8633 - val_loss: 1.0792\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.8739 - val_loss: 1.1855\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.8753 - val_loss: 0.9100\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.8675 - val_loss: 0.4949\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.8628 - val_loss: 0.8937\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.8668 - val_loss: 1.0983\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.8608 - val_loss: 0.5019\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.9003 - val_loss: 0.5040\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.8444 - val_loss: 1.4336\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.8948 - val_loss: 1.0736\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.8511 - val_loss: 0.4318\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.8589 - val_loss: 0.8052\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.8553 - val_loss: 0.9685\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.8463 - val_loss: 1.4907\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.8697 - val_loss: 1.1033\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.8456 - val_loss: 0.3473\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.9073 - val_loss: 0.4985\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.8618 - val_loss: 2.0756\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.9611 - val_loss: 0.9925\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.8993 - val_loss: 0.2228\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.8743 - val_loss: 1.6398\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.8904 - val_loss: 0.9519\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.8342 - val_loss: 0.4447\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.8488 - val_loss: 0.6845\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.8325 - val_loss: 1.0780\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.8371 - val_loss: 0.8385\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.8266 - val_loss: 0.7093\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.8245 - val_loss: 0.7672\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.8228 - val_loss: 0.7566\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 917us/step - loss: 0.8223 - val_loss: 0.7875\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.8215 - val_loss: 0.9166\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.8235 - val_loss: 0.8517\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.8328 - val_loss: 0.7300\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.8192 - val_loss: 0.4814\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.8211 - val_loss: 0.6408\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.8177 - val_loss: 0.8357\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.8336 - val_loss: 0.9363\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.8180 - val_loss: 0.4471\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.8198 - val_loss: 0.3417\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.8242 - val_loss: 0.7257\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 924us/step - loss: 0.8161 - val_loss: 1.1925\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.8262 - val_loss: 0.8744\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.8045 - val_loss: 0.5317\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.8112 - val_loss: 0.3739\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.8286 - val_loss: 0.5675\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.8057 - val_loss: 1.1866\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.8019 - val_loss: 0.5495\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.8471 - val_loss: 0.5663\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.8189 - val_loss: 1.9365\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.8824 - val_loss: 0.8900\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.7903 - val_loss: 0.1620\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 0.8576 - val_loss: 0.5818\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.8254 - val_loss: 1.2865\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 777us/step - loss: 0.8114 - val_loss: 0.3242\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 732us/step - loss: 0.8031 - val_loss: 0.6262\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.7978 - val_loss: 1.2547\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.8060 - val_loss: 0.4871\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.7849 - val_loss: 0.2471\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.8044 - val_loss: 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.8018 - val_loss: 1.0631\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.7842 - val_loss: 0.4151\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.7927 - val_loss: 0.6913\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.7714 - val_loss: 0.7652\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.7700 - val_loss: 0.6378\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.7683 - val_loss: 0.8050\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.7697 - val_loss: 0.8282\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.7681 - val_loss: 0.8706\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.7717 - val_loss: 0.5840\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.7675 - val_loss: 0.4035\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.7750 - val_loss: 0.7160\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.7697 - val_loss: 0.9205\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.7587 - val_loss: 0.2696\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.8283 - val_loss: 0.4541\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.7673 - val_loss: 1.3668\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 763us/step - loss: 0.7811 - val_loss: 0.6444\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.7666 - val_loss: 0.4520\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.7728 - val_loss: 0.9665\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.7722 - val_loss: 1.4039\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.7754 - val_loss: 0.5181\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.7635 - val_loss: 0.7909\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.7531 - val_loss: 0.9515\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.7490 - val_loss: 0.5203\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.7519 - val_loss: 0.6292\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.7457 - val_loss: 0.9824\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.7497 - val_loss: 0.5447\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.7487 - val_loss: 0.5618\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.7544 - val_loss: 1.1456\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.7469 - val_loss: 0.6155\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.7375 - val_loss: 0.6262\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.7406 - val_loss: 0.7299\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.7393 - val_loss: 0.6593\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.7370 - val_loss: 0.3924\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 735us/step - loss: 0.7441 - val_loss: 0.8100\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7475 - val_loss: 1.1494\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.7621 - val_loss: 0.5750\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.7416 - val_loss: 0.3378\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 762us/step - loss: 0.7519 - val_loss: 0.6664\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 779us/step - loss: 0.7482 - val_loss: 0.6912\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.7409 - val_loss: 0.5886\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.7287 - val_loss: 0.9847\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.7410 - val_loss: 0.9217\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.7228 - val_loss: 0.4399\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 725us/step - loss: 0.7477 - val_loss: 1.2375\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.7369 - val_loss: 1.5129\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.7261 - val_loss: 0.3764\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 0.7812 - val_loss: 0.6305\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.7216 - val_loss: 2.2077\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 750us/step - loss: 0.7995 - val_loss: 1.3549\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.7062 - val_loss: 0.1844\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.8805 - val_loss: 0.5830\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.7220 - val_loss: 2.2917\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.7687 - val_loss: 0.6655\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 726us/step - loss: 0.7883 - val_loss: 0.4379\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.7375 - val_loss: 1.6333\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.7979 - val_loss: 1.5352\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.7039 - val_loss: 0.1634\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 902us/step - loss: 0.8912 - val_loss: 0.6134\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.8055 - val_loss: 4.0473\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.9954 - val_loss: 0.2864\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.7525 - val_loss: 0.1609\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 927us/step - loss: 0.7820 - val_loss: 1.3500\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.7585 - val_loss: 1.6975\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.7046 - val_loss: 0.3491\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.7103 - val_loss: 0.7429\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.6861 - val_loss: 0.6991\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.7025 - val_loss: 0.6638\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.6831 - val_loss: 1.2642\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.6899 - val_loss: 0.5578\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.6968 - val_loss: 0.4880\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.6947 - val_loss: 0.7251\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.6795 - val_loss: 0.9222\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.6866 - val_loss: 1.2197\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6887 - val_loss: 0.9207\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.6791 - val_loss: 0.3589\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.6951 - val_loss: 0.8519\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6854 - val_loss: 1.3224\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.7053 - val_loss: 0.5772\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.6948 - val_loss: 0.2977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.7020 - val_loss: 1.0931\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.7114 - val_loss: 1.7103\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.6993 - val_loss: 0.5932\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.7163 - val_loss: 0.2905\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.6996 - val_loss: 1.0584\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.6744 - val_loss: 0.6855\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.6707 - val_loss: 0.5318\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.6787 - val_loss: 1.1240\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.6702 - val_loss: 0.9851\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.6682 - val_loss: 1.1264\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.6670 - val_loss: 0.9553\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.6624 - val_loss: 0.8338\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.6619 - val_loss: 0.8982\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.6621 - val_loss: 0.7041\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.6521 - val_loss: 1.0085\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.6694 - val_loss: 0.7607\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.6614 - val_loss: 0.7054\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6633 - val_loss: 0.9853\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.6624 - val_loss: 0.9003\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.6564 - val_loss: 0.9332\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.6451 - val_loss: 0.6714\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.6523 - val_loss: 0.7519\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.6480 - val_loss: 1.0246\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.6490 - val_loss: 1.2089\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.6516 - val_loss: 0.9501\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.6631 - val_loss: 0.8734\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.6630 - val_loss: 1.2564\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.6401 - val_loss: 0.6840\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 0.6613 - val_loss: 1.2041\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.6791 - val_loss: 1.1966\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.6632 - val_loss: 0.3642\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.6641 - val_loss: 1.2605\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.7094 - val_loss: 1.3330\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.6707 - val_loss: 0.2825\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.6613 - val_loss: 0.9111\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.6599 - val_loss: 0.9101\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.6334 - val_loss: 0.4557\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.6413 - val_loss: 0.6841\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 747us/step - loss: 0.6291 - val_loss: 1.1819\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 750us/step - loss: 0.6377 - val_loss: 1.0541\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.6304 - val_loss: 0.6584\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6316 - val_loss: 1.0329\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.6433 - val_loss: 1.1149\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 739us/step - loss: 0.6466 - val_loss: 0.7077\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.6314 - val_loss: 1.3020\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.6365 - val_loss: 0.3858\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.6574 - val_loss: 0.7424\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.6446 - val_loss: 2.3824\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.6744 - val_loss: 0.7237\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.6425 - val_loss: 1.2217\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.6232 - val_loss: 1.4002\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.6230 - val_loss: 0.8338\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.6187 - val_loss: 0.9741\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.6190 - val_loss: 0.9604\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 778us/step - loss: 0.6350 - val_loss: 0.7253\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.6256 - val_loss: 1.2945\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.6449 - val_loss: 0.4224\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.6411 - val_loss: 1.0216\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.6100 - val_loss: 1.1604\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 780us/step - loss: 0.6316 - val_loss: 1.3282\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 759us/step - loss: 0.6550 - val_loss: 1.3890\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.6287 - val_loss: 0.5748\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.6068 - val_loss: 1.4121\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.6368 - val_loss: 0.8626\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.6417 - val_loss: 0.3558\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.6496 - val_loss: 1.5701\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.6567 - val_loss: 0.6716\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.6203 - val_loss: 0.8167\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.6278 - val_loss: 1.6182\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.5948 - val_loss: 0.4641\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.6573 - val_loss: 0.8887\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.6018 - val_loss: 1.5709\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 927us/step - loss: 0.5902 - val_loss: 0.5884\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.6412 - val_loss: 1.2383\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.5943 - val_loss: 3.0797\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.6850 - val_loss: 1.1554\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.6292 - val_loss: 0.7074\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.6493 - val_loss: 2.0505\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.6018 - val_loss: 0.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.6416 - val_loss: 0.9467\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.5852 - val_loss: 1.6413\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5921 - val_loss: 0.6663\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.6084 - val_loss: 0.8424\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.5697 - val_loss: 1.9462\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.6321 - val_loss: 0.8740\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.6022 - val_loss: 0.3099\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.6227 - val_loss: 1.5973\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.6473 - val_loss: 1.3077\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.5903 - val_loss: 0.3454\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.6238 - val_loss: 1.4280\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.5887 - val_loss: 1.5622\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.5705 - val_loss: 1.2462\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.5714 - val_loss: 1.2365\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.5773 - val_loss: 1.4512\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.5777 - val_loss: 1.5055\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.5701 - val_loss: 0.9682\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.5767 - val_loss: 1.3510\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.5728 - val_loss: 1.4848\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.5781 - val_loss: 0.9492\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.5827 - val_loss: 1.0918\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.5744 - val_loss: 0.9219\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.5719 - val_loss: 1.0541\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.5679 - val_loss: 0.6527\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.5992 - val_loss: 1.1686\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.5557 - val_loss: 2.4032\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.5968 - val_loss: 1.7859\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.5592 - val_loss: 0.9081\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.5797 - val_loss: 0.8978\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.5500 - val_loss: 2.2258\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 0.6307 - val_loss: 1.6964\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.5479 - val_loss: 0.5188\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.5961 - val_loss: 1.0767\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.5689 - val_loss: 1.3945\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.5536 - val_loss: 0.6820\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.5771 - val_loss: 1.4979\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.5748 - val_loss: 2.7021\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.5497 - val_loss: 0.6234\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.6502 - val_loss: 1.5586\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.5897 - val_loss: 2.6650\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 915us/step - loss: 0.5671 - val_loss: 1.2329\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.5410 - val_loss: 1.4561\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.5250 - val_loss: 1.3372\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.5504 - val_loss: 0.5994\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.6054 - val_loss: 0.8674\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.5370 - val_loss: 1.9720\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.5460 - val_loss: 1.0680\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.5394 - val_loss: 1.3413\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 0.5463 - val_loss: 2.2433\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.5437 - val_loss: 1.0114\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 918us/step - loss: 0.5420 - val_loss: 0.8209\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.5328 - val_loss: 1.4389\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 944us/step - loss: 0.5332 - val_loss: 0.8201\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.5689 - val_loss: 1.4608\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.5612 - val_loss: 3.0983\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 0.5634 - val_loss: 1.1618\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.5548 - val_loss: 1.8803\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.5325 - val_loss: 1.4907\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.5301 - val_loss: 1.5955\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 0.5242 - val_loss: 1.6307\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.5197 - val_loss: 1.6938\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.5135 - val_loss: 1.1959\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.5171 - val_loss: 1.0691\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.5200 - val_loss: 1.3294\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.5469 - val_loss: 1.8134\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.5199 - val_loss: 0.7756\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.5358 - val_loss: 1.1474\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5141 - val_loss: 1.7118\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.5165 - val_loss: 0.9566\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.5283 - val_loss: 1.7029\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.5151 - val_loss: 2.3542\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.5229 - val_loss: 1.0286\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.5480 - val_loss: 1.0805\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.5087 - val_loss: 1.7815\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.5025 - val_loss: 1.1971\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.5204 - val_loss: 1.7542\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.5264 - val_loss: 2.7828\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.5165 - val_loss: 1.3314\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.5353 - val_loss: 1.9244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.5171 - val_loss: 1.3994\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.5033 - val_loss: 1.4706\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.4936 - val_loss: 1.0602\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.4994 - val_loss: 1.2286\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.5012 - val_loss: 1.6843\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.5111 - val_loss: 1.3555\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.5267 - val_loss: 0.8531\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.5071 - val_loss: 1.9634\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.5090 - val_loss: 0.7131\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.5121 - val_loss: 1.5877\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5005 - val_loss: 1.5504\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.4952 - val_loss: 1.4066\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.4999 - val_loss: 0.8223\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.5088 - val_loss: 1.7282\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.4839 - val_loss: 1.3868\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.4873 - val_loss: 1.8466\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 749us/step - loss: 0.4944 - val_loss: 1.6604\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.4852 - val_loss: 1.0237\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.5059 - val_loss: 1.8480\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.4847 - val_loss: 1.7295\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.4862 - val_loss: 1.3604\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.4930 - val_loss: 1.0209\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.4893 - val_loss: 1.6992\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.4727 - val_loss: 1.5130\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.4773 - val_loss: 1.4062\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.4968 - val_loss: 2.4059\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.5284 - val_loss: 2.0558\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.5106 - val_loss: 1.4118\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.5351 - val_loss: 4.2731\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.5592 - val_loss: 0.5002\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.5854 - val_loss: 2.2064\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.5126 - val_loss: 1.4219\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.5516 - val_loss: 1.2153\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 0.5784 - val_loss: 1.6658\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.6757 - val_loss: 0.9778\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.7467 - val_loss: 4.7287\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.6053 - val_loss: 0.4258\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.8690 - val_loss: 5.4347\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.9002 - val_loss: 1.4033\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.6997 - val_loss: 0.6437\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.5852 - val_loss: 4.3852\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.5846 - val_loss: 0.9161\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.4861 - val_loss: 2.6988\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.4665 - val_loss: 1.2748\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.4912 - val_loss: 2.0835\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.4584 - val_loss: 2.1360\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.4561 - val_loss: 1.9232\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.4635 - val_loss: 2.4504\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.4746 - val_loss: 2.2046\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.4724 - val_loss: 1.5195\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.4944 - val_loss: 2.0430\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.4928 - val_loss: 1.1295\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.4544 - val_loss: 2.4773\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 0.4819 - val_loss: 1.6164\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 930us/step - loss: 0.4582 - val_loss: 2.2807\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.4919 - val_loss: 2.1933\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.4539 - val_loss: 1.0953\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.4914 - val_loss: 2.1499\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.4527 - val_loss: 3.3591\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.4836 - val_loss: 2.2320\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.4411 - val_loss: 1.9911\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.4418 - val_loss: 1.5048\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.4656 - val_loss: 1.8865\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.4621 - val_loss: 1.8452\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.4468 - val_loss: 0.8473\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.4814 - val_loss: 2.6824\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.4767 - val_loss: 1.4410\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.4538 - val_loss: 1.5200\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.4460 - val_loss: 2.8742\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 764us/step - loss: 0.4509 - val_loss: 2.0853\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.4374 - val_loss: 2.4229\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.4397 - val_loss: 1.7072\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.4719 - val_loss: 2.5718\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.4632 - val_loss: 2.8429\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.4397 - val_loss: 1.6838\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.4368 - val_loss: 2.7632\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.4558 - val_loss: 1.5804\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.4433 - val_loss: 2.5184\n",
      "Epoch 1020/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 811us/step - loss: 0.4326 - val_loss: 1.3358\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.4545 - val_loss: 1.9863\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.4282 - val_loss: 1.8721\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 767us/step - loss: 0.4316 - val_loss: 2.0617\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.4398 - val_loss: 2.8174\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.4275 - val_loss: 1.5907\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.4399 - val_loss: 2.6851\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.5220 - val_loss: 1.9559\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 747us/step - loss: 0.5309 - val_loss: 1.0674\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.4507 - val_loss: 3.5451\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.4635 - val_loss: 0.6837\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.4950 - val_loss: 3.3684\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.5075 - val_loss: 1.6960\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.4564 - val_loss: 1.8408\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.4502 - val_loss: 2.9076\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.4135 - val_loss: 1.2474\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.4730 - val_loss: 2.2671\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.4143 - val_loss: 1.7123\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.4191 - val_loss: 2.9915\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.4651 - val_loss: 1.6057\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.6016 - val_loss: 1.1816\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.4347 - val_loss: 3.6398\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.4232 - val_loss: 1.2287\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.4435 - val_loss: 2.3120\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.4173 - val_loss: 2.2245\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.4194 - val_loss: 2.0899\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.4251 - val_loss: 2.2906\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.4193 - val_loss: 1.4622\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.4162 - val_loss: 2.1239\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.4043 - val_loss: 2.1446\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.4103 - val_loss: 2.9123\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.4091 - val_loss: 1.5141\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.4957 - val_loss: 3.4965\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 905us/step - loss: 0.5531 - val_loss: 3.0728\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.4804 - val_loss: 0.5566\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.5135 - val_loss: 5.9990\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.5968 - val_loss: 1.4783\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.4363 - val_loss: 2.1624\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.4240 - val_loss: 2.5647\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.4207 - val_loss: 1.0462\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.4518 - val_loss: 1.9886\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.4233 - val_loss: 2.2821\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.3894 - val_loss: 1.7449\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.4035 - val_loss: 4.3720\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.4877 - val_loss: 2.1353\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.4291 - val_loss: 2.5984\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.4208 - val_loss: 2.3425\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.4072 - val_loss: 1.6100\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.4369 - val_loss: 2.9468\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.3853 - val_loss: 1.3622\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.4451 - val_loss: 3.7740\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.4428 - val_loss: 3.8978\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.4147 - val_loss: 2.1558\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.4117 - val_loss: 2.5230\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.4228 - val_loss: 2.0936\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.4048 - val_loss: 2.3085\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.4202 - val_loss: 1.5656\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.3958 - val_loss: 3.7301\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.4760 - val_loss: 2.0478\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.4437 - val_loss: 2.8434\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.4289 - val_loss: 3.0291\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.3876 - val_loss: 1.2222\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.4487 - val_loss: 3.7108\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.4375 - val_loss: 1.9246\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.4053 - val_loss: 3.5324\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.4201 - val_loss: 3.2126\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.4530 - val_loss: 2.6883\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.4109 - val_loss: 3.7597\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.4062 - val_loss: 1.6509\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.4174 - val_loss: 4.1987\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.4049 - val_loss: 2.4501\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.3871 - val_loss: 2.8440\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.3837 - val_loss: 3.5704\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.3881 - val_loss: 2.7388\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.3817 - val_loss: 3.4374\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.3906 - val_loss: 2.9882\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.3734 - val_loss: 3.0907\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.3851 - val_loss: 2.9950\n",
      "Epoch 1098/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 877us/step - loss: 0.3788 - val_loss: 3.2757\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.4206 - val_loss: 2.2629\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.3865 - val_loss: 3.1249\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.4156 - val_loss: 3.0403\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.3856 - val_loss: 1.4354\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.4039 - val_loss: 4.7660\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.4138 - val_loss: 2.4504\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.4013 - val_loss: 3.0210\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.3747 - val_loss: 3.5913\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.3775 - val_loss: 3.1056\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.3905 - val_loss: 2.4013\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.3847 - val_loss: 2.1282\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.3793 - val_loss: 3.6886\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.4058 - val_loss: 1.8746\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.3875 - val_loss: 3.6346\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.5003 - val_loss: 2.2430\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.4011 - val_loss: 2.6740\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.4078 - val_loss: 2.9013\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.3730 - val_loss: 2.0828\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.3805 - val_loss: 2.8140\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.3669 - val_loss: 1.7690\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.4093 - val_loss: 3.9285\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.4883 - val_loss: 2.0516\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.4321 - val_loss: 2.0027\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.3657 - val_loss: 3.7012\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.3738 - val_loss: 2.9264\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.3732 - val_loss: 2.9807\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.3658 - val_loss: 3.3812\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.3658 - val_loss: 3.4800\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.3571 - val_loss: 1.6548\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.4880 - val_loss: 4.2524\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.5814 - val_loss: 3.7106\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.3760 - val_loss: 0.8936\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.4372 - val_loss: 5.9524\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.4690 - val_loss: 1.5300\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.4977 - val_loss: 3.3940\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.4414 - val_loss: 3.0677\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.3625 - val_loss: 1.8452\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.3603 - val_loss: 3.6959\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.4192 - val_loss: 1.7433\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.3718 - val_loss: 1.7821\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.3537 - val_loss: 4.1296\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.4018 - val_loss: 2.2889\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.3512 - val_loss: 1.8428\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.3644 - val_loss: 2.1785\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.3445 - val_loss: 2.6407\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.3456 - val_loss: 2.5454\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.3563 - val_loss: 4.0899\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.4397 - val_loss: 2.5739\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.3491 - val_loss: 1.6057\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.3690 - val_loss: 2.8933\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.3448 - val_loss: 2.3833\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.3748 - val_loss: 3.6121\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.3673 - val_loss: 3.5143\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.3541 - val_loss: 3.8635\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.4017 - val_loss: 3.0368\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 895us/step - loss: 0.3518 - val_loss: 2.7191\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.3449 - val_loss: 1.9413\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.5144 - val_loss: 4.1133\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.4782 - val_loss: 2.2583\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3649 - val_loss: 1.8127\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.3456 - val_loss: 4.2918\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.3620 - val_loss: 1.3024\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 902us/step - loss: 0.4805 - val_loss: 5.3397\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.6391 - val_loss: 1.6678\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.5258 - val_loss: 3.2605\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.4165 - val_loss: 3.2347\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.3505 - val_loss: 1.8672\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.3519 - val_loss: 2.5673\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.3782 - val_loss: 1.3006\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 769us/step - loss: 0.3750 - val_loss: 3.1872\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 765us/step - loss: 0.3488 - val_loss: 2.7739\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.3409 - val_loss: 4.6627\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.3778 - val_loss: 3.6977\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.3545 - val_loss: 3.6340\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.3398 - val_loss: 2.2619\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.3708 - val_loss: 2.6373\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 762us/step - loss: 0.3339 - val_loss: 3.6278\n",
      "Epoch 1176/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 826us/step - loss: 0.3529 - val_loss: 2.3917\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.3488 - val_loss: 3.4679\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.3666 - val_loss: 4.4146\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.3397 - val_loss: 2.5502\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.3409 - val_loss: 5.3657\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.4192 - val_loss: 2.2059\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.3427 - val_loss: 3.2676\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.3442 - val_loss: 1.2919\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.4295 - val_loss: 3.4825\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.3787 - val_loss: 2.3717\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.4434 - val_loss: 4.7639\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 772us/step - loss: 0.4891 - val_loss: 2.3386\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.3518 - val_loss: 2.6968\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.3169 - val_loss: 3.9892\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.3288 - val_loss: 1.9265\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3510 - val_loss: 3.7097\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3241 - val_loss: 3.0698\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.3218 - val_loss: 3.0212\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.3184 - val_loss: 2.0278\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.4112 - val_loss: 4.3341\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.3566 - val_loss: 3.0893\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.3175 - val_loss: 2.4585\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.3195 - val_loss: 3.2737\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.3188 - val_loss: 3.2935\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 764us/step - loss: 0.3155 - val_loss: 2.2803\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.3394 - val_loss: 3.7040\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.3157 - val_loss: 1.6574\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.4196 - val_loss: 5.1159\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.5901 - val_loss: 2.6797\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.3554 - val_loss: 2.6383\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.3048 - val_loss: 4.6309\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.3412 - val_loss: 1.9769\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.3478 - val_loss: 4.7334\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.4051 - val_loss: 1.4815\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.3991 - val_loss: 3.8499\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.3312 - val_loss: 3.3767\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.3115 - val_loss: 3.7060\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 764us/step - loss: 0.3093 - val_loss: 2.7296\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.3565 - val_loss: 4.8841\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.3622 - val_loss: 3.0112\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.2977 - val_loss: 3.6652\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.3259 - val_loss: 3.1806\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 755us/step - loss: 0.3264 - val_loss: 1.8764\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 782us/step - loss: 0.3219 - val_loss: 3.1514\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 792us/step - loss: 0.3239 - val_loss: 1.9629\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.3334 - val_loss: 3.2528\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.2996 - val_loss: 3.0854\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.3077 - val_loss: 3.6988\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.3061 - val_loss: 3.1177\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.3018 - val_loss: 3.7779\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.3033 - val_loss: 2.3200\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.3037 - val_loss: 2.0005\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.3108 - val_loss: 3.7661\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3060 - val_loss: 2.8756\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.2959 - val_loss: 4.5648\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.3494 - val_loss: 2.0532\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.3404 - val_loss: 5.8325\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.4202 - val_loss: 1.1866\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.4925 - val_loss: 6.5815\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.5924 - val_loss: 1.0639\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.5345 - val_loss: 6.3676\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.4929 - val_loss: 1.7694\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.3560 - val_loss: 4.9906\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.4365 - val_loss: 0.7115\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.6879 - val_loss: 5.3965\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.5873 - val_loss: 1.5380\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.4043 - val_loss: 3.2408\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.4260 - val_loss: 2.0738\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 894us/step - loss: 0.3188 - val_loss: 3.1283\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 0.3259 - val_loss: 2.1790\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 921us/step - loss: 0.3163 - val_loss: 2.9781\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.2799 - val_loss: 3.8657\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.2909 - val_loss: 3.1023\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.3085 - val_loss: 1.3401\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.4925 - val_loss: 5.3158\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.4860 - val_loss: 1.1976\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.5266 - val_loss: 6.8736\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 902us/step - loss: 0.5844 - val_loss: 1.5342\n",
      "Epoch 1254/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 827us/step - loss: 0.3398 - val_loss: 3.7407\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2929 - val_loss: 2.5406\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.3073 - val_loss: 3.9243\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.3165 - val_loss: 3.9460\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.3338 - val_loss: 2.7641\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.3660 - val_loss: 4.7232\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.3307 - val_loss: 2.1392\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.3660 - val_loss: 4.0372\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.2924 - val_loss: 3.2116\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.2892 - val_loss: 2.0198\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 0.3196 - val_loss: 2.1896\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2919 - val_loss: 2.0352\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3270 - val_loss: 3.1962\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.2754 - val_loss: 3.4123\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.2761 - val_loss: 4.9081\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.3124 - val_loss: 1.3267\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 917us/step - loss: 0.3984 - val_loss: 6.6458\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 1.9237\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.4075 - val_loss: 5.0199\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.3254 - val_loss: 2.1901\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.3712 - val_loss: 5.8375\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.4158 - val_loss: 1.4573\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.4378 - val_loss: 4.1386\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.2780 - val_loss: 3.2181\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2742 - val_loss: 2.8480\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.2686 - val_loss: 5.5363\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.3141 - val_loss: 3.0067\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2770 - val_loss: 3.2216\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.2735 - val_loss: 3.1839\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.2751 - val_loss: 4.1965\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.2787 - val_loss: 2.4352\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.2780 - val_loss: 5.4245\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 778us/step - loss: 0.3726 - val_loss: 2.6325\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.2888 - val_loss: 3.1585\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.2800 - val_loss: 3.1351\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.2758 - val_loss: 1.5851\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.4030 - val_loss: 4.9979\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.3575 - val_loss: 1.4870\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.3020 - val_loss: 6.3273\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.4532 - val_loss: 0.6109\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.4679 - val_loss: 5.8970\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.3956 - val_loss: 2.2517\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.2895 - val_loss: 2.8572\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.3056 - val_loss: 5.4039\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.3287 - val_loss: 1.6465\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.3701 - val_loss: 5.9267\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.3392 - val_loss: 3.0528\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.2594 - val_loss: 5.9817\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.3667 - val_loss: 0.9656\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.4687 - val_loss: 6.5071\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.3377 - val_loss: 1.7277\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3630 - val_loss: 7.4043\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.3575 - val_loss: 1.7808\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3391 - val_loss: 7.8895\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.4535 - val_loss: 1.6972\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.3236 - val_loss: 2.7806\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.2735 - val_loss: 2.2102\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.2781 - val_loss: 5.2583\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.2823 - val_loss: 3.7079\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2570 - val_loss: 1.6239\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.4927 - val_loss: 6.5643\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.3270 - val_loss: 0.7560\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.8547 - val_loss: 10.6137\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.7643 - val_loss: 1.0021\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.4391 - val_loss: 5.6145\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.3066 - val_loss: 4.5177\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.3317 - val_loss: 2.8382\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.3176 - val_loss: 5.3964\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.3181 - val_loss: 2.0814\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.4211 - val_loss: 8.5442\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.4177 - val_loss: 0.9315\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.4681 - val_loss: 9.9312\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.5093 - val_loss: 0.4498\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.8424 - val_loss: 23.6541\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 1.8534 - val_loss: 0.6036\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 876us/step - loss: 0.9372 - val_loss: 8.7733\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.6775 - val_loss: 0.6382\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.7676 - val_loss: 10.3182\n",
      "Epoch 1332/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 844us/step - loss: 0.4733 - val_loss: 3.9289\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.5123 - val_loss: 3.6200\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 914us/step - loss: 0.3514 - val_loss: 6.7764\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.5019 - val_loss: 1.8248\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.4488 - val_loss: 7.2734\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 963us/step - loss: 0.4555 - val_loss: 0.6879\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.5466 - val_loss: 7.8614\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 899us/step - loss: 0.4742 - val_loss: 0.5468\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.4544 - val_loss: 12.7510\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.6837 - val_loss: 0.4853\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.8117 - val_loss: 19.5179\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 1.4845 - val_loss: 0.9523\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.5833 - val_loss: 3.3149\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.3705 - val_loss: 4.6266\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.4785 - val_loss: 1.9844\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.5973 - val_loss: 9.3255\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 1.4370 - val_loss: 0.4239\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 1.2777 - val_loss: 10.6336\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.7165 - val_loss: 0.5069\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.5445 - val_loss: 6.3259\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.4106 - val_loss: 2.4351\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.3311 - val_loss: 2.8833\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.2435 - val_loss: 4.9356\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 0.3070 - val_loss: 2.5919\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.2527 - val_loss: 5.5988\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.3385 - val_loss: 1.9190\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.3207 - val_loss: 5.8941\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.2840 - val_loss: 1.9103\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.3142 - val_loss: 6.5683\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.2784 - val_loss: 3.5419\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.2945 - val_loss: 2.5381\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.4570 - val_loss: 9.2274\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.7015 - val_loss: 0.5092\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 1.0755 - val_loss: 18.1601\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 1.4252 - val_loss: 0.5736\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.7222 - val_loss: 11.4022\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.5115 - val_loss: 1.2357\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.3807 - val_loss: 12.1792\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.5009 - val_loss: 0.5554\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.9101 - val_loss: 17.8649\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 1.3226 - val_loss: 0.7852\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.3991 - val_loss: 17.9271\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 1.1263 - val_loss: 0.5470\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.9095 - val_loss: 14.5258\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 1.3747 - val_loss: 1.4122\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 3.3157 - val_loss: 36.4443\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 913us/step - loss: 3.8433 - val_loss: 1.5081\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 1.6763 - val_loss: 18.8923\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 1.6362 - val_loss: 1.5073\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 2.1741 - val_loss: 43.6082\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 2.8706 - val_loss: 1.9790\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 1.7457 - val_loss: 17.6107\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.9717 - val_loss: 0.9370\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 1.1362 - val_loss: 13.3952\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.5044 - val_loss: 0.8190\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.4131 - val_loss: 4.0525\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.7066 - val_loss: 3.2011\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.3036 - val_loss: 5.4002\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.3789 - val_loss: 3.9540\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.2251 - val_loss: 3.5915\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.3211 - val_loss: 6.0152\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.2639 - val_loss: 3.2026\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.2849 - val_loss: 5.9989\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.2489 - val_loss: 5.4830\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.3928 - val_loss: 3.1411\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.2819 - val_loss: 5.7982\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.2505 - val_loss: 2.1004\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.2972 - val_loss: 5.9626\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2833 - val_loss: 6.1492\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 772us/step - loss: 0.5081 - val_loss: 1.2788\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.6647 - val_loss: 10.8628\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.7203 - val_loss: 0.7670\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 963us/step - loss: 0.6507 - val_loss: 16.9353\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 1.1171 - val_loss: 2.7399\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.5410 - val_loss: 3.7817\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.2285 - val_loss: 2.5594\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.2205 - val_loss: 5.9393\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 765us/step - loss: 0.2659 - val_loss: 2.8737\n",
      "Epoch 1410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 842us/step - loss: 0.2266 - val_loss: 6.2376\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.2681 - val_loss: 3.9632\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 777us/step - loss: 0.2721 - val_loss: 5.5694\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.3393 - val_loss: 7.8182\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.5229 - val_loss: 2.9531\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.4043 - val_loss: 9.9197\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.8209 - val_loss: 0.6796\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 0.8032 - val_loss: 11.0293\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.6431 - val_loss: 0.5043\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 1.0047 - val_loss: 15.8589\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.8848 - val_loss: 2.0078\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.3820 - val_loss: 9.7267\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.3464 - val_loss: 2.2596\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.2703 - val_loss: 5.6657\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 894us/step - loss: 0.2498 - val_loss: 2.5952\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.2264 - val_loss: 5.1574\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.2460 - val_loss: 2.5754\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.2422 - val_loss: 3.4712\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.2333 - val_loss: 4.2580\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.2467 - val_loss: 2.0668\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.2917 - val_loss: 6.6593\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.2780 - val_loss: 2.6062\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.2731 - val_loss: 5.0459\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.2270 - val_loss: 3.2606\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.2596 - val_loss: 4.6286\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.2256 - val_loss: 4.6267\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.2350 - val_loss: 3.0274\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2347 - val_loss: 3.9727\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.2243 - val_loss: 4.4174\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.2319 - val_loss: 2.2573\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.3136 - val_loss: 5.5181\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.2395 - val_loss: 4.1474\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2322 - val_loss: 3.5605\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.2168 - val_loss: 5.7468\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.2917 - val_loss: 1.3857\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.3892 - val_loss: 10.7380\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.5364 - val_loss: 0.5920\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 1.0101 - val_loss: 10.0761\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.6055 - val_loss: 7.2762\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 1.1210 - val_loss: 3.0187\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 735us/step - loss: 0.5176 - val_loss: 8.4608\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.2971 - val_loss: 6.4588\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.2366 - val_loss: 4.9847\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.2147 - val_loss: 5.4095\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.2162 - val_loss: 2.3901\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2749 - val_loss: 7.8042\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.3531 - val_loss: 0.9311\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.4228 - val_loss: 11.5145\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.5992 - val_loss: 3.0902\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 895us/step - loss: 0.2333 - val_loss: 6.0976\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.2345 - val_loss: 4.8421\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.2152 - val_loss: 5.4076\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.2154 - val_loss: 3.1327\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.2252 - val_loss: 6.7695\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.2881 - val_loss: 1.5217\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 922us/step - loss: 0.2957 - val_loss: 8.3847\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.4755 - val_loss: 0.8211\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 924us/step - loss: 0.4568 - val_loss: 12.8762\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.7217 - val_loss: 3.0395\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.3248 - val_loss: 3.4872\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.2120 - val_loss: 3.2103\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.2089 - val_loss: 3.4443\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.2106 - val_loss: 6.9070\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.3165 - val_loss: 1.7927\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.2714 - val_loss: 6.9431\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.3587 - val_loss: 3.8749\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.2682 - val_loss: 2.6612\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.2290 - val_loss: 5.9584\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.2627 - val_loss: 1.4497\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.3713 - val_loss: 5.5389\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.2258 - val_loss: 4.7851\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2289 - val_loss: 5.1757\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2259 - val_loss: 5.9397\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 947us/step - loss: 0.2687 - val_loss: 2.5849\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 817us/step - loss: 0.2184 - val_loss: 6.5442\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.2569 - val_loss: 1.3092\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.2995 - val_loss: 7.2636\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.3145 - val_loss: 1.4456\n",
      "Epoch 1488/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 806us/step - loss: 0.3500 - val_loss: 1.5097\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 754us/step - loss: 0.6131 - val_loss: 11.5136\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.6140 - val_loss: 0.8497\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 1.1952 - val_loss: 11.2239\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 0.4711 - val_loss: 2.5525\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5563 - val_loss: 9.3884\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.4253 - val_loss: 1.7209\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.3436 - val_loss: 7.4855\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.4124 - val_loss: 0.4057\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.5124 - val_loss: 5.4118\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.3448 - val_loss: 5.3738\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.5205 - val_loss: 3.0995\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.3144 - val_loss: 9.2209\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.3551 - val_loss: 2.4791\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.2849 - val_loss: 9.6062\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.3250 - val_loss: 2.5698\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.2690 - val_loss: 3.6119\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 785us/step - loss: 0.3538 - val_loss: 3.6270\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.2218 - val_loss: 2.9019\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.2161 - val_loss: 5.3076\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2553 - val_loss: 0.6548\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 1.5958 - val_loss: 32.2840\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 1.8996 - val_loss: 3.9822\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 2.3395 - val_loss: 7.8804\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 1.0330 - val_loss: 13.8310\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 2.9877 - val_loss: 2.4903\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 2.8155 - val_loss: 25.2009\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 3.8560 - val_loss: 9.6401\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 4.5096 - val_loss: 36.0624\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 2.9453 - val_loss: 9.9806\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 2.9290 - val_loss: 36.3736\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 3.1587 - val_loss: 12.1135\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 4.1552 - val_loss: 10.7637\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.7166 - val_loss: 0.9763\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.4127 - val_loss: 5.6971\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.3269 - val_loss: 1.5501\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.3850 - val_loss: 6.3091\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 907us/step - loss: 0.3948 - val_loss: 3.3535\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.5318 - val_loss: 3.2958\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 0.2229 - val_loss: 2.6471\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.1842 - val_loss: 3.5355\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.2360 - val_loss: 1.4651\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.2097 - val_loss: 3.6405\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.2137 - val_loss: 3.1671\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.1939 - val_loss: 1.6966\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.2505 - val_loss: 6.5286\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.3184 - val_loss: 1.0499\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.3213 - val_loss: 7.9031\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.3757 - val_loss: 0.6594\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.5690 - val_loss: 6.6637\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.2903 - val_loss: 0.6295\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.4504 - val_loss: 11.4714\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.6440 - val_loss: 0.7626\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.4465 - val_loss: 7.8353\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 895us/step - loss: 0.2763 - val_loss: 0.8176\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.6042 - val_loss: 16.2815\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 0.9285 - val_loss: 0.8485\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 1.0008 - val_loss: 13.1827\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.7542 - val_loss: 5.2814\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 928us/step - loss: 1.5247 - val_loss: 0.4571\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 2.3131 - val_loss: 9.4849\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.8940 - val_loss: 1.8762\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 909us/step - loss: 0.8302 - val_loss: 9.3593\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.4695 - val_loss: 1.7007\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.4137 - val_loss: 7.4197\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.2782 - val_loss: 2.1736\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.5229 - val_loss: 15.6800\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.7293 - val_loss: 0.6517\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.6596 - val_loss: 8.9057\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3167 - val_loss: 2.7667\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.1877 - val_loss: 6.1412\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.2349 - val_loss: 1.3945\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.3504 - val_loss: 7.5183\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 747us/step - loss: 0.3019 - val_loss: 3.4553\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.2351 - val_loss: 4.4763\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.2703 - val_loss: 5.9508\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.4150 - val_loss: 2.5812\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.2641 - val_loss: 5.8838\n",
      "Epoch 1566/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 775us/step - loss: 0.2166 - val_loss: 4.0560\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.2229 - val_loss: 3.2367\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1984 - val_loss: 6.9738\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 745us/step - loss: 0.4200 - val_loss: 0.7788\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.4567 - val_loss: 11.7965\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 797us/step - loss: 0.5631 - val_loss: 0.7699\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 749us/step - loss: 0.4823 - val_loss: 8.4965\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.2823 - val_loss: 4.5420\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 803us/step - loss: 0.3528 - val_loss: 5.0905\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.2605 - val_loss: 7.1322\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.3964 - val_loss: 1.6778\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.9157 - val_loss: 10.2291\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 750us/step - loss: 0.7969 - val_loss: 1.2776\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.3891 - val_loss: 7.9059\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.4620 - val_loss: 0.4753\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 0.4865 - val_loss: 10.2347\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 738us/step - loss: 0.5894 - val_loss: 0.8477\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 768us/step - loss: 0.3151 - val_loss: 15.9068\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.9365 - val_loss: 0.6629\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.6640 - val_loss: 24.8827\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 1.3374 - val_loss: 0.7012\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 1.1280 - val_loss: 19.0112\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 1.1073 - val_loss: 0.4823\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.6544 - val_loss: 12.4616\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.5551 - val_loss: 0.8172\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5253 - val_loss: 1.8676\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 0.5479 - val_loss: 3.8955\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.5189 - val_loss: 3.2998\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.4164 - val_loss: 2.6294\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.2570 - val_loss: 5.2312\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 916us/step - loss: 0.1892 - val_loss: 3.7222\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.3642 - val_loss: 0.4891\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 935us/step - loss: 1.7902 - val_loss: 25.8017\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 857us/step - loss: 2.3731 - val_loss: 1.1210\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 1.4775 - val_loss: 19.6272\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.9135 - val_loss: 0.8171\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.9840 - val_loss: 12.0534\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.5078 - val_loss: 0.6022\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.7739 - val_loss: 15.6200\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.7173 - val_loss: 1.1297\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.3041 - val_loss: 12.5502\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.4333 - val_loss: 0.6878\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.5130 - val_loss: 10.8867\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.4966 - val_loss: 2.2635\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.2286 - val_loss: 12.3156\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.5426 - val_loss: 0.4717\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 0.8183 - val_loss: 24.0618\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 2.0794 - val_loss: 5.7147\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 2.7711 - val_loss: 40.7354\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 3.0245 - val_loss: 0.4734\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 1.0735 - val_loss: 16.4487\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.9193 - val_loss: 2.3490\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2897 - val_loss: 9.1326\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.3421 - val_loss: 2.6595\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.2227 - val_loss: 8.5908\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.2929 - val_loss: 1.9405\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.2091 - val_loss: 4.9550\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.1886 - val_loss: 2.4667\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2575 - val_loss: 4.7180\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1789 - val_loss: 2.0671\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.2134 - val_loss: 6.1647\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1828 - val_loss: 2.7346\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 0.2092 - val_loss: 6.8959\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2309 - val_loss: 1.8247\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.3201 - val_loss: 6.3405\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.1940 - val_loss: 2.9606\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1985 - val_loss: 6.5647\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.2029 - val_loss: 2.4738\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.2076 - val_loss: 5.5747\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.1666 - val_loss: 1.2696\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 774us/step - loss: 0.3692 - val_loss: 7.6684\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.2815 - val_loss: 2.2041\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.2082 - val_loss: 5.1546\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.1781 - val_loss: 2.7925\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.1761 - val_loss: 7.4823\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 727us/step - loss: 0.3373 - val_loss: 0.5276\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.6742 - val_loss: 13.2807\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 812us/step - loss: 0.7428 - val_loss: 0.3816\n",
      "Epoch 1644/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 774us/step - loss: 0.5052 - val_loss: 9.2921\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.4557 - val_loss: 2.2332\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 1.3961 - val_loss: 29.1297\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 1.9897 - val_loss: 8.0629\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 3.6015 - val_loss: 13.4186\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5960 - val_loss: 0.9017\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.7964 - val_loss: 25.0686\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 918us/step - loss: 1.8947 - val_loss: 11.0827\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 3.1815 - val_loss: 24.4548\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 911us/step - loss: 4.2350 - val_loss: 4.5864\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 1.2928 - val_loss: 7.5432\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.4517 - val_loss: 1.1488\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.9172 - val_loss: 15.4894\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 822us/step - loss: 1.6000 - val_loss: 6.6408\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 2.3254 - val_loss: 29.3047\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 2.4890 - val_loss: 10.9948\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 3.5046 - val_loss: 63.7615\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 7.7140 - val_loss: 48.1492\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 8.4322 - val_loss: 29.8358\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 3.7819 - val_loss: 31.3659\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 7.1034 - val_loss: 32.6769\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 3.7437 - val_loss: 32.9958\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 7.8391 - val_loss: 65.8878\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 7.2277 - val_loss: 3.5874\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 4.2649 - val_loss: 33.3310\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 2.6172 - val_loss: 1.4728\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.7331 - val_loss: 7.4695\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.6684 - val_loss: 0.6178\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 745us/step - loss: 0.9142 - val_loss: 4.1228\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.5499 - val_loss: 0.9369\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.4112 - val_loss: 1.5431\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.2087 - val_loss: 4.6149\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.2146 - val_loss: 2.1006\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 750us/step - loss: 0.1820 - val_loss: 5.3326\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.2079 - val_loss: 2.5739\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1717 - val_loss: 3.6779\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.1713 - val_loss: 4.7316\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.2655 - val_loss: 2.7367\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.1709 - val_loss: 2.4817\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.1602 - val_loss: 4.7355\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.2000 - val_loss: 1.5453\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.2367 - val_loss: 4.3648\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.1865 - val_loss: 1.8984\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 770us/step - loss: 0.2267 - val_loss: 4.0335\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 776us/step - loss: 0.1697 - val_loss: 4.3859\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.1703 - val_loss: 3.2372\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.1676 - val_loss: 1.0665\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.6305 - val_loss: 8.9290\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 880us/step - loss: 0.7713 - val_loss: 2.0296\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.7629 - val_loss: 6.3468\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.4911 - val_loss: 0.4093\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 0.8558 - val_loss: 5.1120\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.5881 - val_loss: 5.9443\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.7780 - val_loss: 3.0386\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.6808 - val_loss: 0.3347\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 3.4213 - val_loss: 11.3401\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 3.9267 - val_loss: 0.3762\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 807us/step - loss: 4.0494 - val_loss: 18.8444\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 8.0868 - val_loss: 0.4047\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 814us/step - loss: 4.5446 - val_loss: 13.1431\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 2.6952 - val_loss: 4.0285\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.6940 - val_loss: 3.8712\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 875us/step - loss: 0.3587 - val_loss: 14.1074\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.5914 - val_loss: 0.8575\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.2404 - val_loss: 9.3209\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 901us/step - loss: 0.4277 - val_loss: 0.3657\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.9318 - val_loss: 12.4136\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 1.4147 - val_loss: 0.9699\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 1.1968 - val_loss: 8.6248\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.9827 - val_loss: 1.7092\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.8258 - val_loss: 4.6934\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 914us/step - loss: 0.6820 - val_loss: 1.6164\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.3866 - val_loss: 2.8369\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.1769 - val_loss: 4.3645\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.1643 - val_loss: 2.9105\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1649 - val_loss: 5.0781\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.1792 - val_loss: 2.1027\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1917 - val_loss: 5.0447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.2348 - val_loss: 1.3956\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 895us/step - loss: 0.3495 - val_loss: 4.7510\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.3588 - val_loss: 2.2141\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2083 - val_loss: 1.4215\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.1947 - val_loss: 4.1446\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.1553 - val_loss: 1.7415\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.1498 - val_loss: 4.1903\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2035 - val_loss: 1.5700\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1703 - val_loss: 2.5161\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 921us/step - loss: 0.1569 - val_loss: 3.1671\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1700 - val_loss: 1.6407\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.2121 - val_loss: 4.2294\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1865 - val_loss: 2.0241\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.2212 - val_loss: 3.4558\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.1691 - val_loss: 3.4139\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.1714 - val_loss: 1.7674\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.1778 - val_loss: 3.9534\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.2557 - val_loss: 0.6617\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.8245 - val_loss: 9.4918\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 841us/step - loss: 1.0226 - val_loss: 0.9682\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.4190 - val_loss: 3.7234\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.2238 - val_loss: 2.3098\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.1686 - val_loss: 2.5314\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.1623 - val_loss: 3.5772\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.1596 - val_loss: 3.4179\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1508 - val_loss: 3.1332\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.1511 - val_loss: 1.0714\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.2871 - val_loss: 3.2392\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.2561 - val_loss: 1.7874\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 902us/step - loss: 0.1963 - val_loss: 2.6504\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.1662 - val_loss: 2.4815\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 843us/step - loss: 0.1431 - val_loss: 2.0737\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.1494 - val_loss: 2.1650\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1495 - val_loss: 3.3854\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 850us/step - loss: 0.1456 - val_loss: 3.3942\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.1471 - val_loss: 1.9676\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 793us/step - loss: 0.1882 - val_loss: 5.1796\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.1976 - val_loss: 0.6919\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.6590 - val_loss: 4.7610\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.4221 - val_loss: 1.4501\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.2037 - val_loss: 1.4993\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 846us/step - loss: 0.1524 - val_loss: 3.8462\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 837us/step - loss: 0.1681 - val_loss: 1.1660\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.1945 - val_loss: 4.0228\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 831us/step - loss: 0.2239 - val_loss: 2.4305\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 895us/step - loss: 0.1622 - val_loss: 3.2834\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.1557 - val_loss: 0.9014\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.2303 - val_loss: 5.5649\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.2891 - val_loss: 0.5341\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.3324 - val_loss: 6.7705\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.2978 - val_loss: 1.3233\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.2089 - val_loss: 3.5111\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.1518 - val_loss: 2.4041\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 809us/step - loss: 0.1426 - val_loss: 2.5485\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 833us/step - loss: 0.1481 - val_loss: 2.4369\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.1654 - val_loss: 3.1984\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 0.1536 - val_loss: 3.1714\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.1359 - val_loss: 2.4982\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1394 - val_loss: 2.4332\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.1459 - val_loss: 3.9019\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.1971 - val_loss: 1.7152\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1756 - val_loss: 3.4359\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.1721 - val_loss: 1.9852\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1702 - val_loss: 4.2918\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.2242 - val_loss: 2.7146\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.2281 - val_loss: 2.5776\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.1628 - val_loss: 2.0207\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.1507 - val_loss: 3.0155\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1863 - val_loss: 1.7576\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.3361 - val_loss: 6.0206\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.3490 - val_loss: 0.4275\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3879 - val_loss: 3.0538\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 854us/step - loss: 0.1392 - val_loss: 1.6902\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.1480 - val_loss: 4.3243\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 855us/step - loss: 0.2298 - val_loss: 2.4199\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.1364 - val_loss: 2.4591\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.1397 - val_loss: 3.6512\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1668 - val_loss: 2.6880\n",
      "Epoch 1800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 839us/step - loss: 0.1472 - val_loss: 4.5008\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 936us/step - loss: 0.1932 - val_loss: 2.1124\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 852us/step - loss: 0.1311 - val_loss: 3.8754\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 821us/step - loss: 0.1945 - val_loss: 2.1476\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1607 - val_loss: 1.3869\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.2021 - val_loss: 3.2240\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 842us/step - loss: 0.1499 - val_loss: 1.8228\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.1737 - val_loss: 3.5556\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.1457 - val_loss: 2.3804\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.1662 - val_loss: 1.4430\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.2283 - val_loss: 5.0027\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.2764 - val_loss: 1.2542\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 874us/step - loss: 0.2150 - val_loss: 4.5553\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.2630 - val_loss: 2.7125\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.1315 - val_loss: 1.9328\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.1941 - val_loss: 2.7122\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.1435 - val_loss: 1.9213\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 950us/step - loss: 0.1373 - val_loss: 3.5133\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 892us/step - loss: 0.1442 - val_loss: 1.9372\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 940us/step - loss: 0.1373 - val_loss: 3.6485\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 970us/step - loss: 0.1305 - val_loss: 1.8159\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 897us/step - loss: 0.1515 - val_loss: 5.2022\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.1967 - val_loss: 1.6069\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 954us/step - loss: 0.2159 - val_loss: 4.4112\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 955us/step - loss: 0.2129 - val_loss: 1.3280\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.2894 - val_loss: 4.9269\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 914us/step - loss: 0.2330 - val_loss: 0.7770\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 970us/step - loss: 0.3341 - val_loss: 5.5215\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.2877 - val_loss: 0.6048\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 939us/step - loss: 0.2803 - val_loss: 6.8308\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 948us/step - loss: 0.4031 - val_loss: 0.3218\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.5650 - val_loss: 7.4783\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.5452 - val_loss: 0.4041\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.8337 - val_loss: 9.6102\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 0.5437 - val_loss: 0.3197\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 916us/step - loss: 0.5258 - val_loss: 11.5943\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.6368 - val_loss: 0.3417\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.5851 - val_loss: 14.1728\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 913us/step - loss: 0.8953 - val_loss: 1.3097\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 1.3027 - val_loss: 20.8379\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 931us/step - loss: 1.4208 - val_loss: 6.6247\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 896us/step - loss: 2.2087 - val_loss: 10.2613\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.4111 - val_loss: 5.1826\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 903us/step - loss: 1.5008 - val_loss: 27.9551\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 891us/step - loss: 3.1235 - val_loss: 24.4589\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 941us/step - loss: 5.5550 - val_loss: 25.0483\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 936us/step - loss: 2.4131 - val_loss: 11.0951\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 949us/step - loss: 2.9112 - val_loss: 6.9610\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 861us/step - loss: 0.5252 - val_loss: 1.5650\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 870us/step - loss: 0.9978 - val_loss: 6.6205\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 0.6636 - val_loss: 4.3391\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 914us/step - loss: 1.1675 - val_loss: 19.7101\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 1.4891 - val_loss: 3.4882\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 2.4413 - val_loss: 32.6770\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 900us/step - loss: 6.6705 - val_loss: 11.5870\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 898us/step - loss: 10.0991 - val_loss: 52.9398\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 926us/step - loss: 9.9279 - val_loss: 9.5423\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 7.8677 - val_loss: 21.8829\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 4.7888 - val_loss: 0.3382\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 943us/step - loss: 1.8879 - val_loss: 2.8173\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 1.0167 - val_loss: 2.6106\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.8331 - val_loss: 0.4994\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 873us/step - loss: 0.6520 - val_loss: 3.6874\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.7153 - val_loss: 1.1185\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6909 - val_loss: 3.3130\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 966us/step - loss: 0.3873 - val_loss: 0.2712\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 979us/step - loss: 0.4854 - val_loss: 6.6444\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2234 - val_loss: 1.0694\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 8.3943\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 970us/step - loss: 0.4112 - val_loss: 0.3666\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 934us/step - loss: 0.2939 - val_loss: 6.0664\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 879us/step - loss: 0.2736 - val_loss: 0.7566\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 0.2211 - val_loss: 3.9051\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 908us/step - loss: 0.2544 - val_loss: 0.5659\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 955us/step - loss: 0.4969 - val_loss: 6.0236\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.7560 - val_loss: 0.7781\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.4167 - val_loss: 0.7261\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 941us/step - loss: 0.1652 - val_loss: 4.7324\n",
      "Epoch 1878/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 953us/step - loss: 0.1875 - val_loss: 0.8038\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 968us/step - loss: 0.1777 - val_loss: 3.9754\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 986us/step - loss: 0.1562 - val_loss: 0.8611\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.1981 - val_loss: 4.8192\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 913us/step - loss: 0.2256 - val_loss: 1.2862\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 928us/step - loss: 0.2486 - val_loss: 4.0696\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1904 - val_loss: 1.5650\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 924us/step - loss: 0.1894 - val_loss: 2.4901\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 914us/step - loss: 0.1203 - val_loss: 3.3392\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.1417 - val_loss: 3.4026\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.2478 - val_loss: 2.0698\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.1539 - val_loss: 2.4331\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.1140 - val_loss: 3.1146\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.1291 - val_loss: 1.3976\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.1444 - val_loss: 3.8867\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.2456 - val_loss: 1.7670\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.2381 - val_loss: 3.9500\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 889us/step - loss: 0.1852 - val_loss: 1.6238\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 912us/step - loss: 0.2062 - val_loss: 4.1109\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 973us/step - loss: 0.3717 - val_loss: 2.3427\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.1982 - val_loss: 3.4893\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.5460 - val_loss: 0.5171\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 877us/step - loss: 0.8405 - val_loss: 2.3276\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.4969 - val_loss: 2.1993\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.3431 - val_loss: 0.2733\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.2201 - val_loss: 5.0602\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.2276 - val_loss: 0.5289\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.5800 - val_loss: 9.3263\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.6468 - val_loss: 0.7159\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.1814 - val_loss: 5.4719\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.1680 - val_loss: 1.1535\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.2461 - val_loss: 3.9710\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 865us/step - loss: 0.1581 - val_loss: 2.7547\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.1351 - val_loss: 1.9081\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 886us/step - loss: 0.1568 - val_loss: 3.9504\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.2556 - val_loss: 0.9556\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.1739 - val_loss: 2.7084\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 883us/step - loss: 0.2455 - val_loss: 1.1205\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 878us/step - loss: 0.1616 - val_loss: 2.1564\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.1164 - val_loss: 2.8502\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.1310 - val_loss: 2.5965\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.1210 - val_loss: 3.4803\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 872us/step - loss: 0.1419 - val_loss: 1.0924\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 802us/step - loss: 0.1681 - val_loss: 3.1304\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.1611 - val_loss: 1.6721\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.1266 - val_loss: 2.0982\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 755us/step - loss: 0.1147 - val_loss: 1.7843\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1231 - val_loss: 2.6136\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1223 - val_loss: 0.9276\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 794us/step - loss: 0.2632 - val_loss: 5.1239\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.3505 - val_loss: 1.4039\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 771us/step - loss: 0.1530 - val_loss: 2.3238\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.1214 - val_loss: 2.8542\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.1248 - val_loss: 0.9933\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 829us/step - loss: 0.1550 - val_loss: 3.8518\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.2497 - val_loss: 0.8361\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 882us/step - loss: 0.2645 - val_loss: 5.7958\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 0.3379 - val_loss: 0.9783\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.2046 - val_loss: 3.8840\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.1721 - val_loss: 1.3152\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.1619 - val_loss: 1.8055\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.1129 - val_loss: 3.3685\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.1394 - val_loss: 1.3871\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.1325 - val_loss: 2.7454\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.1169 - val_loss: 0.8688\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 756us/step - loss: 0.2138 - val_loss: 2.9638\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.2023 - val_loss: 0.7440\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.2286 - val_loss: 3.8690\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 806us/step - loss: 0.2022 - val_loss: 0.6936\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.2043 - val_loss: 3.1153\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.1754 - val_loss: 1.6825\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.1482 - val_loss: 4.0541\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.1845 - val_loss: 2.1761\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.1118 - val_loss: 2.8656\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 894us/step - loss: 0.1391 - val_loss: 1.7529\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.1116 - val_loss: 2.7366\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.1192 - val_loss: 1.6448\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.1141 - val_loss: 1.9595\n",
      "Epoch 1956/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 781us/step - loss: 0.1209 - val_loss: 1.7315\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 784us/step - loss: 0.1240 - val_loss: 1.8046\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1234 - val_loss: 2.3991\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 848us/step - loss: 0.1215 - val_loss: 1.2622\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.1571 - val_loss: 4.3336\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.1601 - val_loss: 0.6182\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.3484 - val_loss: 2.7153\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 751us/step - loss: 0.1169 - val_loss: 1.7286\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.1135 - val_loss: 3.2977\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.1830 - val_loss: 0.5530\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.2363 - val_loss: 3.1877\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.1536 - val_loss: 2.5167\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 823us/step - loss: 0.1487 - val_loss: 2.3949\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.1094 - val_loss: 1.9864\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 830us/step - loss: 0.1097 - val_loss: 3.1520\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.1668 - val_loss: 1.2988\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1307 - val_loss: 3.5215\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.1696 - val_loss: 0.4326\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.1922 - val_loss: 4.4653\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.3806 - val_loss: 0.2317\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.5351 - val_loss: 7.0151\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 828us/step - loss: 0.5482 - val_loss: 0.4677\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.2193 - val_loss: 7.0955\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.3586 - val_loss: 0.8706\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 756us/step - loss: 0.2853 - val_loss: 10.2411\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.4960 - val_loss: 0.7913\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 810us/step - loss: 0.2170 - val_loss: 5.4489\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.2649 - val_loss: 0.5527\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.2865 - val_loss: 4.3177\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 751us/step - loss: 0.2202 - val_loss: 0.3024\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.3020 - val_loss: 3.4121\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.1389 - val_loss: 1.0838\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 816us/step - loss: 0.2273 - val_loss: 0.3843\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.7969 - val_loss: 8.4735\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 798us/step - loss: 1.5140 - val_loss: 0.2833\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 767us/step - loss: 1.1531 - val_loss: 7.3469\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 791us/step - loss: 1.6572 - val_loss: 1.2515\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 863us/step - loss: 1.1964 - val_loss: 10.9889\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.6455 - val_loss: 0.6659\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.1986 - val_loss: 5.6899\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 840us/step - loss: 0.1998 - val_loss: 0.9319\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 738us/step - loss: 0.1804 - val_loss: 5.2152\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.1970 - val_loss: 0.7472\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.2039 - val_loss: 5.3546\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.3116 - val_loss: 1.2311\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X, Y, epochs=2000, validation_split=0.2, verbose=1, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 442.0501]\n",
      " [ 873.4851]\n",
      " [1303.9532]] [[ 446.62033]\n",
      " [ 878.9653 ]\n",
      " [1305.45   ]] [[ 440.1685]\n",
      " [ 846.5757]\n",
      " [1234.9359]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([30,60,90])\n",
    "test_input = test_input.reshape((3, 1, 1))\n",
    "test_output = model1.predict(test_input, verbose=0)\n",
    "print(model.predict(test_input, verbose=0),model1.predict(test_input, verbose=0),model2.predict(test_input, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
